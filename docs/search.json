[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Open Research",
    "section": "",
    "text": "Overview\nWelcome to the Open Research course! This course will guide you in making your research more open.\nThis course is intended for self-paced learning, aimed at academic researchers and scientists in any field and at any stage of their careers. The course is organised into 8 chapters, which you can either complete step-by-step over 8 weeks, or you can focus on specific topics of interest!\nOutline: First, you will explore what open research is, why it’s important, and how it can be applied to different disciplines and stages of the research process. You will become familiar with the underlying principles of open research: transparency, integrity, and accessibility. You will consider the actions you need to take to ensure your own research outputs meet all three of these standards.\nThe decision-making tree below summarises the topics covered in this course.",
    "crumbs": [
      "Overview",
      "Overview"
    ]
  },
  {
    "objectID": "Week1.html",
    "href": "Week1.html",
    "title": "1  Week 1: What is Open Research",
    "section": "",
    "text": "1.1 Examples of open research projects\nWhat is open research? There are many different definitions, and these may vary from discipline to discipline and across research methodologies. Here are a couple of examples:\nSimply, open research is a way of doing research that focuses on being transparent, honest, and thorough. It’s about making sure that all the steps of a study are clear and accessible, so that other researchers can understand, verify, and build upon the methodology and findings. It is an open door to research evidence, where everyone can see what’s available and contribute to the collective pool of knowledge.\nNo matter what your career stage, it is important to learn about how open research applies to your discipline, so that you can better assess the quality of research in your field and conduct more open research yourself. By the end of this course, you will have a good understanding of the principles underlying open research, and a set of practical techniques you can use to translate these abstract principles into action.\nTo give you an idea of what open research can look like, here are some examples. It is a good idea to open these in a new tab or window (right mouse click or long press), so you can easily return to this page:\nExample 1: The International Virtual Observatory Alliance (IVOA) is an impressive project in astronomy. IVOA is a framework that allows astronomical data to be shared and accessed globally. Over the years, the IVOA has developed standards and protocols to facilitate the seamless integration of data from various observatories, making it available to the global community. Have a play around with ESA Sky (built on IVOA protocols) yourself!\nExample 2: The mRNA Vaccine Technology Transfer Hub is an innovative project in the field of biotechnology and global health. Established by the WHO (World Health Organization) to facilitate the widespread production of mRNA vaccines, this hub provides training, resources, and support to manufacturers in low- and middle-income countries. This openness enables a broader range of producers to develop mRNA vaccines, helping to combat pandemics and improve global health security.\nExample 3: The Education Endowment Foundation (EEF) funds rigorous, high-quality evaluations of educational interventions. They are conducted by independent evaluators rather than the team that initially developed the intervention. All studies are registered ahead of time and the evaluation protocol is published in advance. All study findings are published on the EEF website, regardless of the outcome of the study.\nExample 4: The Pelagios Network is an inspiring example from the humanities. It is a community of researchers, data scientists and curators who use linked data methods and tools to investigate the past. Their interests are wide-ranging (history, language, archaeology, conservation, etc.) and span the field of cultural heritage, including universities, galleries, libraries, archives and museums. There’s more on this project in the next section.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1: What is Open Research</span>"
    ]
  },
  {
    "objectID": "Week1.html#examples-of-open-research-projects",
    "href": "Week1.html#examples-of-open-research-projects",
    "title": "1  Week 1: What is Open Research",
    "section": "",
    "text": "1.1.1 Spotlight: the Pelagios Network\nThe Pelagios Network uses linked open data to share information and support collaboration between scholars. The basic idea of linked open data goes back to the pioneers of the World Wide Web. It is a powerful way to freely use and distribute information.\nThroughout this course, we use videos to present perspectives on open research. Take a little time to write notes on these videos.\nOur first video, funded by AHRC and created by Too Tall Productions, takes you on a whistle-stop tour of how the Pelagios Network uses linked open data. As you watch, think about why this has the potential to be a great tool for research.\n\n\nVideo 1: Linked open data, what on earth is that?\n\n\n\n\n\n\n\nVideo Transcript - Click to expand\n\n\n\n\n\nPresenter: The archaeologist Winifred Lamb was a pioneer, not only in her research, but as a female in an occupation dominated by men.\nWinifred Lamb: Yes, but the research is so slow!\nPresenter: Excuse me?\nWinifred Lamb: Have you ever heard of linked open data?\nPresenter: No.\nWinifred Lamb: Right. When I’m fortunate enough to find an object such as this, I want to know more about it and how it links to other objects. But with the current research methods, researching objects and sites can take ages. I have to take a car, a plane, a bus to the library to find a book to look up which museum has the object I want to compare my object with, only to discover it’s on loan to a museum in Los Angeles. But these days we have a thing called the World Wide Web.\nPeople like me put their knowledge and research up there for all to see, so it can be viewed by anyone anywhere in the world, and it all links together. It’s called ‘linked open data’. And it can help us do research at lightning speed. When you put data out there on the web for all to see, and if we collaborate to help link this data, then that’s when we get linked open data. It means objects like this can talk to other objects all around the world. Locations, people, artifacts, books, we can link anything.\nMembers of the Pelagios community and friends of the Linking Islands of Data network have used the new technology to enrich the writings of the traveller Pausanias. His first-hand accounts of ancient Greece now link to enhanced information. This can lead to museum records, numismatic collections, and catalogues of Greek pottery.\nIn this way, linked open data can help us make meaningful connections and tell new stories which traditional methods of research could never achieve. And what’s more it can be accessed from anywhere in the world. So, through collaboration, we can all help make linked open data truly powerful.\n\n\n\n\n\nVideo 2: Using linked open data\nNow listen to Professor Elton Barker, classicist and co-founder of the Pelagios Network, to get the backstory. He talks about the very first attempts at collaboration, and how linked open data has helped him with his own research. As you watch the video, think about how this kind of resource could also help with other types of research.\n Click to download video\n\n\n\n\n\n\nVideo Transcript - Click to expand\n\n\n\n\n\nSo my name is Elton Barker. I’m a professor of Greek literature and culture at The Open University. That basically means I read a lot of ancient Greek literature and put that into its cultural and political context. But I’m also interested in the stories that we can extract from ancient Greek narratives in terms of their spatiality. So we don’t have maps of the ancient world, but we do have a lot of spatial knowledge embedded in texts.\nSo Pelagios, in its initial form, this goes back to 2012, I think. The proof of concept was working with the Persius classical library in the States, lots of people know that, it’s a fantastic resource - the German archaeological database, Arachne, and also the Pleiades Gazetteer. These were our three external partners and through these three external partners, we were able to come up with this lightweight method of connecting data, basically connecting their information.\nSo what can linked open data do for you? Well, let me give an example from a project that I’m working on. The title is the Digital Periegesis, which basically means a digital ‘going around’. It’s an echoing of a title of an ancient Greek narrative written in the second century CE, by this Greek called Pausanias. And he gives this deep dive into the Greek mainland. He doesn’t just talk about Athens, he takes you into Athens and he talks about the sites in Athens down to the ground level.\nSo not just there’s the Acropolis, but he takes you into inside the temple, he talks about the statues, the paintings, it’s a level of granularity you don’t get anywhere else. And one quick win there, of course, is that we can then visualise the places that he visited , and draw a line, and kind of follow Pausanias’ footsteps.\nBut critically, - this is where the linked open data comes in - there are two things I think are really interesting. The first is, as you are following Pausanias around, you can also link out to other materials. Because Pausanias, I’ve mentioned, he talks about statues, he talks about paintings.\nNow, we have this information in other resources, the German archaeological database again comes back. They have great resources in Athens and elsewhere. So as you are moving through Pausanias’ text and he’s describing these objects on the ground, you can link out from the text and go and have a look. The second critical thing, and this is where I think linked data gets really exciting, is that you can discover stuff that he doesn’t talk about. Let me give you one example.\nIn book one, he’s in Athens, he’s moving around Athens. He’s moving around the central marketplace of Athens and moving to talk about the great Olympian Temple of Zeus. You can see it from the map. But then using linked data means we can bring in other information about that area. So what other artefacts are in that area? And one artefact that is shown is the Arch of Hadrian.\nNow that appears on our map because that information has been published as linked data, by the Pleiades Gazetteer. But it’s not in Pausanias. So that already starts to ask us really interesting questions. Why does he not talk about the Arch of Hadrian? It’s not as if he couldn’t have seen it. It’s still there in Athens. You can go and look at the Arch of Hadrian now. He would probably have had to walk through the Arch of Hadrian to get to the Temple of Zeus. So why not mention it? I think this idea of using linked data to draw attention to the gaps, the absences, the biases in text, I think is one of the most exciting things about it.\n\n\n\n\nActivity 1\nAllow about 10 minutes.\nUsing your own notebook (online or offline), take some notes on what you have learned from both videos. How does the Pelagios Network use linked open data? What are the particular features of linked open data that Prof. Barker believes are most useful for scholars?\n When you are ready, press the button to view our comments.\n\n\n  Show / Hide Discussion \n  \n  \n  How the Pelagios Network use linked open data\nThe Pelagios Network researchers are interested in Greek objects and texts. Even if you come from a very different discipline, you should still be able to recognise how linked open data allows researchers in different institutions to collaborate, enriching the amount of data they can all access. The data is organised in a systematic way and given permanent identifiers, so the information can be scrutinised from different perspectives, and reused by researchers in other institutions or disciplines.\n  \n\nSo far, you have been introduced to five examples of open research projects from astronomy, medicine, education and the humanities. What do these disparate projects, from very different academic disciplines, have in common? To a greater or lesser extent, they all share some foundational principles. In this course, open research will be broken down into three key facets that span across disciplines: transparency, integrity, and accessibility. Let’s start with transparency.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1: What is Open Research</span>"
    ]
  },
  {
    "objectID": "Week1.html#transparency",
    "href": "Week1.html#transparency",
    "title": "1  Week 1: What is Open Research",
    "section": "1.2 Transparency",
    "text": "1.2 Transparency\nThe principle of transparency in research refers to the practice of being open and honest about all aspects of the research process.\nIn the TV show, Great British Bake Off, contestants compete in a UK-wide baking competition. In some tasks bakers are assessed on their creativity and flavour combinations, but in the show’s ‘Technical challenge’ they all have to follow the same recipe and make the same thing. Simple, right? Well, if it’s so simple, then why are there so many soggy bottoms?\nTechnical challenge instructions:\n\nMake the cake batter\nBake the cake\nIce the cake\n\nEven when a recipe is provided, there can be a lot missing. In the technical challenge above, the instructions do not specify which ingredients should go into the cake batter, in what order they should be added, or how long the cake should be baked. A recipe for disaster!\nA similar issue occurs in many academic research papers. Researchers describe what they did, but often not in enough detail for someone else to clearly understand what was done, or to repeat the study themselves. This means that another researcher hoping to reproduce the study may not able to reproduce it accurately. This is referred to as a study’s replicability.\nSimilarly, why are there so many amazing looking cakes on Pinterest, which become ‘Pinterest fails’ when people try to make them at home?\n\n\n\nCat cakes: reality versus expectations.\n\n\nSometimes it might be because the person sharing the beautiful picture of their cake tried thirty times before one turned out right, but fails to mention this, and instead tells readers how easy it was to make!\nSimilarly, researchers can fail to disclose versions of studies that they have tried, but that in their view didn’t ‘work’, choosing instead to share results from those studies that had the results that they desired.\n\nActivity 2\n What are all the things you could include in a recipe to give the baker the best chance of success? Make a note in your notebook. Try to think of at least five before revealing the answers below.\n\n\n  Show / Hide Discussion \n  \n  \n  Recipe for success?\nThe details will differ from person to person. In your answer, you might have included things like: pictures of each step, temperature of the oven, ingredients, length of baking time, size of tin, order of adding ingredients, how long to mix, and possible substitutions. It is likely that the details you included are those that will help determine whether your cake looks like the cat cake on the left, or the cat cake on the right. In the same way, researchers are more likely to be able to get the same result as other researchers if they can follow clear instructions on how to conduct the study.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1: What is Open Research</span>"
    ]
  },
  {
    "objectID": "Week1.html#integrity",
    "href": "Week1.html#integrity",
    "title": "1  Week 1: What is Open Research",
    "section": "1.3 Integrity",
    "text": "1.3 Integrity\nThe principle of integrity refers to the degree of trustworthiness or believability of research findings. So, a transparent study is trustworthy and believable, right? Not necessarily! Transparency can be considered to be necessary, but not sufficient, for assessing integrity. Being transparent about how a study was done enables other researchers to better assess whether the study has integrity.\nIf you let your friend taste a cake you’ve made, but don’t tell them any of the ingredients that went into it, they might have a harder job working out why they do or don’t like it than if they know what went into it. For example, if they liked that the cake tasted citrussy, they would not know that was because of the grapefruit zest in the ingredients list (rather than maybe lemon juice or citric acid).\n\nActivity 3\nAllow about 10 minutes.\nNow let’s assume you have been completely transparent about your ingredients. Can you think of any circumstances where there could still be doubts about your integrity? Write down some notes for yourself. \n\n  Show / Hide Discussion \n  \n  \n  Considering integrity\nThere are lots of different ideas about what gives research findings integrity, and this will vary greatly depending on the field and research methodology. One important distinction is between qualitative and quantitative methodologies. In the next section, you’ll find out how this can fundamentally affect how researchers think about integrity.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1: What is Open Research</span>"
    ]
  },
  {
    "objectID": "Week1.html#quantitative-research",
    "href": "Week1.html#quantitative-research",
    "title": "1  Week 1: What is Open Research",
    "section": "1.4 Quantitative research",
    "text": "1.4 Quantitative research\nQuantitative research deals with numbers, aiming to quantify phenomena and establish patterns or relationships.\nA quantitative researcher interested in baking might be interested to know how many chocolate chips are needed to make the most delicious chocolate chip cookie. They decide to make three batches of cookies: one where each cookie has five chocolate chips, one where each has ten chocolate chips and one where each has fifteen chocolate chips. They ask participants to eat one of each cookie type and rank each cookie type from 1 (worst cookie) to 3 (best cookie). In other words, the researcher uses numerical (quantitative) data to work out how to make the most delicious cookie.\nWhen conducting quantitative research, researchers often try to remove themselves as much as possible from the research, aiming for objectivity (although there is considerable debate about whether this is possible!). As such, quantitative researchers believe that the replicability of a study is of the utmost importance for that study to be considered to have integrity. This means that when another researcher conducts the same study, they should get the same results.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1: What is Open Research</span>"
    ]
  },
  {
    "objectID": "Week1.html#qualitative-research",
    "href": "Week1.html#qualitative-research",
    "title": "1  Week 1: What is Open Research",
    "section": "1.5 Qualitative research",
    "text": "1.5 Qualitative research\nQualitative research focuses on understanding qualities, meanings and contexts through non-numerical data like words, images or observations.\nA qualitative researcher interested in how to make the most delicious chocolate chip cookie would take a different approach to the quantitative researcher. They might ask participants to describe the best and worst chocolate chip cookies they’ve ever eaten, and what they liked or disliked about them.\nIn qualitative research, objectivity is seldom desired or even considered possible. Instead, subjectivity is embraced explicitly, and researchers may include their own perspectives when writing up their papers. They wouldn’t necessarily assume that if someone else conducted the same study they would get the same results due to the complex interplay between the context of the participants and unique positionality of the researchers.\nSo qualitative and quantitative researchers often have different opinions about whether a study needs to be replicable in order to have integrity.\nIt’s important not to assume that there’s only one way for research to have integrity, and to understand the importance of different ways of doing research. The cheesecake below might look burnt to someone who is used to non-baked cheesecakes, but will look perfect to someone who is used to baked cheesecakes!\n\n\n\nDelicious or burnt?\n\n\n\nActivity 4\nAllow about 10 minutes.\nIn this activity, you will have the chance to test your understanding of ‘transparency’ and ‘integrity’ in open research. Read the following vignette, and decide whether it is an example of research that has transparency, whether it has integrity, transparency and integrity, or neither?\n\nDr. McGonagle is conducting a study on the effects of a new drug on psoriasis. She publishes her methodology, including how participants were selected, how the drug was administered, and how data were collected and analysed. She also shares her raw data and statistical analysis code publicly, allowing others to verify her results or conduct their own analysis. She clarifies in her methodology that she isn’t planning on comparing the new drug to anything else.\n\n Make a note of your thoughts before revealing our comments.\n\n  Show / Hide Discussion \n  \n  \n  Does the research have both transparency and integrity?\nDr. McGonagle has been transparent by publishing all the details of her study. However, the results from her research will show less integrity because she hasn’t compared the new drug to anything else. To increase the integrity of her research, she could compare the new drug to an existing drug and/or a placebo.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1: What is Open Research</span>"
    ]
  },
  {
    "objectID": "Week1.html#accessibility",
    "href": "Week1.html#accessibility",
    "title": "1  Week 1: What is Open Research",
    "section": "1.6 Accessibility",
    "text": "1.6 Accessibility\nThe principle of accessibility refers to ensuring that all who are interested are able to consume, evaluate, and otherwise interact with research products (e.g. data, results) and processes (e.g. methods). Even when research is transparent and has integrity, if only a limited group can access the outcomes or outputs of this research, it is not truly open.\nAsking people to pay to read a hidden recipe for the best cake ever means that only certain people will be able to afford to make it. This may not seem like the end of the world for cake, because cake is a luxury. We might even hope that the reason the recipe is behind a paywall is so that the author of the recipe can be paid for the hard work they put into developing it, as well as covering the costs to the website of editing and hosting the content. However, research is a bit different.\nOne reason for this is that the outputs of research are not a luxury, as research is used predominantly to solve the world’s problems! Another reason is that much research is publicly funded, meaning the public has a right to access the products of this research. Also, when research is behind a paywall (e.g. published in a journal where you have to pay to access articles), authors don’t get any of the money that people pay to read the article.\nIf authors want to make their article openly available to everyone, they usually have to pay for this themselves. That’s like a recipe creator either having to pay to have their recipe openly listed on a website, or the website charging for people to read the recipe which the recipe creator gave them for free.\nAccessibility is about more than just making the products of research available for free. Even if all research articles were free to read, if the public isn’t able to understand them, then they are useless! Converting a complicated recipe into bullet points, adding hints and tips, and translating it into different languages or adapting it for different accessibility needs, will mean that many more people are able to make the same recipe than if only the original version is provided.\n\n\n\n\n\n\nPause for thought 🤔\n\n\n\nTo publish an article openly in the famous journal Nature, researchers have to pay almost £9,000 (in 2024, at the time of writing; or US$12,000). Reflect on how APCs affect researchers in the Global South, and how journals might address this. Then, look up whether Nature has any ways of addressing this (clue: search for ‘APC waiver’).",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1: What is Open Research</span>"
    ]
  },
  {
    "objectID": "Week1.html#quiz",
    "href": "Week1.html#quiz",
    "title": "1  What is Open Research",
    "section": "1.7 Quiz",
    "text": "1.7 Quiz\nHow much have you learned? Take the self-test quiz below to find out!\n\n\n\nWhich of the following statements is not true:\n\n\nResearch can be transparent without having integrityResearch can have integrity without being transparentResearch can be accessible without being credibleResearch can be transparent without being accessible\n\n\n\nFeedback: Without transparency, we cannot assess whether or not research has integrity.\n\nResearch can be transparent without having integrity. False\nResearch can have integrity without being transparent. True\nResearch can be accessible without being credible. False\nResearch can be transparent without being accessible. False\n\n\n\n\n\n\nWhat does the principle of ‘integrity’ refer to in research?\n\n\nEnsuring that everyone has access to all research outputsWhether or not a study is replicableThe believability or trustworthiness of research findingsBeing open and honest about all aspects of the research process\n\n\n\nFeedback: Being open and honest about all aspects of the research process relates to transparency, and ensuring that everyone has access to all research outputs is accessibility. Some would consider whether or not a study is replicable to be an aspect of integrity, but integrity encompasses many other factors.\n\nEnsuring that everyone has access to all research outputs False\nWhether or not a study is replicable False\nThe believability or trustworthiness of research findings True\nBeing open and honest about all aspects of the research process False\n\n\n\n\n\n\nWhy is it important for researchers to provide detailed information about how a study was conducted? (Select one or more)\n\n\nSo that other researchers can repeat the same study againTo make it easier for readers to understand what was done in the studyTo enable other researchers to better assess the integrity of the studyTo prove that the researcher’s work is outstanding\n\n\n\nFeedback: These three are important academic reasons to provide detailed information about how a study was conducted – the researcher’s ego is not!\n\nSo that other researchers can repeat the same study again True\nTo make it easier for readers to understand what was done in the study True\nTo enable other researchers to better assess the integrity of the study True\nTo prove that the researcher’s work is outstanding False\n\n\n\n\n\n\nWhat is an example of a lack of transparency? (Select one)\n\n\nNot fully describing how you conducted your studyUsing an out-dated statistical methodPublishing your article behind a paywallSharing participants’ identifiable information\n\n\n\nFeedback: By not being transparent about how you conducted your study, others will find it difficult to understand what was done, assess the credibility of your study, and repeat the same study again. The other options do not refer to transparency, they relate to other principles of open research.\n\nNot fully describing how you conducted your study True\nUsing an out-dated statistical method False\nPublishing your article behind a paywall False\nSharing participants’ identifiable information False\n\n\n\n\n\n\nWhat is an example of a lack of accessibility?\n\n\nResearchers having to pay thousands of pounds to publish their articleAn article written in a very technical way, with no summary for the publicAn article published on publicly accessible websiteA research paper written using green and red textAn article published in an online journal which readers have to pay to download articles from\n\n\n\nFeedback: If an article is published in a journal behind a paywall, only those who can afford it can access it. Similarly, if researchers must pay to publish their article, then only researchers who have the funding to do this can publish. Red and green text could make an article less accessible for those with one type of colour-blindness. Even if an article is published openly, if there is no non-specialist summary for the public, then they still may not be able to learn from the research.\n\nResearchers having to pay thousands of pounds to publish their article True\nAn article written in a very technical way, with no summary for the public True\nAn article published on publicly accessible website False\nA research paper written using green and red text True\nAn article published in an online journal which readers have to pay to download articles from True",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Open Research</span>"
    ]
  },
  {
    "objectID": "Week1.html#summary",
    "href": "Week1.html#summary",
    "title": "1  Week 1: What is Open Research",
    "section": "1.8 Summary",
    "text": "1.8 Summary\nIn Week 1, we have briefly introduced the principles of transparency, integrity, and accessibility in open research. You’ve learned how they can interact with each other.\nAs you progress through the course, you will explore these open research principles in more depth, across disciplines and research methodologies. More importantly, you will learn how to apply them to your own research. In the final week, we will discuss ways you can commit to open research and get involved in different open research communities.\nNext week, we will take a deeper dive into transparency.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1: What is Open Research</span>"
    ]
  },
  {
    "objectID": "Week2.html",
    "href": "Week2.html",
    "title": "2  Transparency: As open as possible",
    "section": "",
    "text": "2.1 Sharing data and materials\nIn Week 1, you learned about what transparency is, and why being transparent is important in research. Ensuring your study generates open data and materialsData and materials from an open study are freely available to be used, reused, and redistributed by anyone. is a good way to increase the transparency of your research.\nMaking the outputs of your study more open means the data and materials you have gathered during your research can be used, reused, and redistributed by anyone. DataThe information or facts collected, observed, or generated during the course of a study or investigation. refers to the information or facts collected, observed, or generated during the course of a study or investigation. For example, in the quantitative chocolate chip cookie example from Week 1, the chocolate chip ranking would be the data.\nMaterialsAnything used in a study, e.g., questionnaires, consent forms, protocols outlining what was done, the code used to run any statistical analyses, etc. refers to any materials used in a research study. These can include (but are not limited to) the code used to run any statistical analyses, protocols outlining exactly what was done in the study, auditory and visual stimulus files shown to participants, questionnaires, documents used to obtain consent from participants, and videos of the study being run.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Transparency: As open as possible</span>"
    ]
  },
  {
    "objectID": "Week2.html#sharing-data-and-materials",
    "href": "Week2.html#sharing-data-and-materials",
    "title": "2  Transparency: As open as possible",
    "section": "",
    "text": "2.1.1 What are the benefits to sharing data and materials?\nThere are many benefits to sharing data and materials. See if you agree with all of them:\n\nOne is financial – the more products that are shared from any individual study, the more efficient the use of the funding used to conduct the study.\nSharing data also allows others to check the data for quality and accuracy, reproduce the analyses reported in a research paper, and expand on the analyses through running alternative analyses.\nMost datasets have uses beyond what is reported in a paper, including secondary data analysis that addresses different questions altogether.\nSharing data may be required by the project funder or the journal in which the article is published (see Top Factor for a list of journal requirements).\nJust as in sharing data – readers can check what was done in the study, re-run the same study, or change the materials to run a slightly different study.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Transparency: As open as possible</span>"
    ]
  },
  {
    "objectID": "Week2.html#open-data",
    "href": "Week2.html#open-data",
    "title": "2  Transparency: As open as possible",
    "section": "2.2 Open data",
    "text": "2.2 Open data\nData can be shared even when it is not related to a paper. However, researchers tend to share data alongside their papers, so that readers can see the structure of their data more clearly, re-run analyses from the manuscript, run additional analyses, and use the data to answer new questions.\n\nWhat do we mean by data?\nData can look very different depending on the research field, for example:\n\n\n\nBiology\nGenomic data from projects like the Human Genome Project, providing sequences of human DNA and other organisms.\n\n\nSocial Sciences\nSurvey data on demographics, attitudes, and behaviours collected by organisations like the United Nations or national statistical agencies.\n\n\nMedicine\nClinical trial data, including study protocols, patient demographics, treatment interventions, and health outcomes.\n\n\nHistory\nArchives of historical documents, such as diaries, letters, manuscripts, and government records, providing insights into past events, societies, and cultures.\n\n\nLiterature\nText datasets containing literary works, poetry, plays, and other written texts, facilitating analysis of language use, stylistic trends, and cultural themes.\n\n\nMusicology\nMusical score datasets, containing compositions from different composers, genres, and historical periods, for analysis of musical structure and style.\n\n\n\nEven within one study, there will often be multiple levels of data. For example, a study using interviews will result in video recordings of the interviews, the source data, transcripts, processed data, and then the text from the transcript may be coded quantitatively or qualitatively, resulting in the coding data.\n\nCan all data be shared?\nTechnically, it is possible for all of these to be shared, if participants have consented to do so. However, it is usually important to protect the anonymity of participants. While this is often possible to do with transcript data (after anonymising any identifying information about participants), this would be very difficult if sharing their video recordings.\n\n\nWhat data can or cannot be shared?\nWhen we talk about open data, the phrase ‘as open as possible, as closed as necessary’ is often used – meaning that researchers should strive to make their data open, but not where this would be unethical or illegal. Researchers must work within the ethical codes of their country and type of data collection. For example, in Europe, the General Data Protection Regulation (GDPR) sets out guidelines for dealing with ‘personal data’, i.e., any information related to an identifiable individual. To ensure human participants are not identifiable in our datasets, we as researchers must ensure we have removed all identifiable data from our datasets.\nIn some cases, this is obvious, simple, and doesn’t affect the usefulness of the data shared, for example removing IP addresses from data collected online. However, there are other cases where this is much more complex, and may result in the data not being possible to share at all, for example where qualitativeA qualitative method is used to identify, analyse and report patterns (themes) in non-numerical data. data on a very specific topic makes participants identifiable.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Transparency: As open as possible</span>"
    ]
  },
  {
    "objectID": "Week2.html#the-fair-principles",
    "href": "Week2.html#the-fair-principles",
    "title": "2  Transparency: As open as possible",
    "section": "2.3 The FAIR principles",
    "text": "2.3 The FAIR principles\nIn the previous section, you considered different types of data, and how open you can be when sharing them. Given the subtleties, it is useful to have a clear set of guidelines. The FAIR principles provide this. They state that shared data should be FAIR – findable, accessible, interoperable, and reusable:\n\nFindableResearch data is more findable by interested parties if it is stored in a well-organised repository with detailed metadata and persistent identifiers.: Data should be easy to find for both humans and computers. This involves using unique identifiers and metadataInformation that accompanies a piece of research, organising the materials, data and publications..\nAccessibleResearch data is accessible if it can be accessed by anyone in the world, either openly or through an authentication or authorisation process. This requires metadata describing it in a standardised format.: Once found, data should be easy to access, either openly or through an authentication or authorisation process. This ensures data is available in a standardised format.\nInteroperableDatasets are interoperable if they can be used together to generate new studies. The metadata uses standard vocabularies, which are consistent across lots of different datasets.: Data should be able to work with other data. This means using standardised formats and languages so that different systems can use the data together.\nReusableResearch data is reusable if it can be used, modified or analysed, potentially by other researchers, to generate new knowledge. It needs to include clear information to facilitate re-use.: Data should be well-documented and organised so that it can be used again in future research, potentially by different people. This includes clear information about how the data were collected and any licenses or permissions needed for its use.\n\n\n2.3.1 Expert voice: How do the FAIR principles work?\nIn this video, Isabel Chadwick, a research data specialist from the Open University, talks about the FAIR principles(From FORRT Glossary) Describes making scholarly materials Findable, Accessible, Interoperable and Reusable (FAIR). Findable and Accessible are concerned with where materials are stored (e.g. in data repositories), while Interoperable and Reusable focus on the importance of data formats and how such formats might change in the future., and how they can help researchers look after their data. As you watch the video, think about how you could follow Isabel’s advice in your own research.\n\n\n\n\n\n\n\nVideo Transcript\n\n\n\n\n\nMy name’s Isabel Chadwick. I’ve got a special interest in research data management. So my job involves helping researchers and research students to look after their data during their projects, thinking about all of the legal, ethical implications of looking after what is sometimes personal data, sometimes sensitive data, and sometimes just really, really big data.\nThe FAIR data principles are intended to give guidelines on the findability, the accessibility, the interoperability and the reusability of digital assets that are created during the course of research.\nThey go beyond merely saying that research data should be made open, and rather give more concrete guidance on how that data can be best exploited to enable reuse, replication, verification of results, any kind of scrutiny.\nSo they’re really, really important because a huge amount of money and time is invested into generating research data globally.\nAnd if that data isn’t findable, if it can’t be accessed, if it doesn’t interoperate, then essentially it isn’t reusable - and that sort of means that it’s a huge financial loss for global research as well as a bit of a setback for research progress.\nSometimes there are legal, ethical or commercial reasons why research data cannot be made publicly accessible.\nAnd FAIR data doesn’t always mean open data. So even where data has to be restricted to only allow access to certain people, or maybe even no people, the really important thing is that the metadata that describes that data is made available.\nNow, when we use the term metadata, what we mean is all of the information that builds up a picture about what that item or that data set might be. So a really good way of thinking about metadata is thinking about things that you use in your everyday life. So for example, you might have a record collection that you have organised according to different things.\nSo you might have put it in alphabetical order according to the name of the artist, or you might have put it into different sections for classical, pop, rock, for example. Or you might simply have just done it in a colour order to make it look like a pretty rainbow and all of those are ways of organising information using different types of metadata in order to be able to find things and understand things more easily.\nAnd we do the same things with information that includes data sets, but also would be things like publications, so every published piece of research will have rich metadata assigned to it.\nWhen it comes to research data, that information is really, really important, because in terms of transparency, allowing people to understand how you created your data, what the data is - and pretty key to this is - how they can reuse it, is really important.\nTo make your data FAIR, there are a few really key steps that come at different points in your research process. So right at the beginning of your research project, before you’ve even started collecting your data, we would always advise that you write a data management plan(From FORRT Glossary) A structured document that describes the process of data acquisition, analysis, management and storage during a research project. It also describes data ownership and how the data will be preserved and shared during and upon completion of a project.. And that plan should outline how you’re going to look after your data during your project, and then what’s going to happen to it after your project.\nIn terms of what happens after your project, the best piece of advice for making your data FAIR, would be to deposit it in a trusted digital repository. And you should do this whether your data is going to be openly available to the public, or whether it’s going to have a restricted access placed upon it.\nThe reason why we say that you should put your data into a trusted digital repository is because it will provide you with a persistent identifier like a DOI, which will ensure findability and accessibility of your data.\nIn terms of reusability, it will also enable you to assign an open license to your data, so that people can understand what the terms of free use are, and they know what they are and aren’t allowed to do with that data when they access it.\nAnd finally, in terms of interoperability, what’s really important is that you use those DOIs or those persistent identifiers that you are provided with by your repositories, or by your publishers, to link your different outputs. So we want to see you linking your data sets with your publications, with your other outputs, with your software, for example, and your materials.\nThat’s a really important aspect of FAIR.\nBut, to start from the beginning, the data management plan(From FORRT Glossary) A structured document that describes the process of data acquisition, analysis, management and storage during a research project. It also describes data ownership and how the data will be preserved and shared during and upon completion of a project. is a really solid way to start.\n\n\n\n\n  Show / Hide Discussion \n  \n  \nIsabel explains that the FAIR principles make the best use of expensively acquired global research findings, given the limits to openness. She explains the key concept of ‘metadata’: something that allows you to organise your research data and publications. She advises researchers to write a data management plan at the outset of their study, and to place the material in a trusted digital repository at the end of the study (you will learn more about this later).\n  \n\n\n\n\n\n\n\nPause for thought\n\n\n\nData shouldn’t just be FAIR for humans. It needs to be FAIR for machines as well. Take ten minutes to think about the implications of living in a world that’s becoming more and more computationally intensive, and where global research data is being generated so quickly that humans struggle to keep up. How can you organise your own open data so computers are able to find it without human intervention? When you are ready, press ‘reveal’ to see our comments.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Transparency: As open as possible</span>"
    ]
  },
  {
    "objectID": "Week2.html#licensing-data",
    "href": "Week2.html#licensing-data",
    "title": "2  Transparency: As open as possible",
    "section": "2.4 Licensing data",
    "text": "2.4 Licensing data\nIn the video, Isabel Chadwick recommended that when researchers share their data, they should choose a license to apply to the data. A license is a set of rules and permissions that tells you how you can use someone else’s data. It is like an agreement between the person who created the data (the data owner) and the person who wants to use it (the data user).\nA license specifies what you can and cannot do with the data, whether or not you need to give attribution to the data owner, and whether or not you can further share the data. For example, a common open license used for research data is CC BY-NC 4.0, which allows the person using your data to share and adapt the data, but only if they give attribution to you, the data owner, and don’t use the data for commercial purposes.\nThere are other types of license, which allow you to specify different levels of openness. You can choose to give your work over to the public domain, so people can do whatever they like with it. Alternatively, you can choose a type of license which prevents users from adapting your work. You can find out more about licensing by referring to this helpful list on the Creative Commons website.\n\nActivity 1\nAllow about 10 minutes\nIn this activity, you can test your understanding of considering anonymity when it comes to data sharing.\nIn an interview study about criminal experiences, three types of data are generated.\n\nA. Edited transcripts form the interview, with identifiable information removed\nB. Videos of people being interviewed\nC. Full unedited transcripts from the interview\n\nWhich type of data do you think is the least likely that you will be able to be share them openly? Which would be the most likely?\n Take a moment to write your notes before continuing.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Transparency: As open as possible</span>"
    ]
  },
  {
    "objectID": "Week2.html#where-to-share-data",
    "href": "Week2.html#where-to-share-data",
    "title": "2  Transparency: As open as possible",
    "section": "2.5 Where to share data?",
    "text": "2.5 Where to share data?\nIn the video, Isabel Chadwick explained that it is best practice to archive data and materials in an open access repositoryOpen access is the free, immediate, online availability of research outputs such as journal articles without having to pay a fee, combined with the rights to use these outputs fully in the digital environment. to make your research accessible. Whether you choose an institutional repository or a discipline’s repository, these trusted digital platforms provide a safe way to store research materials and data, and link to related content held elsewhere.\nThere are different repositories for different research fields and different types of data, but some examples are the Open Science Framework, the Qualitative Data Repository, and Zenodo. Here is an example of how to share data and materials on the Open Science Framework. The Open University also has its own repository (ORDO) where data and materials from researchers at The Open University can be shared.\nCase Studies\n\n\n\nChemistry\nThis study by Lia et al. (2020) investigates the structure and mechanisms of one enzyme involved in the chain of reactions through which our bodies metabolise glucose. All the data in this study are openly available with the paper, which directs readers to RCSB Protein Data Bank and Zenodo for underlying data and extended data.\n\n\nPsychology\nPLAY (Play & Learning Across a Year) is a project that aims to explore infants and their mother’s natural behaviours in their homes, across 50 universities in the United States. All materials, home visit protocols and the video and questionnaire data collected are all openly available on their website.\n\n\nArt\nQuantitative and qualitative data and software related to an Open University PhD thesis by Kanter (2024) have been shared openly on ORDO. This thesis was about British portraiture in the 1900s.\n\n\n\n\nActivity 2\nAllow around 10mins\nIn this activity, you will get the opportunity to explore an open access repository.\nHave a look online for some open data and materials, preferably in your field of research. One way of doing this is to use keywords to search for projects on ZENODO. Use the ‘search records’ box at the top to select your keywords, and use ‘resource types’ to filter your search so that it only includes datasets. Think of ways you could use the research products you find to answer a question that interests you.\nWhen you are ready, see our comments below.\n\n  Show / Hide Discussion \n  \n  \n  Exploring an open access repository\nYour response will depend on your discipline and interests, and those of the researchers whose work you found. You might decide to use the data to generate new knowledge by analysing the original researchers’ datasets in new ways, or by running a related study based on their materials.\n  \n\n\n\nExample of using data from Open Science Framework\nHere’s a real-life example of using data from the Open Science Framework platform for a secondary data analysisA type of study where you use existing data to answer new questions..\nPrinzing (2024) reused data from an experience sampling study (where participants are repeatedly asked about their daily experiences related to a particular topic) on pro-environmental, sustainable behaviour. Prinzing used these data to investigate whether engaging in sustainable behaviour increased a person’s wellbeing. They shared some of the original data that they used and their analysis code on a separate OSF project. There are a few other things they could have done: they did not share a data dictionaryA data dictionary is a collection of names, definitions, and attributes about data elements being used in shared data., and they didn’t apply a license to the materials on their OSF project.\nNevertheless, the author of this course, Silverstein (2020), was able to reproduce the analyses from Prinzing (2024) using their data and code. Interestingly, in the process of conducting this reproduction, Silverstein found a typo in one of the values in the paper! The authors have now updated this.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Transparency: As open as possible</span>"
    ]
  },
  {
    "objectID": "Week2.html#reproducibility-in-quantitative-research",
    "href": "Week2.html#reproducibility-in-quantitative-research",
    "title": "2  Transparency: As open as possible",
    "section": "2.6 Reproducibility in quantitative research",
    "text": "2.6 Reproducibility in quantitative research\nOpen data is key to understanding one of the big concerns in quantitative research: reproducibilityA study is reproducible if you are able to get the same results when conducting the same analyses on the same data as the original study.. Assessing reproducibility means assessing the value or accuracy of a scientific claim based on the original methods, data, and code. So, when you run the same analyses on the same data, do you get the same results?\nRunning the same analyses on the same data can mean different things depending on what materials the reproducer has access to. Investigating the reproducibilityA minimum standard on a spectrum of activities (“reproducibility spectrum”) for assessing the value or accuracy of scientific claims based on the original methods, data, and code. For instance, where the original researcher’s data and computer codes are used to regenerate the results (Barba, 2018), often referred to as computational reproducibility. of a study can mean taking the original data and:\n\nFollowing the description of analyses in the paper.\nFollowing an analysis plan created by the original authors.\nRe-running the analysis code that has been shared with the data.\n\nAs you can imagine, it’s easier to get the same results as the original researchers if there is less uncertainty around what they did. So, re-running the analysis code will be more likely to produce the same results than following the description of analyses in the paper. Going back to our baking analogy, it would usually be easier to produce the same cake as a professional chef if they shared the recipe they used than if they just described what they did, and the more detail they provided in the recipe, the easier it would be. However, even if a professional chef shared both a detailed recipe and a description of what they did, your cake might end up with a soggy bottom! Similarly, in research, when we have both the code and the data, it can still be difficult to reproduce results.\n\n\n\n\n\n\nMake it more likely for other researchers to reproduce results of your study\n\n\n\n\nShare a data dictionary – list all the variables in your dataset, what they mean, how they were manipulated, and how they’re structured\nAnnotate your code – make notes of what you did at each stage of the data pre-processing and analysis and why\nMake a note of software versions – analyses might stop working with future versions\nMake sure your data and code are suitably licensed – for example, a CC-BY-NC 4.0 license means that anyone can share or adapt the material as long as they give you appropriate credit and do not use the materials for commercial purposes.\n\n\n\n\nActivity 3\nAllow about 10 minutes.\nThis activity will allow you to test your understanding of reproducibility.\nYou have been hired to run a reproduction of a study, and your goal is to ensure that the results are reproducible before a journal publishes it. Consider the situations below. Which do you think has the lowest likelihood of reproducing the study findings? Which has the highest likelihood?\nA. The paper comes with shared data but no code, however there is a detailed analysis plan explaining exactly which analyses were done in which order, and a data dictionary describing exactly how the data are named and structured.\nB. The paper comes with shared data and code, but the code is from over 10 years ago and doesn’t specify which version of the software it used. The code isn’t annotated and there is no data dictionary. Variable names in the data don’t match what’s in the code.\nC. The methods section of the paper isn’t written very clearly, so you’re not sure exactly how the key analysis was run or what the exclusion criteria are. The data have been shared, but without any code or analysis plan.\n\n\n\n\n\n\nCorrect Answer - Click to reveal\n\n\n\n\n\n\nThe methods section of the paper isn’t written very clearly, so you’re not sure exactly how the key analysis was run or what the exclusion criteria are. The data have been shared, but without any code or analysis plan.\nThe paper comes with shared data and code, but the code is from over 10 years ago and doesn’t specify which version of the software it used. The code isn’t annotated and there is no data dictionary. Variable names in the data don’t match what’s in the code.\nThe paper comes with shared data but no code, however there is a detailed analysis plan explaining exactly which analyses were done in which order, and a data dictionary describing exactly how the data are named and structured.\n\n\n\n\n Take a moment to write down your answers and logic.\n\n\n\n\n\n\nThis was a bit of a trick question! - Click for our comments\n\n\n\n\n\nUsually re-running analysis code will get you closer to the same results as the original researchers than following an analysis plan will, but in this case there are a lot of issues with the code that has been shared.\nScenario 1 is the one where you are least likely to be able to reproduce the original study’s findings. You don’t have much to work with at all: you have neither the code nor a detailed analysis plan. It will be very difficult to make sure you’re doing the exact same analysis as the authors, and so you’re a lot less likely to get the exact same results.\nIn Scenario 2, although you have the code, it is old and doesn’t say which software version it used. You’re likely to run into errors when you try to run the code (the software may have changed since the code was originally written). Because the code isn’t annotated and there isn’t a data dictionary, it will be very hard to work out what the different sections of code are trying to do, meaning a lower likelihood of being able to ‘debug’ the code if you run into errors.\nScenario 3 gives the best chance of reproducing the original study’s findings. Although the original code hasn’t been shared, there is a detailed analysis plan and data dictionary, so you should be able to work out which variables are which, and follow what the authors did in their original analyses. Because there isn’t existing code, you won’t run into errors with the code not running, although you might get slightly different numbers due to different software versions having slightly different ways of running analyses (e.g. different default settings).",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Transparency: As open as possible</span>"
    ]
  },
  {
    "objectID": "Week2.html#open-data-in-qualitative-research",
    "href": "Week2.html#open-data-in-qualitative-research",
    "title": "2  Transparency: As open as possible",
    "section": "2.7 Open data in qualitative research",
    "text": "2.7 Open data in qualitative research\nIn the previous section we considered transparency in a quantitative study. To recap, in quantitative studies your data will usually be numerical. You might measure how quickly people respond to stimuli on a computer, or how much people would be willing to pay for a certain item.\nOpen data and materials can mean something quite different in qualitative research. This type of research focuses on patterns and themes in non-numerical data such as words, images, or observations. Imagine you are taking part in a qualitative study and are being interviewed about something close to your heart or your experiences. Try to imagine a topic that feels personal or emotive. Your data – instead of being a number – would be the actual words you said.\n\nHow would you feel if you took part in an interview study about an emotive topic and your data was made open and accessible?\nAre there any situations where you would be happy for your data to be open?\nAre there any situations where you definitely wouldn’t want your data to be open?\n\n Write down your thoughts in your notes.\n\nActivity 4:\nAllow about 20 minutes.\nNow read the vignette below, about a qualitative researcher considering sharing their data. Consider the benefits of making the data open, and the ethical issues that the researcher should consider.\n\nA researcher is conducting a qualitative study with LGBTQ+ students about their experiences of mental health problems. The students that participated took part in in-depth interviews, which were video recorded, transcribed and analysed using thematic analysis. They gave consent for their data to be used in this study. The researcher is trying to work out whether or not to make the data from this study open.\n\n\nWhat would be the benefits of making this data open?\nWhat issues should the researcher consider when making this decision?\n\nWrite your notes down, and see our comments when you are ready.\n\n  Show / Hide Discussion \n  \n  \n  Benefits of making data open\nPromotes transparency as others can see exactly how the research conclusions were derived.\n The data can be used in future studies, maximising the usefulness of the data and meaning further insights can be gained from the same data.\n The data can be used by a broader audience, including policymakers, practitioners, and researchers outside of the original researcher’s team.\n\nIssues\n\nThere could be risks to participants if they are identifiable, e.g., they might not be ‘out’ as LGBTQ+ or want people beyond the research study to know this information.\nThematic analysis usually uses short quotes from interviews. Making the full interviews open and accessible can increase the likelihood of participants being identified.\nParticipants only gave consent for their data to be used in this study, and did not have the opportunity to consent to their data being shared openly.\nVideo recordings were made, but these are even more likely to make participants identifiable so likely shouldn’t be shared.\nWill participants be less likely to discuss their experiences if they know the data will be open?\n\n  \n\n\n\nHow can qualitative researchers overcome these challenges when planning their studies?\nWe hope the suggestions in this section have helped you think about this. Qualitative researchers should consider using a data management plan(From FORRT Glossary) A structured document that describes the process of data acquisition, analysis, management and storage during a research project. It also describes data ownership and how the data will be preserved and shared during and upon completion of a project. at research inception, carefully anonymising their data, licensing the data or only making the data available to other researchers on request, getting consent from participants for open data up-front.\nJust as quantitative researchers aspire to make their research repeatable, for qualitative researchers, a bit of forward planning is important to make studies as transparent as they can be.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Transparency: As open as possible</span>"
    ]
  },
  {
    "objectID": "Week2.html#quiz-2",
    "href": "Week2.html#quiz-2",
    "title": "2  Transparency: As open as possible",
    "section": "2.8 Quiz 2",
    "text": "2.8 Quiz 2\nThis quiz covers concepts underlying the principle of transparency. See how much you have learned, and please read our feedback too.\n\n\n\nWhat is the definition of open data and materials in research? (Select one)\n\n\nData and materials that can only be accessed by researchers involved in the studyData and materials that are shared only with collaborators of the research projectData and materials that are freely available for anyone to use, reuse, and redistributeData and materials that are accessible only through subscription-based services with a fee\n\n\n\nAnswers:\n\nData and materials that can only be accessed by researchers involved in the study False\nData and materials that are shared only with collaborators of the research project False\nData and materials that are freely available for anyone to use, reuse, and redistribute True\nData and materials that are accessible only through subscription-based services with a fee False\n\n\n\n\n\n\nWhich of the following are most likely to be benefits of sharing your research data and materials? (Select one or more)\n\n\nIt allows others to reproduce analyses reported in a paper and expand on themIt provides checks on the quality and accuracy of research findingsIt gives publicity to your participants’ messagesIt makes the analysis easierIt enables secondary data analysis addressing different research questions\n\n\n\nFeedback: Publicising participants’ issues is unlikely to be a benefit, and could pose a risk to participants unless the release of information has been carefully agreed. Open research is just as rigorous as any other research – arguably more so, since your methods are potentially open to wider scrutiny!\n\nIt allows others to reproduce analyses reported in a paper and expand on them True\nIt provides checks on the quality and accuracy of research findings True\nIt gives publicity to your participants’ messages False\nIt makes the analysis easier False\nIt enables secondary data analysis addressing different research questions True\n\n\n\n\n\n\nWhat does the phrase ‘as open as possible, as closed as necessary’ mean in the context of open data? (Select one)\n\n\nResearchers should keep their data and materials closedResearchers should make all data and materials completely openResearchers should make their data open only if they have toResearchers should make data open within ethical and legal constraints\n\n\n\nAnswers:\n\nResearchers should keep their data and materials closed False\nResearchers should make all data and materials completely open False\nResearchers should make their data open only if they have to False\nResearchers should make data open within ethical and legal constraints True\n\n\n\n\n\n\nWhich of the following is most likely to be a challenge when sharing qualitative research data? (Select one or more)\n\n\nManaging ethical considerations related to participant consentEnsuring results are repeatableBalancing openness with potential risks to participants’ privacyEnsuring participant anonymity and confidentiality\n\n\n\nFeedback: Ensuring results are repeatable is more likely to be a challenge for quantitative researchers.\n\nManaging ethical considerations related to participant consent True\nEnsuring results are repeatable False\nBalancing openness with potential risks to participants’ privacy True\nEnsuring participant anonymity and confidentiality True\n\n\n\n\n\n\nCan participants be identifiable in both quantitative and qualitative data? (Select one)\n\n\nNo, neitherNo, only qualitativeYes, both quantitative and qualitativeNo, only quantitative\n\n\n\nFeedback: Yes, both quantitative and qualitative. But only if the participants have given their consent!\n\nNo, neither False\nNo, only qualitative False\nYes, both quantitative and qualitative True\nNo, only quantitative False",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Transparency: As open as possible</span>"
    ]
  },
  {
    "objectID": "Week2.html#summary",
    "href": "Week2.html#summary",
    "title": "2  Transparency: As open as possible",
    "section": "2.9 Summary",
    "text": "2.9 Summary\nIn this week, you learned about transparencyThe principle of transparency in research refers to the practice of being open and honest about all aspects of the research process. in research, particularly focusing on open data and materials. You learned about the benefits of sharing data and materials, and practical ways you can share your materials. You learned about some of the nuances of different data across disciplines, and the importance of protecting participant anonymity and complying with legal regulations.\nIn Week 3 you will learn about integrity. You will discover the ‘replication crisis’(From FORRT Glossary) The finding, and related shift in academic culture and thinking, that a large proportion of scientific studies published across disciplines do not replicate (e.g. Open Science Collaboration, 2015). This is considered to be due to a lack of quality and integrity of research and publication practices, such as publication bias, QRPs and a lack of transparency, leading to an inflated rate of false positive results. Others have described this process as a “Credibility revolution” towards improving these practices. ‘replication crisis’ which is gripping parts of the research community, explore some questionable research practices, and learn how to find out whether the results of your research can be applicable to a wider context.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Transparency: As open as possible</span>"
    ]
  },
  {
    "objectID": "Week3.html",
    "href": "Week3.html",
    "title": "3  Integrity: Challenging questionable research practices",
    "section": "",
    "text": "3.1 Replicability\nIn Week 1, we broke down the idea of open research into three key facets that make research open: transparency, integrity and accessibility. We’re now going to take a deeper dive into integrity: how trustworthy a study is.\nIn this week, you will learn how to recognise and avoid questionable research practices. You will discover why it is often important to be able to replicate other researchers’ findings, and how to go about doing this. You will experience an important test for the integrity of a piece of research: its .\nThere may be cases where you don’t expect to get the same results if you conduct the same study again. For example, if a study is based around a specific political event, it may be difficult or even impossible to replicate. But in many other types of investigation, we would expect to be able to get the same results when we run the same study again.\nIn Week 2, we talked about reproducibilityA study is reproducible if you are able to get the same results when conducting the same analyses on the same data as the original study. – being able to get the same results when conducting the same analyses on the same data as the original study. ReplicabilityA study is replicable if you are able to conduct the same study again, generate new data, and still get the same results as the original study. is similar, in that it’s about getting the same results as the original study when running the same analyses, however, the difference is that now these analyses are run on new data. So, replication means conducting the same study again, and seeing if you get the same results.\nReplication studies are deliberate attempts to do this. But what does the ‘same study’ mean? There are always going to be differences between the original study and the replication study. Replication studies vary on a spectrum from ‘direct’ to ‘conceptual’. Direct replicationsA type of replication study which aims to stay as close to the original study as possible. try to stay as close to the original study as possible, whereas conceptual replicationsA type of replication study which aims to vary some aspect of the original study, in order to better understand the underlying phenomenon. purposefully vary some aspects to better understand the underlying phenomenon. Here are some examples, from most direct (the first) to most conceptual (the last):\nNow let’s dig deeper into the process of designing a replication study.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Integrity: Challenging questionable research practices</span>"
    ]
  },
  {
    "objectID": "Week3.html#replicability",
    "href": "Week3.html#replicability",
    "title": "3  Integrity: Challenging questionable research practices",
    "section": "",
    "text": "A researcher makes a surprising finding in their research. To test whether they should rely on this result, they conduct a replication immediately after, using all the same materials and the same participant pool.\nA researcher wants to replicate a study they’ve read about. The study is much older (from the 1990s), when open materials were not common. They only have the methods described in the original short paper to refer to, so they interpret these as best they can.\nA researcher wants to replicate a study they’ve read about. They don’t think the original study was well-designed, but they think the hypothesis is interesting so they design a new study testing the same hypothesis but in a different way.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Integrity: Challenging questionable research practices</span>"
    ]
  },
  {
    "objectID": "Week3.html#replication-studies",
    "href": "Week3.html#replication-studies",
    "title": "3  Integrity: Challenging questionable research practices",
    "section": "3.2 Replication studies",
    "text": "3.2 Replication studies\nIn the next video, psychologist Priya Silverstein talks about their first forays into conducting a replication study, and lessons learned. As you watch the video, think about what Priya’s results tell us about the process of running a good replication study.\n Download the video\n\n\n\n\n\n\nVideo transcript\n\n\n\n\n\nHi everyone, my name’s Priya Silverstein and I’m a post-doctoral researcher for the Psychological Science Accelerator, and I’m also the author for this course. My pronouns are ‘they, them’.\nAs part of my PhD, I ran my first replication study. It wasn’t meant to be a big part of my PhD, but it ended up being one of the biggest parts!\nI thought that before starting any of my own original research, it would make more sense to start with a replication study. However it wasn’t that simple, so when I ran the replication study, surprisingly, we got a null result, and I was a bit confused about why this might be. So the first thing that I did was I contacted the original researchers to ask them what they thought might be the problem.\nThey got back to me and they said that they thought it was because of some differences between the stimuli, so the things that I’d shown in my study versus the things that they showed in the original. And some of these differences were things I couldn’t have known, because they didn’t outline the specifics of that in their original paper.\nI made some edits to the protocol to the way that I was going to run the study.\nAnd then I thought, okay, now that I’ve had approval from the original authors this new version should be able to replicate the original study. So I ran it again and surprisingly I still wasn’t able to replicate the result.\nErm and so this was quite disappointing, both for me and the original authors, because it meant that I wasn’t able to find the same thing that they did.\nSo… This was my first experience of replications. And you might think that that was enough to put me off doing any more, but instead, quite the opposite. I ended up realising how important replications are.\nSo yeah, ever since starting with that first replication study as part of my PhD, I’ve now kind of made that my specialty.\nMy advice for anyone who would be conducting their own replication study comes from some of the mistakes that I made as part of that first replication study that I did.\nSo my first piece of advice would be to always contact the authors before you begin your replication study.\nI think I was a bit naïve, and thought if I just follow what’s written in the paper then how can I go wrong? But papers don’t have enough space to include everything about a study that you would need to know in order to conduct a good replication.\nSo I’d recommend talking to the original authors, coming to an agreement with them, making sure that they agree that the protocol that you’ve proposed, they would agree that’s a good faith replication attempt of their study.\nAnother thing that I did wrong is that I only collected the same number of participants as in the original study, for my replication, because I thought that was more ‘replication-y’, because it was the same amount of participants as the original. But now, after learning more about both replication studies, but also sample size more generally, I would really recommend to go with a much larger sample than the original study that you’re replicating.\nAnd this is just so that you can be a little bit more sure about what your findings mean. So, in my study, I wasn’t able to replicate the same result as the original authors, but this could just be because the true effect size that’s in the world for that effect that I was looking at might be smaller than what they kind of measured in the original study.\nIf I had used a much larger number of participants, if I still wasn’t able to replicate the study, we could be a bit more sure that it wasn’t just because of low sample size.\nI ran my study just as a normal study where we finished the entire study and then submitted it to a journal for publication. And I was lucky that it was successful in getting published.\nBut it could have been a lot harder for me to publish, which would have been a bit disappointing and taken a lot of time. So what I would recommend instead is submitting any replication study as a registered report.\nA registered report is essentially where your paper gets peer-reviewed before you have collected data. So the peer reviewers say whether your protocol makes sense, recommend any suggested changes, and then once they’ve accepted it, the journal agrees to accept your study, regardless of what the outcome is. So that would be my third piece of advice.\n\n\n\nVideo 2: Conducting a replication study\nWrite your comments on what Priya advises. Allow about 10 minutes. When you are ready, see our comments.\n\n  Show / Hide Discussion \n  \n  \n  Advice from Priya\n  \nPriya suggests getting in touch with the authors of the original study and asking for more detail than a published paper provides. Using a larger sample size increases confidence that your findings do (or don’t) support those of the previous study. Priya also recommends submitting a registered report, to increase your chances of getting published. \n  \n\n\n3.2.1 Limits to replication\nThere are fields and methodologies where the value of replication is hotly debated. For instance:\n\nSome argue that replication should be encouraged in qualitative research, whereas others argue that there are still open questions about whether replication is possible, desirable, or even aligned with the fundamental principles of qualitative research.\nEconomics has had a long history with replication studies, but not under this name. In economics, replication often takes place as ‘robustness checks’, where researchers test if their results hold when they use different datasets.\nResearch in the humanities is primarily interpretive and context-specific, focusing on understanding human experiences, cultures, texts, and historical events. This interpretive nature makes exact replication more challenging.\n\nIt is important to think carefully about whether replication makes sense for your field and methodology.\nIf you are working in a field where replication is important, and if your study replicates the one you are trying to replicate, you can be pretty confident about the result.\nBut what does it mean if, like Priya’s first attempts, your study does not replicate? One explanation could be that the original result was a ‘false positiveAn error that occurs when a researcher believes that there is a genuine effect or difference when there is not (e.g. a person has a positive Covid test although they do not have Covid).’ , and so the failed replication is a ‘true negative’. Another explanation is that the replication result was a ‘false negativeAn error that occurs when a researcher believes that there is no effect or difference, when actually there is (e.g. a person has a negative Covid test although they do have Covid).’, and that the original study was a ‘true positive’. It’s also possible that differences between the two studies are responsible for the different results.\n\nActivity 1\nAllow about 10 minutes.\nThis activity relates to our examples of typical direct and conceptual replication studies. By way of reminder:\nResearcher A finds a surprising finding in their research. To test whether they should rely on this result, they conduct a replication immediately after, using all the same materials and the same participant pool. This is a direct replication.\nResearcher B wants to replicate a study they’ve read about. They don’t think the original study was well-designed, but they think the hypothesis is interesting, so they design a new study testing the same hypothesis but in a different way. This is a conceptual replication.\nNow imagine these two researchers both carry out their studies. List the reasons why each of these two researchers may not replicate the original result.\n\n  Show / Hide Discussion \n  \n  \n  Why were the two researchers unable to replicate the original results?\nYou might have listed: \n\n The original result was a false positive\n The replication result is a false negative\n There are important differences between the original study and the replication study:\n\na. These could be small changes that researchers didn’t think should be important but that turned out to be (e.g.: which brand of a specific chemical was used).\nb. It could be that the replication researcher didn’t realise these were differences because there wasn’t enough detail in the original paper to be able to work out how everything had been done.\nc. The replication researcher might know they’re making a change from the original protocol, but approve this change because theoretically it shouldn’t make a difference to the result.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Integrity: Challenging questionable research practices</span>"
    ]
  },
  {
    "objectID": "Week3.html#the-replication-crisis",
    "href": "Week3.html#the-replication-crisis",
    "title": "3  Integrity: Challenging questionable research practices",
    "section": "3.3 The replication crisis",
    "text": "3.3 The replication crisis\nThis section will highlight some of the issues around replication in quantitative research. Replication is possible in qualitative research, and many qualitative researchers see the value of replication. So if you are a qualitative researcher, this section is still relevant to you. It will allow you to explore key issues faced by quantitative colleagues, learn how to read quantitative research papers more critically, and think about whether these issues could also apply to qualitative research, albeit manifested differently.\nIf we consider relatively direct replications, using the same materials as the original authors but conducted by different researchers, what percentage of published results do you imagine would replicate? It would be tempting to think that most published research findings are true, and therefore that a replication of a published research finding would be pretty likely to find the same result. However, researchers have found these percentages of findings could not be replicated:\n\nPsychology: up to 60%\nCancer biology: up to 55%\nEconomics: up to 40%\nPhilosophy: up to 30%\n\nThe number of studies that could not be replicated was much higher than expected in certain fields, which has led some to refer to this as a ‘replication crisis’.\nWhy is it that so many quantitative studies cannot be replicated? It’s complicated!\nPreviously, you learned the three classifications of failed replications: the original result was a false positive, the replication result was a false negative, or differences between the two studies could have been responsible for the different results. However, these three interpretations are not all as likely as each other. There are ways to try and work out which of these are most likely.\nThe original result being a false positive is more likely than you would think. Researchers often do not publish all the research that they do. As a researcher, there is an incentive to publish papers in ‘high impact’ journals (journals that are regarded highly in the researcher’s discipline, and that publish papers that receive a high number of citations). Historically, it has been harder to publish negative (null) results than positive (statistically significant) results, as journals have prioritised headline-grabbing results that confirm popular or contemporary positions. This has been the case for all journals, but especially high-impact ones.\nThis means that researchers have an incentive to get positive results in their research and can feel disappointed, stressed, and even ashamed if they don’t get a significant result. This can entice them to turn to questionable research practices, to increase the likelihood of a false positive result.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Integrity: Challenging questionable research practices</span>"
    ]
  },
  {
    "objectID": "Week3.html#questionable-research-practices",
    "href": "Week3.html#questionable-research-practices",
    "title": "3  Integrity: Challenging questionable research practices",
    "section": "3.4 Questionable research practices",
    "text": "3.4 Questionable research practices\nYes, you read the end of the previous section correctly. There are questionable research practices that researchers may feel pressurised to use. Here are some examples:\n\nP-hacking(From FORRT Glossary) Exploiting techniques that may artificially increase the likelihood of obtaining a statistically significant result by meeting the standard statistical significance criterion (typically α = .05). : in quantitative research, p-hacking means exploiting techniques that increase the likelihood of obtaining a statistically significant result, for example by performing multiple analyses, or stopping data collection once a significant p-value is reached.\nSelective reporting: when results from research are deliberately not fully or accurately reported, in order to suppress negative or undesirable findings. For example, researchers might run two analyses but only report the one with significant findings, or be selective in what results are included in a report aimed at particular audiences.\nHARK-ingResearchers are HARK-ing if they write papers as if they had a hypothesis they wanted to test in their study, whereas in reality, they made up the hypothesis after seeing the results.: is a shortening of ‘hypothesising after the results are known’. This is when researchers write their papers as if they had hypotheses that they then went on to test in their study, when really they made up the hypothesis after seeing their results, to pick one that best fit.\nPost-hoc justificationsResearchers write up justifications for their actions after a study; these justifications were not planned or decided before the study happened.: means stating, after the fact, justifications for decisions made during the research project. For example, if the researcher only managed to recruit women for a study after trying to recruit all genders, but claimed in the paper that this was intentional.\n\nAlthough pressures to publish can sometimes be seen as barriers to transparency, the benefits of writing transparently can also be seen as a positive incentive, as the next section shows.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Integrity: Challenging questionable research practices</span>"
    ]
  },
  {
    "objectID": "Week3.html#writing-transparently",
    "href": "Week3.html#writing-transparently",
    "title": "3  Integrity: Challenging questionable research practices",
    "section": "3.5 Writing transparently",
    "text": "3.5 Writing transparently\nWhen writing manuscripts, researchers should aim to be as transparent as possible, being honest about what happened in the study, how it was conducted, and when and why decisions were made. By using questionable research practices, researchers make it more likely that they get a false positive result, which can partially explain low replicability rates.\nIn the video, Priya introduced another important consideration for evaluating replication results: sample size (the number of samples in your study, e.g. participants). Smaller sample sizes make it more likely to get both a false positive and a false negative result. This is because smaller sample sizes provide less information about the population you are studying, which increases the variability and uncertainty in your results. With a small sample, the random variation (or ‘noise’) can more easily overshadow the true effect you are trying to measure. This means you might detect an effect that isn’t really there, a false positive, or miss an effect that actually exists, a false negative.\nFor instance, imagine trying to judge the average height of a population by looking at just a few individuals. Your estimate is more likely to be off compared to measuring a larger group, because you may happen to have either a very tall or very short person in your sample. So, if you have an original study with a small sample size and a (well-designed) replication with a large sample size, you could be more confident in the result of the replication than the result of the original study.\n\nActivity 2: What not to do!\nAllow about 10 minutes.\nSo far, you have considered good and bad writing practices. With these in mind, have a go at this ‘hack your way to scientific glory’ activity. First, choose a political party: Republican or Democrat (UK equivalents: Conservative or Labour). Then predict whether the party has a positive or negative impact on the economy. When you have done that, change aspects of the research (e.g. participant inclusion criteria and how you’re measuring your dependent variable) and see whether you can find a significant result (p &lt; 0.05) in your predicted direction.\nThe reason this is an example of ‘what not to do’ is because when you first choose a political party and predict whether they will have a positive or negative impact on the economy, you are forming a hypothesis. But, if you then play around with the data until you get the result that you wanted, and only stop when you do, then you are fixing the result.\nThe activity involves various questionable research practices, such as P-hackingIn quantitative research, exploiting techniques that increase the likelihood of obtaining a statistically significant result., HARK-ingResearchers are HARK-ing if they write papers as if they had a hypothesis they wanted to test in their study, whereas in reality, they made up the hypothesis after seeing the results., selective reportingResearchers are selective reporting if their results are deliberately not fully or accurately reported, in order to suppress negative or undesirable findings.. However, there is a way to do different analyses on the same data without any of these being a problem. If instead of deciding on a hypotheses first then confirming it, you were to conduct purely exploratory research (without a hypothesis) you could be transparent about all of the different ways you looked at the data and how the results differed when you tried different things. This could even lead to people conducting their own future studies to confirm your exploratory results!\nWhen reading an academic paper, it’s important to read with a critical mindset and feel free to disagree with the methodological or analysis strategy, the interpretation of the results, or the conclusions drawn. Although we know that there are rare instances of outright fraud in science, we would expect that the researchers are truthfully describing what happened in the study, how it was conducted, and when and why decisions were made.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Integrity: Challenging questionable research practices</span>"
    ]
  },
  {
    "objectID": "Week3.html#generalisability",
    "href": "Week3.html#generalisability",
    "title": "3  Integrity: Challenging questionable research practices",
    "section": "3.6 Generalisability",
    "text": "3.6 Generalisability\nYou have learned that replication studies vary on a spectrum from ‘direct’ to ‘conceptual’. However, most replication studies have some differences from the original study, even if these weren’t intentional. Consider one of the examples from before, where a researcher was replicating a paper from the 1990s. The materials they create will be different from the original materials, and if what they’re studying is context-dependent, a lot might have changed since then.\nFor example, a study on internet usage habits conducted in the 1990s would yield very different results if replicated today, due to the dramatic changes in technology and how people use the internet. Similarly, a study examining public attitudes toward mental health in the 1990s might produce different findings now because societal awareness and acceptance of mental health issues have evolved significantly over the past few decades.\nFor this reason, some consider that most replication studies are actually generalisability studies. GeneralisabilityThe extent to which the findings of a study can be generalised to other situations, beyond the specific participants and conditions of the study.means whether a particular result generalises beyond the specific participants and conditions of the study to broader groups of samples, settings, methods, or measures. For example, if we’re interested in public attitudes to mental health, it wouldn’t make sense for us to only ask people aged 50-60, or only men, or only those living in cities. It’s possible that any of these characteristics could affect people’s opinions on mental health, meaning the results would be biased and not representative of the full population.\nWithout generalisability studies, it might be possible that the theoretical explanation for why the finding occurred might be incorrect. For example, there could even be a mistake in the design of the study that biased the results. For instance, imagine a biological study investigating the effects of a new drug using a specific strain of lab mice. If this particular strain has a unique genetic mutation that makes it respond differently to the drug compared to other strains, the study’s results might not generalize to other mice or to humans. This could lead to an incorrect conclusion about the drug’s overall effectiveness and safety.\nResearchers wishing to be transparent when writing their papers should declare possible ‘Constraints on generalityA statement identifying populations sampled in the study and potential limits to the samples and methods, enabling others to assess the extent to which results can be generalised.’ in the discussion section. This could take the form of a statement that identifies and justifies the target populations for the reported findings, and other considerations the authors think would be necessary for replicating their result. This could help other researchers to sample from the same populations when conducting a direct replication, or to test the boundaries of generalisability when conducting a conceptual replication.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Integrity: Challenging questionable research practices</span>"
    ]
  },
  {
    "objectID": "Week3.html#studying-generalisability",
    "href": "Week3.html#studying-generalisability",
    "title": "3  Integrity: Challenging questionable research practices",
    "section": "3.7 Studying generalisability",
    "text": "3.7 Studying generalisability\nSo you think your research has potential do good in the world, but don’t know how widely it can be applied? There are lots of different ways to study generalisability:\n\nSystematic reviews: these look at how an outcome varies in the published literature across samples, settings, measures and methods (meta-analyses do this statistically). This can be done without conducting any new studies.\nFor example, UNICEF’s Evidence and Gap Map Research Briefs provide an overview of available evidence of the effectiveness of interventions to improve child well-being in low- and middle-income countries.\n\nComparative studies: comparing results from different populations using the same (adapted) materials can show where there may be similarities and differences. For example, Hofstede’s cultural dimensions theory, which identified and measured cultural differences across countries, particularly in the workplace context. Big team science Big team scienceA research project in which researchers from around the world conduct the same study and pool their results.: when researchers from around the world conduct the same study and pool their results, they can look at various factors affecting the presence or size of the effect they’re interested in. For example, the first ManyGoats project is examining goat responses to different human attentional states, and will be testing a diverse range of goats in different living conditions.\n\nActivity 3\nAllow about 10 minutes.\nThink about a study in your field that would or wouldn’t generalise. Consider why this might be the case.\nTake some notes of your thoughts first, and see our discussion.\n\n  Show / Hide Discussion \n  \n  \n  Why a study may or may not generalise\nThere are lots of reasons why a study may or may not generalise. Imagine a study evaluating a new therapy for depression in a university clinic with primarily urban-based participants.\n\nWhile the therapy showed significant improvement in depressive symptoms over ten weeks among a diverse sample, including college students and middle-aged adults of various ethnicities recruited through local health centres and university channels, its applicability to other populations and settings may be limited. Factors such as regional differences in mental health resources, demographic diversity beyond the studied age groups, and recruitment biases could affect the therapy's effectiveness in rural or suburban areas and among older adults or adolescents.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Integrity: Challenging questionable research practices</span>"
    ]
  },
  {
    "objectID": "Week3.html#quiz",
    "href": "Week3.html#quiz",
    "title": "3  Integrity: Challenging questionable research practices",
    "section": "3.8 Quiz",
    "text": "3.8 Quiz\nThis self-test quiz tackles key ideas in replication and the principle of generalisability.\n\n\n\nWhat is the difference between replicability and reproducibility? (Select one)\n\n\nReplicability refers to getting different results when running the same analyses on new data, while reproducibility refers to getting the same results when conducting different analyses on the same data.Replicability refers to getting the same results when running the same analyses on new data, while reproducibility refers to getting the same results when conducting the same analyses on the same data.There isn’t a difference.Replicability refers to getting the same results when conducting the same study again, while reproducibility refers to getting different results when conducting the same study again.\n\n\n\nAnswers:\n\nReplicability refers to getting different results when running the same analyses on new data, while reproducibility refers to getting the same results when conducting different analyses on the same data. False\nReplicability refers to getting the same results when running the same analyses on new data, while reproducibility refers to getting the same results when conducting the same analyses on the same data. True\nThere isn’t a difference. False\nReplicability refers to getting the same results when conducting the same study again, while reproducibility refers to getting different results when conducting the same study again. False\n\n\n\n\n\n\nWhich of the following is an example of a conceptual replication? (Select one)\n\n\nA researcher designs a study to explore how mental concepts replicate themselves.A researcher designs a new study testing the same hypothesis but in a different way because they believe the original study was not well-designed.A researcher replicates a study from the 1990’s using only the methods described in the original short paper.A researcher conducts a replication immediately after the original study, using all the same materials and the same participant pool.\n\n\n\nAnswers:\n\nA researcher designs a study to explore how mental concepts replicate themselves. False\nA researcher designs a new study testing the same hypothesis but in a different way because they believe the original study was not well-designed. True\nA researcher replicates a study from the 1990’s using only the methods described in the original short paper. False\nA researcher conducts a replication immediately after the original study, using all the same materials and the same participant pool. False\n\n\n\n\n\n\nWhy might a replication study fail to replicate the original result? (Select one or more)\n\n\nanswer = “The original result was a false positive.answer = “The differences between the two studies are responsible for the different results.answer = “The replication result was a false negative.The replication study was a waste of time.\n\n\n\nFeedback: All of these are possible causes for failure to replicate. Far from being a waste of time, a failure to replicate can provide very useful information.\n\nThe original result was a false positive. True\nThe differences between the two studies are responsible for the different results. True\nThe replication result was a false negative. True\nThe replication study was a waste of time. False\n\n\n\n\n\n\nWhich of the following is the best way for researchers to study generalisability? (Select one)\n\n\nBy re-running the original analyses from a piece of research.By comparing results from different populations using the same materials.By conducting direct replications with the same materials and participant pool.By using questionable research practices.\n\n\n\nAnswers:\n\nBy re-running the original analyses from a piece of research. False\nBy comparing results from different populations using the same materials. True\nBy conducting direct replications with the same materials and participant pool. False\nBy using questionable research practices. False\n\n\n\n\n\n\nWhich of the following explanations are most likely if the result of an original study which suggested an effect to be ‘true’, is not replicated in a replication study? (Select one or more)\n\n\nThe original researcher was fraudulent.The original effect might be ‘true’, but only under very narrow conditions.The replication study might have had too small a sample size to find a result.The original study cannot possibly have been a ‘true’ result, because it did not replicate.\n\n\n\nFeedback: The other two cannot be deduced from the information provided in the question.\n\nThe original researcher was fraudulent. True\nThe original effect might be ‘true’, but only under very narrow conditions False\nThe replication study might have had too small a sample size to find a result False\nThe original study cannot possibly have been a ‘true’ result, because it did not replicate True",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Integrity: Challenging questionable research practices</span>"
    ]
  },
  {
    "objectID": "Week3.html#summary",
    "href": "Week3.html#summary",
    "title": "3  Integrity: Challenging questionable research practices",
    "section": "3.9 Summary",
    "text": "3.9 Summary\nIn this week, you learned about an important aspect of integrity: replicabilityA study is replicable if you are able to conduct the same study again, generate new data, and still get the same results as the original study.. Replicability relates to whether or not a study ‘replicates’, i.e. whether or not, when you repeat the study with new data, you get the same result. You learned some reasons why replicability may be low in many fields, and how differences between studies may sometimes contribute to this. You also learned about the importance of generalisability in research. Next week, you’ll learn techniques which can support both the integrity and the transparency of your research.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Integrity: Challenging questionable research practices</span>"
    ]
  },
  {
    "objectID": "Week4.html",
    "href": "Week4.html",
    "title": "4  Documenting Decisions Transparently",
    "section": "",
    "text": "4.1 Preregistration: publishing your plans for a study\nThis week is about ways to make your research more transparent. As you discovered earlier, transparency means being clear about exactly what you did at every stage of your research. However, over the course of an entire research project (typically months to years), it’s highly likely that you will forget certain aspects of how the study was conducted, and when and why decisions were made.\nOne of the most important ways you can make sure that others will be able to replicate your research is by keeping detailed records of all aspects of the project, and updating them as you go. It’s a bit like keeping a record of the twists and turns you made while going through a maze. Without detailed notes, remembering all the decisions you made at every stage of your research project can be difficult. You will build up a lot of information, which can be hard to compile once you get to the writing stage.\nThe most important distinction is whether decisions were made before or after data collection begins. This is because when researchers are able to look at the data they can be swayed by what they see. PreregistrationThe practice of publishing the plan for a study, including research questions or hypotheses, research design, and data analysis plans, before the data has been collected or examined. (or RegistrationSome disciplines differentiate between preregistration and registration, but the broad purpose is often similar. in some fields) is the practice of publishing the plan for a study, including research questions, hypotheses(From FORRT Glossary) A hypothesis is an unproven statement relating the connection between variables (Glass & Hall, 2008) and can be based on prior experiences, scientific knowledge, preliminary observations, theory and/or logic. In scientific testing, a hypothesis can be usually formulated with (e.g. a positive correlation) or without a direction (e.g. there will be a correlation). Popper (1959) posits that hypotheses must be falsifiable, that is, it must be conceivably possible to prove the hypothesis false., research design, and data analysis plans before the data has been collected or examined.\nA preregistration document is time-stamped and typically registered with an independent party (e.g., an open access repository) so that it can be publicly shared with others. Preregistration provides a transparent documentation of what was planned at a certain time and allows third parties to assess what changes may have occurred afterwards. Importantly, it’s fine for changes to occur, it’s just important to know when and what these were, and why these changes were made.\nHaving a more detailed preregistration leaves fewer research degrees of freedomThe flexibility inherent in research, from hypothesis generation, designing and conducting a research study, to processing and analysing the data and interpreting and reporting results.. In other words, the more detailed a preregistration is, the better third parties can assess any possible changes and how they may affect confidence in the results.\nOne platform for preregistering research is the Open Science Framework (OSF). On the OSF there are support videos and documentation to guide you through the process. You can use a variety of templates depending on your discipline and methodology to preregister your study in varying levels of detail. These templates include:\nIf none of the available templates suit you, you can write your own document and preregister this in an open-ended preregistration!",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Documenting Decisions Transparently</span>"
    ]
  },
  {
    "objectID": "Week4.html#preregistration-publishing-your-plans-for-a-study",
    "href": "Week4.html#preregistration-publishing-your-plans-for-a-study",
    "title": "4  Documenting Decisions Transparently",
    "section": "",
    "text": "Standard OSF template (good for most science disciplines)\nSystematic Reviews(From FORRT Glossary) A form of literature review and evidence synthesis. A systematic review will usually include a thorough, repeatable (reproducible) search strategy including key terms and databases in order to find relevant literature on a given topic or research question. Systematic reviewers follow a process of screening the papers found through their search, until they have filtered down to a set of papers that fit their predefined inclusion criteria. These papers can then be synthesised in a written review which may optionally include statistical synthesis in the form of a meta-analysis as well.\nSocial Psychology\nQualitative\nSecondary Data\n\n\n\n4.1.1 Confirmatory vs explanatory analysis\nConfirmatory analysesAnalyses set before data collection or examination; their role is to test hypotheses. refer to analyses that were set before data collection or examination, and that test whether a hypothesis is supported by the data. Exploratory analysesAnalyses set after an initial data set and hypothesis have been generated; they are useful for discovering patterns in data, in order to foster hypothesis development and refinement. are carried out when some data have already been collected. They are useful for discovering patterns in that data or extending to new topics or subjects. They foster hypothesis development and refinement.\nPreregistration often aims to clearly distinguish confirmatory from exploratory analyses. This is helpful because you won’t be able to convince yourself (or others) that you had hypotheses before you saw your data, when actually you added these ‘post-hoc’, after seeing the results.\nIf you are thinking of preregistering either type of research, here are some things to consider:\n\nBoth quantitative and qualitative research can be confirmatory, and so preregistration for confirmatory research can be used for both.\nFor exploratory research, preregistration can be a great way to document initial study plans, even if those later change through an iterative process.\nPreregistering exploratory studies can be useful for both quantitative and qualitative research, for all disciplines.\nIf your discipline has another good way of keeping track of how study plans change over the course of the research, then this could also work well instead of preregistration.\n\nIt is important to distinguish between confirmatory and exploratory analysis so that results can be interpreted accordingly.\n\n\n4.1.2 How to approach preregistration\nWhether your work is confirmatory or exploratory, preregistering keeps a permanent record of your ideas at the design stage, before you start the analysis.\nThe process of preregistering involves answering a series of questions about your research. There are many templates of preregistration forms available. In the next activity, we will walk you through some typical questions.\nWhen answering the questions, you should aim to be as precise and detailed as possible. By doing this, you are being transparent about your research plans from the outset. The benefits include establishing a clear and detailed plan for your research, that you can revisit and update as you make your way through your research project.\nA detailed and comprehensive preregistration demonstrates that you haven’t engaged in the questionable research practices that you learned about in the last week, and can be useful for reviewers and readers when they assess the integrity of your research.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Documenting Decisions Transparently</span>"
    ]
  },
  {
    "objectID": "Week4.html#preregistration-activity",
    "href": "Week4.html#preregistration-activity",
    "title": "4  Documenting Decisions Transparently",
    "section": "4.2 Preregistration activity",
    "text": "4.2 Preregistration activity\nAllow about 30 minutes.\n Time to get your notebook ready.\nIn the activity below, you will gain experience of the type of information you will need to provide when preregistering a research project. Please answer the questions based on one of your existing research projects, or a project you would like to do in the future.\n1.1 What is your research project title?\n\n  Show / Hide Discussion \n  \n  \nThe title of your research project should, in ten to fifteen words, provide an informative description of the research being reported. When coming up with the title you might want to think about the variables, the design of the study, and the key findings of your research project.\n  \n\n1.2 Who is contributing to this research?\n\n  Show / Hide Discussion \n  \n  \nIf you are collaborating with people on this research project, you can list their names and affiliations here. Declaring these provides contextual information about your research, and the academic perspectives the people in your team are likely to bring to it.\n  \n\n1.3 Have any data been collected for this study already?\nThis question concerns whether you have already collected data. There are three possible options: select the one that best describes the stage you are at with your research, write your own notes on further details, then click ‘Show / Hide Discussion’ to see our comments.\n\na) Yes, at least some data has been collected for the study already.\n\n\n  Show / Hide Discussion \n  \n  \nYou may need to explain how much exposure to the data you've had: the general rule of thumb is the less involvement you’ve had with the data, the better. However this does depend on your project, and preregistration can still protect you from questionable research practices, even if some data has already started to come in.\n  \n\n\nb) No, no data have been collected for the study already.\n\n\n  Show / Hide Discussion \n  \n  \nGreat! When you are preregistering, the general rule of thumb is the less involvement you’ve had with data, the better. That way, you won’t be tempted to add post hoc justifications after you’ve seen the results.\n  \n\n\nc) It’s complicated because we have already collected some data or are using secondary data.\n\n\n  Show / Hide Discussion \n  \n  \nIf you select this third option, you’ll need to explicitly state how, and to what capacity, you’ve been exposed to the data previously. When you are hoping to preregister, the general rule of thumb is the less involvement you’ve had with the data, the better, but a project that involves secondary data is a good example of how preregistration can still be valuable, even when a lot of data already exists.\n  \n\nNow let’s continue our walk through preregistration. The next question gets to the heart of the matter: what your research is about. You need to be clear and concise in your responses, so that when you return to your preregistration document, it will clearly encapsulate what your plans were at this point in time.\n1.4 What is the main question being asked, or hypothesis being tested in the study?\n\n\n\n\n\n\nTip\n\n\n\nAs you write your notes on your research question, here are some tips to help with your responses:\nYour research questions should be specific. If you have more than one hypothesis(From FORRT Glossary) A hypothesis is an unproven statement relating the connection between variables (Glass & Hall, 2008) and can be based on prior experiences, scientific knowledge, preliminary observations, theory and/or logic. In scientific testing, a hypothesis can be usually formulated with (e.g. a positive correlation) or without a direction (e.g. there will be a correlation). Popper (1959) posits that hypotheses must be falsifiable, that is, it must be conceivably possible to prove the hypothesis false., you need to write multiple statements (one per hypothesis). It is helpful to write hypotheses in bulleted or numbered format: this forces you to be concise. If you are doing quantitative research, you should also state whether your hypothesis predicts a certain direction and if so what that direction is.\n\n\n\n  Show / Hide Discussion \n  \n  \nYour response will vary according to your discipline and style of research. Try to ensure the research question or hypothesis is as focused as possible. Use simple language and avoid ambiguity. Here is an example:\n\nResearch question: Can we replicate the findings of Yoon, Johnson and Csibra \\[PNAS, 105, 36 (2008)\\] that nine-month-old infants retain qualitatively different information about novel objects in communicative and non-communicative contexts?\n\nHypothesis 1: In a communicative context (‘ostensive pointing’), infants will mentally process the identity of novel objects at the expense of mentally processing their location. We would expect longer looking times for changed objects than changed location.\n\nHypothesis 2: In a non-communicative context (‘non-ostensive reaching’), infants will mentally process the location of novel objects at the expense of encoding their identity. We would expect longer looking times to changed location than changed identity.\n\n\n\nNext, you’ll be asked questions about the design of your study. The first of these questions relates to quantitative research. If your research is not quantitative, you may wish to go to question 6 directly.\nThese are some questions you might want to ask yourself when answering: - What are your independent variablesIn a scientific experiment design, this is the variable that the researcher manipulates in order to investigate its effect. and your dependent variableIn a scientific experiment design, this is the variable that changes as a result of an intervention; the researcher is interested in recording these changes.? How do these variables relate to each other? - How will they be measured (a self-scale report, a behavioural task)? - What is your sample size and criteria? - How did you determine your sample size? - Do you have a Between, within or mixed study designA between study design compares different conditions between groups, a within design compares different conditions within the same group, and a mixed study combines the two.? - Are you using counterbalancingA technique used by psychologists to deal with order effects when conducting repetitive tests, giving half the participants the tests in one order, the other half in the reverse order.?\n1.5. Describe the design, key variables, and sample, specifying how they will be measured and collected.\nIn your notes, reflect on why you think this information is important for preregistration.\n\n  Show / Hide Discussion \n  \n  \nYour response will vary according to your discipline and style of research. Here’s one example:\nIndependent variable: Our study investigates two conditions: communicative (ostensive pointing) and non-communicative (ostensive reaching).\n\nDependent variable: Duration of first looks and total looking time, measured using a Tobii eye-tracker. We may also hand-code looking offline (blind) to increase confidence in our results.\n\nDesign: Previous research has only found a significant effect for duration of first look, so we only predict differences in this. However, we are still including total looking time: although previous research data were not significant for this variable, they appear to be in the predicted direction.\n\nMeasurement: Duration from first video frame when object is revealed to when infant first looks off-screen.\n\nSampling: We will run the study until twenty four infants that meet the criteria for the experiment have been tested. This will exclude excessive fussiness preventing completion of study or resulting in uncodable eye movement, experimenter and equipment error, caretaker interference, or infants looking off-screen.\n\n\nIf your research is qualitative, you will also be asked to specify exactly how you plan to conduct your research, although your answers are likely to be a little different.\nFor instance, you might be interested in the experience of parenting a child prodigy. How will you approach the task? With a questionnaire? An interview? A focus group? Open or closed questions? Or supposing you are interested in changes in depictions of families through the twentieth century. What evidence will you use? Newspapers and magazines? Archive photographs? How will you analyse them? Discourse analysis? Visual analysis?\n1.6. Describe the study design and how data will be sampled and collected.\nAs you write your own notes documenting your design and data collection plan, here are some tips to help with your responses:\n\n\nWhat methodologies are you using, e.g.: case study, ethnography?\nWhat is your sampling, recruiting or case selection strategy?\nWhat type of data are you interested in, and what is your method for collecting or generating the data?\nYou may also want to describe tools, instruments, plans or schedules (e.g.: interview schedule or archival search plan)?\nWhat criteria need to be reached in order to stop data collection or generation?\n\n\n\n  Show / Hide Discussion \n  \n  \nYour response will vary according to your discipline and style of research. But asking yourself questions like this helps to focus on what you want to know, and how you will be exploring it. Here is one example of a preregistered qualitative study.\n  \n\nWe hope this activity has helped you feel confident about your next preregistration. These questions have concentrated on your methodology plan, but you will also need to provide information about your analysis plans. We will explore the analysis stage in more detail in the next week.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Documenting Decisions Transparently</span>"
    ]
  },
  {
    "objectID": "Week4.html#reporting-guidelines",
    "href": "Week4.html#reporting-guidelines",
    "title": "4  Documenting Decisions Transparently",
    "section": "4.3 Reporting guidelines",
    "text": "4.3 Reporting guidelines\nWe’ve talked about preregistration as a way to be transparent before you collect your data. How about once you’ve collected your data and are writing up your research? You should be honest about how you conducted your study, and anything that has changed since you planned (and perhaps preregistered) it. One way of being transparent when writing up your research is to use reporting guidelines.\nReporting guidelines are sets of rules or standards that help researchers present their findings clearly and transparently. They’re like a checklist that ensures all-important information about a study is included in a research paper. These guidelines vary depending on the type of study or field of research, but they generally help researchers communicate their methods, results and conclusions effectively, making it easier for others to understand and evaluate their work.\nHere are some reporting guidelines for different fields:\nSTROBE (STrengthening the Reporting of OBservational studies in Epidemiology)\n\nSTROBE provides a checklist to enhance the reporting of observational studies in epidemiology, encompassing key aspects such as study design, participant selection, data collection methods, and statistical analysis.\n\nCOREQ (COnsolidated criteria for REporting Qualitative research)\n\nCOREQ provides a checklist of items that researchers should address when reporting qualitative research, covering aspects such as study design, data collection, analysis, and interpretation.\n\nEQUATOR (Enhancing the QUAlity and Transparency Of health Research)\n\nEQUATOR provides a variety of reporting guideline templates for various branches of health research, including reporting guidelines for randomised trials, observational studies, systematic reviews, qualitative research, animal studies, economic evaluations, and more.\n\nThere are many benefits to using reporting guidelines. Most obviously, they help researchers to clearly and comprehensively communicate all the important information about their study. This is helpful for the researcher themselves, and for anyone else who wants to read, understand, and potentially build upon their work. However, if you’re unable to find reporting guidelines for your particular field, being as transparent as possible and including as much detail as possible is your best bet!\n\nActivity 2\nAllow about 30 minutes.\nIn the activity below, you get the chance to practise writing your own simple set of guidelines.\nImagine that your friend has some very important news to tell you. Create a set of reporting guidelines for them, so that they can make sure to include all relevant information about what happened and the people involved when telling you the news. Fill the reporting guidelines out for the piece of news to make sure the guidelines include everything you would need.\n\n  Show / Hide Discussion \n  \n  \nHere’s an example of what this might look like:\n1. Briefly describe the news: Sanjay is moving to Argentina!\n2. Outline short descriptions of all people involved in this piece of news: Sanjay is a 30-year-old sociology researcher who currently lives in the UK.\n3. Outline important dates relevant to the news: Sanjay will be moving in September 2026.\n4. Provide any background reasoning for the news: Sanjay has been offered a research job in Argentina.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Documenting Decisions Transparently</span>"
    ]
  },
  {
    "objectID": "Week4.html#applying-open-research-in-your-own-work-the-open-research-decision-tree",
    "href": "Week4.html#applying-open-research-in-your-own-work-the-open-research-decision-tree",
    "title": "4  Documenting Decisions Transparently",
    "section": "4.4 Applying open research in your own work: The open research decision tree",
    "text": "4.4 Applying open research in your own work: The open research decision tree\nSo far, you have learned a lot about the principles of open research and how they are applied. You may be planning to begin incorporating open research practices into your own research immediately, or perhaps you will want to do so in the future. To help you navigate more quickly to the information you need, the course team have developed an open research decision tree. This has been developed as a companion to the course helps you remind yourself of the principles of open research, and how to take open research actions.\n Write down your thoughts:\n\nIn what ways are these principles Transparency, Integrity, Accessibility connected to your work, or your field?\nWhat actions can you plan for your research to ensure replicability?",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Documenting Decisions Transparently</span>"
    ]
  },
  {
    "objectID": "Week4.html#quiz-4",
    "href": "Week4.html#quiz-4",
    "title": "4  Documenting Decisions Transparently",
    "section": "4.5 Quiz 4",
    "text": "4.5 Quiz 4\n\n\n\nWhat is preregistration in the context of research? (Select one)\n\n\nRegistering for a research conferenceSubmitting a research proposal for fundingPublishing the final report of a studyDocumenting the plan for a study\n\n\n\nFeedback: Preregistration documents the plan for a study. This is usually before data have been collected, but it can be done after data collection, or when you are using data that already exist (secondary data).\n\nRegistering for a research conference Incorrect\nSubmitting a research proposal for funding Incorrect\nPublishing the final report of a study Incorrect\nDocumenting the plan for a study Correct\n\n\n\n\n\n\nWhich are the most important benefits of preregistration? (Select one or more)\n\n\nIt can facilitate collaborationIt guarantees funding for the studyIt provides transparent documentation of planned researchIt allows for more flexible research designsIt ensures data privacy\n\n\n\nFeedback: Providing a transparent documentation of planned research means that others can know when certain decisions about the research were made, and can assess any changes from your original plan.\n\nIt can facilitate collaboration Correct\nIt guarantees funding for the study Incorrect\nIt provides transparent documentation of planned research Correct\nIt allows for more flexible research designs Incorrect\nIt ensures data privacy Incorrect\n\n\n\n\n\n\nWhy is it important to distinguish between confirmatory and exploratory analyses? (Select one)\n\n\nTo enhance the complexity of the researchTo limit the scope of the studyTo clarify which analyses were pre-planned and which were data-drivenTo determine the funding sources for each analysis\n\n\n\nFeedback: Differentiating between which analyses were pre-planned and which were data-driven means that you won’t be able to convince yourself (or others) that you had hypotheses before you saw your data, when actually you thought of these explanations after seeing the results. This helps you avoid questionable research practices.\n\nTo enhance the complexity of the research Incorrect\nTo limit the scope of the study Incorrect\nTo clarify which analyses were pre-planned and which were data-driven Correct\nTo determine the funding sources for each analysis Incorrect\n\n\n\n\n\n\nWhat should researchers do when writing up their research after data collection? (Select one)\n\n\nAlter their preregistered plans to match the resultsMinimise the reporting of unexpected findingsBe honest about how the study was conducted and any changes since preregistrationEnsure all results align with the initial hypotheses\n\n\n\nFeedback: Researchers should always be honest about all aspects of a research project. It’s fine to deviate from your original plans, as long as you explain any changes clearly. You are absolutely free to report unexpected findings and exploratory analyses beyond what you specified in your preregistration, these should just be discussed separately from the preregistered analyses.\n\nAlter their preregistered plans to match the results Incorrect\nMinimise the reporting of unexpected findings Incorrect\nBe honest about how the study was conducted and any changes since preregistration Correct\nEnsure all results align with the initial hypotheses Incorrect\n\n\n\n\n\n\nWhat are reporting guidelines? (Select one)\n\n\n“Instructions for writing literature reviews”“Standards to help researchers present their findings clearly and transparently”“Sets of rules for how to conduct studies”“Regulations for obtaining research grants”\n\n\n\nFeedback: Reporting guidelines outline how you should write up the results of your studies, not how you should conduct your studies. They are another way (like preregistration) or helping researchers to write clearly and transparently about their research.\n\n“Instructions for writing literature reviews” Incorrect\n“Standards to help researchers present their findings clearly and transparently” Correct\n“Sets of rules for how to conduct studies” Incorrect\n“Regulations for obtaining research grants” Incorrect",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Documenting Decisions Transparently</span>"
    ]
  },
  {
    "objectID": "Week4.html#summary",
    "href": "Week4.html#summary",
    "title": "4  Documenting Decisions Transparently",
    "section": "4.6 Summary",
    "text": "4.6 Summary\nIn this week, you have dug deeper into transparency in research – documenting how your study was conducted and when and why decisions were made. You learned about preregistration and reporting guidelines: how these can increase transparency, and potentially help you avoid questionable practices.\nYou were also introduced to the open research interactive decision tree, which you can continue to use throughout the course. You can return to the decision tree after you have finished the course as needed.\nIn Week 5, you’ll move on to consider the trustworthiness or believability of research findings.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Documenting Decisions Transparently</span>"
    ]
  },
  {
    "objectID": "Week4.html#references",
    "href": "Week4.html#references",
    "title": "4  Documenting Decisions Transparently",
    "section": "4.7 References",
    "text": "4.7 References\nEnhancing the QUAlity and Transparency Of health Research (EQUATOR) Network (2024): Reporting guidelines for main study types\nAvailable at: https://www.equator-network.org/\nEnhancing the QUAlity and Transparency Of health Research (EQUATOR) Network (2024): What is a reporting guideline?\nAvailable at: https://www.equator-network.org/ about-us/ what-is-a-reporting-guideline/\nOpen Science Framework (2024): Registrations and preregistrations\nAvailable at: https://help.osf.io/article/ 330-welcome-to-registrations\nSilverstein, P., Gliga, T., Westermann, G., Parise, E. (2019): Probing communication-induced memory biases in preverbal infants: Two replication attempts of Yoon, Johnson and Csibra (2008), Infant Behaviour and Development, 55, 77-87.\nAvailable at: https://doi.org/ 10.1016/ j.infbeh.2019.03.005\nTong, A, Sainsbury, P, Craig, J (2007): Consolidated criteria for reporting qualitative research (COREQ): a 32-item checklist for interviews and focus groups. International Journal for Quality in Health Care, Volume 19, Issue 6, December 2007, 349–357.\nAvailable at: https://doi.org/ 10.1093/ intqhc/ mzm042\nThe Open University (2024): The open research decision tree\nAvailable at: https://www.open.edu/openlearncreate/course/view.php?id=11974\nvon Elm E, Altman D G, Egger M, Pocock S J, Gøtzsche P C, Vandenbroucke J P; STROBE Initiative (2007): The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement: guidelines for reporting observational studies. The Lancet, 370(9596): 1453-7\nAvailable at: https://doi.org/ 10.1016/ S0140-6736(07)61602-X",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Documenting Decisions Transparently</span>"
    ]
  },
  {
    "objectID": "Week5.html",
    "href": "Week5.html",
    "title": "5  Integrity: Supporting robust interpretations",
    "section": "",
    "text": "5.1 Conflicts of interest\nResearchers are human, and humans have their own experiences, perspectives, values, and biases. For this reason, we must be alert to the possibility that any individual researcher’s observations could be influenced by their position.\nIn Week 3, you looked at the principle of integrity in open research: you will finish your consideration of integrity in Week 5. You will learn how to protect yourself from unintended bias, spot the signs of flimsy analysis, and scrutinise the robustness of your own research. By the end of this week, you will have a toolkit of techniques which you can use to support the integrity of your research.\nIt is standard in all types of research to disclose any specific ‘conflicts of interest’ – factors that could make the researcher biased towards particular results. This is common in research projects where money is involved. Would the researcher (or the company funding the researcher) benefit from the results of the research coming out in a particular direction?\nHere are some examples of potential conflicts of interest:\nWhile it is common to disclose conflicts of interest, there are many fields where it isn’t common to consider how our experiences, perspectives, values, and biases might affect our research in a way that is less clear-cut.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Integrity: Supporting robust interpretations</span>"
    ]
  },
  {
    "objectID": "Week5.html#conflicts-of-interest",
    "href": "Week5.html#conflicts-of-interest",
    "title": "5  Integrity: Supporting robust interpretations",
    "section": "",
    "text": "A pharmaceutical company funding a clinical trial for its own drug may create a conflict of interest, if the company stands to benefit financially from positive results.\nA researcher receiving funding from an oil company to study the environmental impacts of drilling may face conflicts of interest, if they are under pressure to downplay negative findings.\nResearchers studying the effectiveness of educational interventions funded by the companies producing those interventions may have conflicts of interest if their findings recommend using the products of those companies.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Integrity: Supporting robust interpretations</span>"
    ]
  },
  {
    "objectID": "Week5.html#positionality",
    "href": "Week5.html#positionality",
    "title": "5  Integrity: Supporting robust interpretations",
    "section": "5.2 Positionality",
    "text": "5.2 Positionality\nPositionalityRefers to the social and political position of an individual within society, including their identity, background, experiences, and beliefs. refers to an individual’s social and political position within society, including their identity, background, experiences, and beliefs. These factors can influence the way researchers perceive and interpret data, potentially impacting the research process and outcomes. Positionality is not always negative – a researcher can also be uniquely positioned to study something because they have a deeper lived understanding of it.\nHere are some positive and negative examples of ways that positionality could influence research:\n\nGender biases among medical professionals may affect the way certain health conditions are studied or treated.\nEconomic researchers’ ideological beliefs and political affiliations can shape their interpretations of data and policy recommendations.\nIndigenous researchers may offer traditional ecological knowledge that complements non-indigenous approaches, leading to innovative conservation strategies.\nAn activist-researcher may use their lived experience of living under a dictatorship when conducting a study on political systems.\n\n\n5.2.1 Positionality statements\nPositionality statements allow readers to assess the positionality of a researcher, and how it might affect their research. They are common in qualitative research, and are starting to be considered in quantitative research, too.\nResearchers can consider including a ‘positionality statement’ in papers, to contextualise themselves and their research environment, and define the boundaries of their research output. This can provide additional context around how the study was conducted, including the researcher’s experiences, perspectives, and potential biases.\nPositionality statements and conflict of interest statements both serve to disclose personal biases or influences that might affect an individual’s work or perspective. However, they differ in scope and intent. Positionality statements focus more heavily on the author’s social and cultural identity factors, such as race, gender, and socioeconomic status, to provide context on how these factors might influence their viewpoint. Conflict of interest statements, on the other hand, disclose financial or personal relationships that could compromise the integrity of one’s work or create a perception of bias. While both aim for transparency, positionality statements address broader socio-cultural influences, whereas conflict of interest statements specifically target potential financial or relational biases.\nQualitative researchers(From FORRT Glossary) Research which uses non-numerical data, such as textual responses, images, videos or other artefacts, to explore in-depth concepts, theories, or experiences. There are a wide range of qualitative approaches, from micro-detailed exploration of language or focusing on personal subjective experiences, to those which explore macro-level social experiences and opinions. often talk about reflexivity(From FORRT Glossary) The process of reflexivity refers to critically considering the knowledge that we produce through research, how it is produced, and our own role as researchers in producing this knowledge. There are different forms of reflexivity; personal reflexivity whereby researchers consider the impact of their own personal experiences, and functional whereby researchers consider the way in which our research tools and methods may have impacted knowledge production. Reflexivity aims to bring attention to underlying factors which may impact the research process, including development of research questions, data collection, and the analysis. – a researcher’s ability to reflect critically on their own position, and how it influences the research process. This is a key skill in the social sciences and other disciplines that use qualitative research methods for studying social interaction, interpersonal relations, or cultural practices. A dash of reflexivity is particularly helpful for writing a positionality statement: see this article for more on reflexivity(From FORRT Glossary) The process of reflexivity refers to critically considering the knowledge that we produce through research, how it is produced, and our own role as researchers in producing this knowledge. There are different forms of reflexivity; personal reflexivity whereby researchers consider the impact of their own personal experiences, and functional whereby researchers consider the way in which our research tools and methods may have impacted knowledge production. Reflexivity aims to bring attention to underlying factors which may impact the research process, including development of research questions, data collection, and the analysis. and positionality statements.\n\nActivity 1\nAllow about 30 minutes\nWrite a positionality statement for yourself. You can do this for a research project you are involved in, one you have been involved in in the past, or for a fictional project in a field you are interested in.\nAs you do so, think about whether your positionality might influence the way you perceive and interpret the data in the project you have chosen, and whether it might impact the research process and outcomes in both negative and positive ways. For instance, your negative experience with police after being a witness to a crime might influence your interpretation of police data relating to lineup processes in a way that does not reflect reality. In contrast, your experience of having a child with a rare disease might help to ask the right questions when interviewing other parents with similar experiences.\n Write your positionality statement in your notes.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Integrity: Supporting robust interpretations</span>"
    ]
  },
  {
    "objectID": "Week5.html#flimsy-interpretations",
    "href": "Week5.html#flimsy-interpretations",
    "title": "5  Integrity: Supporting robust interpretations",
    "section": "5.3 Flimsy interpretations?",
    "text": "5.3 Flimsy interpretations?\nIn Week 3, you learned how researchers can be biased towards statistically significant results, and results that fit with the story they are trying to tell in their paper. One of the ways to spot this is when results and conclusions don’t follow on from each other. Tenuous links between results and conclusions are not always obvious, but they will be easier to spot once you are familiar with papers in your particular research area. Here are some to avoid in your own research:\n\n\n\n\n\n\nP-value interpretation\n\n\n\nIn quantitative papers where a specific p-valueA p-value is a statistical measurement used to validate a hypothesis against observed data. The lower the p-value, the greater the significance of the observed difference. threshold is being used to determine whether a result is statistically significant or not, researchers should specify at the beginning of their analysis section what their threshold will be for interpreting significance (e.g. &lt; 0.05). It’s important that p-values are interpreted consistently throughout the analysis. For example, you shouldn’t find 0.05 being used to show a significant difference in one case, but not in another. Any statistical value that is larger than your identified threshold should not be presented as evidence of an effect or association, however much you may wish it to be so!\n\n\n\n\n\n\n\n\nSupport for theory\n\n\n\nSometimes, researchers can be so invested in a particular theory they are not able to see other ways their results could be interpreted. You should always try to think about alternative explanations for your results, and include these in the manuscript discussion. When reading other researchers’ papers, think about other possible interpretations of their results, and evidence for and against those different interpretations. It can be difficult to see theories outside your own position, so it is helpful to get other researchers with different experiences or expertise to read your work before submitting it. You can offer to do the same for them when they are writing a manuscript.\n\n\n\n\n\n\n\n\nBurying results\n\n\n\nSometimes researchers present several results in an article, but ‘cherry-pick’ which of these to highlight in the discussion, overemphasising results that fit the story they’re trying to tell in their paper, and underemphasising those that seem to be contradictory. It’s important that any contradictory results are included in the discussion section, with speculation about why they may have occurred.\n\n\nIn Week 3, we pointed out that these biases are largely due to problematic incentive structures in academia. Researchers are incentivised to publish exciting, significant results in their papers, as these are more easily accepted by highly-regarded journals. Knowing this, it isn’t surprising that researchers are often biased to tell a simple, effective story in their papers, even though research is messy!\nSlowly, the norms do seem to be shifting, so it is becoming more common to be fully transparent in your manuscript writing, by including potentially confusing results and being honest about uncertainties.\n\n5.3.1 Avoiding the pitfalls\nSometimes academic journals have specific word counts, and it can be difficult to fit a lot of nuance and several additional analyses into the body of the paper. Where this is the case, it can be helpful to include all this information as supplementary information accompanying the paper (e.g. as a document uploaded to the Open Science Framework) rather than in the paper itself.\nPreregistrationThe practice of publishing the plan for a study, including research questions or hypotheses, research design, and data analysis plans, before the data has been collected or examined., which you learned about in Week 4, can also help you to avoid the pitfalls described on the previous page. If you plan to use p-values to make conclusions about whether your statistical tests are significant or not, you will need to outline a significance threshold in your preregistration. You will also need to outline how you will interpret different results, including whether they will support a specific theory.\nPreregistration can also protect you from burying results that don’t support your conclusions: if you preregister that you will run certain analyses, you will need to report the results of these, regardless of what they were.\nImportantly, without anyone checking your preregistration, you could still make decisions in the preregistration that make your results less credible. For example, you could pick a very high significance threshold (e.g. p &lt; 0.1), which would make false positive results more likely. You could say that a result supports a theory that doesn’t make sense, or you could ‘bury’ additional analyses that negate the results you’d prefer to draw attention to, if they weren’t included in your preregistration. Preregistration doesn’t automatically give your work more integrity, but it can help you to think through your research decisions more clearly before you start, and stop you from tricking yourself later.\n\nActivity 2\nAllow about 30 minutes\nThink of a disagreement you’ve had with someone. Write down three versions of the disagreement: one where you’re completely right, one where the other person is completely right, and one where you explain the complicated truth!\n\n\n\n\n\n\n  Show / Hide Discussion\n  \n  \nReflect on the activity – was it more difficult to write someone else’s perspective rather than your own? How might this manifest in research? Might it be easier to write about how your results support your preferred theory than to think about alternatives? Could stepping into the shoes of another researcher help you to try to work out alternative explanations for your results?",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Integrity: Supporting robust interpretations</span>"
    ]
  },
  {
    "objectID": "Week5.html#robustness",
    "href": "Week5.html#robustness",
    "title": "5  Integrity: Supporting robust interpretations",
    "section": "5.4 Robustness",
    "text": "5.4 Robustness\nRobustnessRefers to the strength and reliability of results. refers to the strength and reliability of results. Results can be considered more robust (and therefore have more integrity) if they hold up under various conditions, e.g. different data analyses. When results are robust to different data analyses, this indicates that the conclusions drawn from the research are not overly dependent on specific features of one type of analysis, and are therefore likely more widely applicable.\n\n\n\nA ruined wooden bridge on the left and a cast iron bridge on the right. Let’s check the integrity of the bridges here. The bridge on the left is likely to be less robust to extreme weather events than the bridge on the right. Which would you rather cross?\n\n\nIn some fields, it’s common to run many robustness analyses. For example, in economics, it is typical to have dozens of pages of any paper showing that a particular result holds up no matter how you measure the variables, which participants you include, which statistical model you use, and even when you control for a variety of factors that could be an alternative explanation for the effect.\nHowever, in other fields it’s less common. For example, in psychology, papers are often published where only one key analysis is performed to examine the results. If data and materials aren’t shared openly, it means others outside of the original research team cannot even choose to run these analyses themselves to check the robustness of the results. This is a good example of how integrity is difficult to check without transparency.\n\n5.4.1 Multiverse analysis\nOne way to take robustness to its most extreme is to perform multiverse analysisSystematically sampling a vast set of specifications, known as a multiverse, to estimate the uncertainty surrounding the validity of a scientific claim.. Although this sounds like something out of a science fiction movie about time travel - it’s actually a lot less out-of-this-world (however, still very cool). Multiverse analysis is where researchers try to perform all possible reasonable analyses on the data, in order to explore which analyses show the effect they’re interested in and which don’t.\n\nActivity 3\nAllow 10 minutes.\nUsing the hack your way to scientific glory activity from Week 3, try to write down as many different combinations of analysis parameters and the results you get from them (perform and write down as many as you can in 10 minutes). In effect, you will be doing a mini-multiverse analysis. What does it mean that the results are so variable, depending on the analysis performed?\n\n\n\n\n\n\n  Show / Hide Discussion\n  \n  \nThere are actually NINE HUNDRED different analysis combinations you could use in this activity! Conducting a full multiverse analysis on data like these would take a very long time, and go beyond the scope of the usual research project. But perhaps thinking about some of the most important robustness checks you could do with your research could be a first step towards enhanced robustness, without exploring the entire multiverse.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Integrity: Supporting robust interpretations</span>"
    ]
  },
  {
    "objectID": "Week5.html#the-open-research-decision-tree",
    "href": "Week5.html#the-open-research-decision-tree",
    "title": "5  Integrity: Supporting robust interpretations",
    "section": "5.5 The Open Research Decision Tree",
    "text": "5.5 The Open Research Decision Tree\nAllow 10 minutes for this activity.\nClick the image to open an interactive tool created by Open University.\n\n\n\nClick to open an interactive tool created by Open University.\n\n\nHere’s another opportunity to explore the open research decision tree. Consider ‘Actions’. The ‘Actions’ pathway suggests concrete steps you can take at three different stages: the planning stage, when you are actively collecting data, and after you have finished your analysis. In each of these, try to decide which actions support the integrity of a piece of research, and why you think it does so.\nWrite down some of your ideas about which actions in the decision tree relate to integrity.\n\n\n\n\n\n\n  Show / Hide Discussion\n  \n  \nYou might have chosen actions like preregistration, positionality statements, or robustness analysis as actions that are related to integrity. It is sometimes tricky to state that an action supports integrity alone, because transparency and integrity often relate to each other: without transparency, we cannot assess whether or not research has integrity.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Integrity: Supporting robust interpretations</span>"
    ]
  },
  {
    "objectID": "Week5.html#quiz",
    "href": "Week5.html#quiz",
    "title": "5  Integrity: Supporting robust interpretations",
    "section": "5.6 Quiz",
    "text": "5.6 Quiz\n\n\n\nWhat is the purpose of disclosing conflicts of interest in research? (Select one)\n\n\nTo ensure transparency and prevent bias in the researchTo increase the complexity of the research findingsTo make the research more difficult to understandTo hide potential sources of funding\n\n\n\nFeedback: Disclosing conflicts of interest ensures that you are transparent about any ways in which you may be biased towards the results turning out one way or another.\n\nTo ensure transparency and prevent bias in the research Correct\nTo increase the complexity of the research findings Incorrect\nTo make the research more difficult to understand Incorrect\nTo hide potential sources of funding Incorrect\n\n\n\n\n\n\nWhich of the following influences a researcher’s positionality? (Select one or more)\n\n\nThe size of the research teamThe presence of flimsy analysisThe geographical location of the researchThe political affiliation of the participantsThe social and political position of the researcher within society\n\n\n\nFeedback: Positionality refers to an individual’s social and political position within society, including their identity, background, experiences, and beliefs. This is the best definition. It is also conceivable the place of research could affect a researcher’s positionality. For instance, if a researcher works for a research institute in a country in the Global South, they may have experiences and beliefs relating to that particular country and culture.\n\nThe size of the research team Incorrect\nThe presence of flimsy analysis Incorrect\nThe geographical location of the research Incorrect\nThe political affiliation of the participants Incorrect\nThe social and political position of the researcher within society Correct\n\n\n\n\n\n\nWhat does robustness refer to in research? (Select one)\n\n\nThe size of the research teamWhether research results hold up under various conditionsThe amount of funding received for the researchThe complexity of the research findings\n\n\n\nFeedback: Robustness refers to the strength and reliability of results. Results can be considered to be more robust, and therefore to have more integrity, if they hold up under various conditions, e.g.: different data analyses.\n\nThe size of the research team Incorrect\nWhether research results hold up under various conditions Correct\nThe amount of funding received for the research Incorrect\nThe complexity of the research findings Incorrect\n\n\n\n\n\n\nWhich of the following is an example of investigating robustness in research? (Select one)\n\n\nWriting about potential alternative explanations for the resultsOnly performing one key analysis on the dataSharing data and materials with other researchersRunning multiple analyses on the data\n\n\n\nFeedback: Running multiple analyses on the data and seeing whether the same conclusions can be drawn is a way to investigate the robustness of a result.\n\nWriting about potential alternative explanations for the results Incorrect\nOnly performing one key analysis on the data Incorrect\nSharing data and materials with other researchers Incorrect\nRunning multiple analyses on the data Correct\n\n\n\n\n\n\nWhat is multiverse analysis in research? (Select one)\n\n\nPerforming all possible reasonable analyses on the dataRunning the most complicated analysis possible on the dataExploring multiple universes to find research resultsUsing new multiverse technology to run analyses on the data\n\n\n\nFeedback: Multiverse analysis is what you attempted a mini-version of in Activity 3. As you probably discovered there, multiverse analyses are very hard, and take a long time, but the results can be very interesting and important for understanding how a finding may differ based on different factors.\n\nPerforming all possible reasonable analyses on the data Correct\nRunning the most complicated analysis possible on the data Incorrect\nExploring multiple universes to find research results Incorrect\nUsing new multiverse technology to run analyses on the data Incorrect",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Integrity: Supporting robust interpretations</span>"
    ]
  },
  {
    "objectID": "Week5.html#summary",
    "href": "Week5.html#summary",
    "title": "5  Integrity: Supporting robust interpretations",
    "section": "5.7 Summary",
    "text": "5.7 Summary\nThis week you explored more aspects of the principle of integrity: conflicts of interest, positionality, and the link between results and conclusions, and robustness.\nPositionality is an individual’s social and political position, shaped by factors like identity, background, experiences, values, and beliefs. It can influence the link between results and conclusions: when researchers interpret their data, there is a chance it could colour their interpretation. Potential researcher biases can also impact how researchers write up conclusions following on from their results. It’s important to try to avoid, or at least be explicit about potential biases in your own writing. Finally, robustness is whether or not results hold up in multiple analyses – where they do, we can have more confidence in the results. This helps researchers defend themselves against potential bias.\nIn Week 6 you’ll be moving on from the principle of integrity to the principle of accessibility.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Integrity: Supporting robust interpretations</span>"
    ]
  },
  {
    "objectID": "Week5.html#references",
    "href": "Week5.html#references",
    "title": "5  Integrity: Supporting robust interpretations",
    "section": "5.8 References",
    "text": "5.8 References\nFivethirtyeight.com: Hack your way to scientific glory\nAvailable at: https://projects.fivethirtyeight.com/p-hacking/\nLacy, M. (2017): Just tell me what I need to know: reflexivity and positionality statements\nAvailable at: https://medium.com/@Marvette/ just-tell-me-what-i-need-to-know-reflexivity-and-positionality-statements-fb52ec0f4e17\nThe Open University (2024): The open research decision tree.\nAvailable at: https://www.open.edu/openlearncreate/course/view.php?id=11974",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Integrity: Supporting robust interpretations</span>"
    ]
  },
  {
    "objectID": "Week6.html",
    "href": "Week6.html",
    "title": "6  Accessibility: Making your research accessible online",
    "section": "",
    "text": "6.1 Open access\nIn Weeks 2 to 5 of this course, you have explored two key principles of open research: transparency and integrity. Now let’s turn to the third principle of accessibility. Accessibility is crucial, because knowledge generation is a collective endeavour, funded at least in part by taxpayers, and so everyone has a right to the knowledge that is generated. For this short course, accessibility will be discussed in the context of journal manuscripts, while acknowledging that research can also be made accessible through many other outputs.\nAccessible researchResearch is accessible if all who are interested can consume, evaluate, and otherwise interact with research products and processes. in this context means ensuring that all who are interested can consume, evaluate, and otherwise interact with research products and processes. Even if research is transparentThe principle of transparency in research refers to the practice of being open and honest about all aspects of the research process. and has integrityThe principle of integrity refers to the degree of trustworthiness or believability of research findings., if only certain people can access the research products, it is not truly open.\nOne aspect of ensuring that all those who are interested are able to consume research products is open accessOpen access is the free, immediate, online availability of research outputs such as journal articles without having to pay a fee, combined with the rights to use these outputs fully in the digital environment., which refers to manuscripts being made freely available and reusable. If a manuscript is truly ‘open access’ then the author should have full copyright permissions, which means they can use the final manuscript however they wish.\nTo be reusable, the manuscript should be made available through a Creative CommonsA Creative Commons license enables reusers to distribute, remix, adapt and build upon the material, as long as they abide by conditions set by the author. (also known as CC) licencing, which offers more flexible usage rights for your work. As you learned in Week 2, there are various types of license, ranging from fairly permissive (e.g.: others can access, copy, use and adapt the work as long as credit is given to the author), to more restrictive (e.g.: credit must be given to the author, non-commercial uses only, and the work cannot be altered). You can find out more about licensing on the Creative Commons website.\nAs well as being related to accessibility, you can consider open access to be another form of transparency. It makes manuscripts openly available, for the same reasons as you learned about in Week 2, for making data and materials openly available.\nImagine you’re in a library searching for a book that you need for an assignment. You find the perfect one on the shelf, but when you try to open it, the pages are glued together. You can see the cover and read the blurb, but the valuable content inside is completely inaccessible to you. This is what it’s like to not be able to access an article because it’s behind a paywall.\nOpen access can take many different forms:\nGreen open access 🟢\nWith green open access, the work is openly accessible from a public repository, such as a preprint server. This is a way researchers can provide access to their research without cost to themselves or their readers. Usually this means sharing a version of the manuscript openly (i.e. a version of the manuscript that has gone through the peer-review process, but has not been copy-edited or typeset by the publisher). The manuscript becomes freely available, either at the point of deposit or after a publisher’s embargo period, usually 6 to 24 months.\nGold open access ⭐️\nWith gold open access, the work is immediately openly accessible upon publication via the publisher’s website. Usually this means the researcher paying a fee to the publisher, which can be up to several thousand pounds. Some universities have a deal with certain publishers, and will pay this charge on behalf of the researcher.\nDiamond open access 💎\nDiamond open access (also known as platinum open access) is where an organisation covers the cost of publication so that neither the reader nor the author pays to read or publish. The work is immediately openly accessible upon publication via the publisher’s website, without cost to researchers or their readers.\nIf diamond open access is possible, why don’t more publishers offer it?",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Accessibility: Making your research accessible online</span>"
    ]
  },
  {
    "objectID": "Week6.html#journal-publishing-models",
    "href": "Week6.html#journal-publishing-models",
    "title": "6  Accessibility: Making your research accessible online",
    "section": "6.2 Journal publishing models",
    "text": "6.2 Journal publishing models\nThe reason why more publishers don’t offer diamond open access is because the different journals have different business modelsA business model is the plan of a company for how it will make a profit.. Each journal will have a publisher, who plays a varying role in the operation and management of the journal. Publishers can be involved in editorial support, production and typesetting, distribution and access, marketing and promotion, financial management, copyright and licensing, and indexing and impact metrics.\nHere are some of the different business models for academic journals:\n\nTable: Journal Publishing – Business Models\n\n\n\n\n\n\nSubscription-based model:\nUnder this model, readers pay a subscription fee to access the journal's content. This fee could be paid by individuals, institutions like universities, or both. The journal may also offer print and online subscription options.\nSociety or Association-based model:\nMany journals are published by scholarly societies or professional associations. Depending on the society, the journal can either be a source of income for the society or association, or it can be financed by other sources of income.\n\n\nOpen Access model:\nIn this model, sometimes referred to by its acronym ‘OA’, the content of the journal is freely available to readers without requiring a subscription. Instead, the costs of publication are often covered by charging authors a fee, known as an ‘article processing charge’, or ‘APC’.\nAdvertising-supported model:\nIn this model, journals generate revenue by selling advertising space within their publications. Advertisers pay to reach the journal's audience, typically researchers, academics, and professionals in a specific field.\n\n\nHybrid model:\nJournals employing this model offer a combination of both subscription-based and open access options. Some articles are freely available (open access), while others require a subscription to access. Authors may choose to pay APCs to make their articles open access within a hybrid journal.\nPay-per-view model:\nSome journals offer individual articles for purchase on a pay-per-view basis. Readers can access specific articles by paying a fee for each article they wish to view, rather than subscribing to the entire journal.\n\n\n\n\n6.2.1 What help is available for authors when publishing in journals with an APC?\nSometimes, institutions and/or research funders are willing to pay the APCs for authors to publish Open Access. Some institutions even have ‘Transitional Agreements’ with publishers to cover these APCs. Similarly, the UKRI block grant provides funding for eligible authors to meet publishing costs. Many journals also offer ‘APC waivers’ for eligible authors who are unable to pay. For authors seeking further assistance, exploring their institutional guidance or speaking directly with library staff can help identify other potential funding opportunities tailored to their specific needs.\n\n6.2.1.1 The Big Five\nMany journals have a large publisher, e.g. Elsevier, Sage, Springer Nature, Taylor and Francis, and Wiley – the ‘big five’. These publishers are for-profit, meaning that they make a large amount of money from researchers (through APCs), universities (through subscriptions), or readers (through subscriptions and pay-per-view). For example, it has been estimated that the research community paid over $1.06 billion in open access fees alone to the big five publishers between 2015 and 2018.\n\n\n6.2.1.2 Activity 1\nAllow about 10 minutes.\nWrite down the advantages and disadvantages of each business model in terms of accessibility and open access to research. Which business model do you find the most concerning and why?\n\n\n\n\n\n\n  Show / Hide Discussion\n  \n  \nThere are many nuanced advantages and disadvantages to the different models. For example, the open access model ensures that anyone can read the published articles, but isn’t very accessible to authors, since they may not have the funding to pay to publish in the journal. Solving this problem, hybrid models mean that authors do not have to pay to publish, but then their article would be paywalled, making the model less accessible to readers.\n  \n\n\n\n\n6.2.2 Changing tides\nPeople have been working for years to build up open access publishing. Latin America is a global leader. Governments, foundations, and public universities in Latin America have fostered a vibrant culture of open access, with between fifty and ninety percent of articles published in the region appearing open access through platforms such as SciELO and Redalyc, typically as diamond open access.\nPlan S is an initiative launched by Coalition S, a group of international research agencies and funders from around the world. The goal is to make all publicly funded research freely available to everyone. Under Plan S, researchers who receive funding from Coalition S members must publish their work in open access journals or platforms.\nMore recently, academics have started developing independent journals, bypassing for-profit publishers. For example, the editorial team from the journal Lingua broke off from Elsevier and launched a new journal called Glossa.\nWhen publishing your research, one consideration of where to publish can be the values of the journal, and whether you want to contribute to further profits for a for-profit publisher or not. The next few sections explore some of your options.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Accessibility: Making your research accessible online</span>"
    ]
  },
  {
    "objectID": "Week6.html#preprints",
    "href": "Week6.html#preprints",
    "title": "6  Accessibility: Making your research accessible online",
    "section": "6.3 Preprints",
    "text": "6.3 Preprints\nAlthough as researchers we can strive towards only publishing in open access journals that fully uphold our scientific values, life unfortunately is not that simple! As you learned in previous weeks, in academia, publishing in prestigious journals is incentivised, and impacts researchers’ ability to obtain grants, jobs and promotions. Unfortunately, what’s considered prestigious most often overlaps with for-profit publishers. This is why initiatives like DORA (Declaration on Research Assessment) and responsible metrics are crucial. Rather than evaluating research based on the impact factor of the journal, which promotes the merits of individual works, they advocate evaluating research based on its quality and placing value on a wider range of scholarly outputs.\nAlthough it might seem tempting to boycott all for-profit publishers (and many are doing this), it can be a balancing act for researchers to weigh up the relative costs and benefits of trying to publish in a prestigious journal. Those with more privilege – such as researchers with a permanent job, or enough savings or support to not worry about not having a job for a while – are able to be more radical in their approach, so it’s important to acknowledge that researchers have their individual circumstances to consider when deciding which journals to publish in, and more generally, which open research practices to engage in.\nPreprints are a way to ensure that your work is openly accessible to others, regardless of where you publish your research. A preprint is a version of your article that you submit to a preprint repository. There are preprint repositories in many fields, e.g. bioRxiv (pronounced ‘bio-archive’), PsyArXiv (pronounced ‘psy-archive’), and PhilPapers. There are also discipline non-specific repositories, e.g. OSF preprints. All you need to do is upload a version of your paper to the server, and it is available for anyone to read free! This is also a great way to showcase your work before waiting for it to be peer-reviewed and published in a journal, which can be especially beneficial to early-career researchers.\nYou can upload preprints for work that is already published in a journal, work that you’re submitting to a journal, and even work that you never intend to submit to a journal. There are different benefits to uploading preprints at these different stages:\n\nAlternative to a journal: If you’re not interested in publishing your paper in a peer-reviewed journal, or don’t have the time to do so, uploading it to a preprint server means that the research community can still read your findings and benefit from your hard work.\nAlongside submission to a journal: Submitting a preprint alongside submission to a journal gets your paper out there quicker than waiting for it to be peer-reviewed and published. If you submit a preprint before submitting to a journal, people outside of the journal’s reviewers can give informal feedback that you can implement in your journal submission (or in the next round of submission).\nAfter publishing in a journal: Submitting a preprint of work that has already been published in a journal means you can make your work green open access if it is currently published behind a paywall, meaning more people can read it.\n\nMany journals will allow you to publish a preprint of your work alongside submission to their journal, or after your article has been accepted in the journal. However, some journals will not. To check the rules for the journal that you’re interested in, enter the journal or publisher information in Open Policy Finder.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Accessibility: Making your research accessible online</span>"
    ]
  },
  {
    "objectID": "Week6.html#preprint-considerations",
    "href": "Week6.html#preprint-considerations",
    "title": "6  Accessibility: Making your research accessible online",
    "section": "6.4 Preprint considerations",
    "text": "6.4 Preprint considerations\nPreprints are used to varying degrees across different fields of research, and in different ways within these fields, so it might be worth having a chat with your colleagues or educators to find out what the norms are in your field before deciding how and whether to upload your own preprints.\nIt’s important to consider that preprints that are published instead of, or alongside journal publication, have not always been peer-reviewed. This doesn’t automatically mean that they’re ‘worse’ than articles that have been peer-reviewed – many terrible manuscripts have slipped through peer-review, and many excellent ones have been rejected – but it does mean that readers should take the content with a pinch of salt and an even more critical eye than usual. This can be problematic when the public or journalists are interacting with preprints, as they might take the content as fact, which they shouldn’t even be doing for peer-reviewed work, let alone work that hasn’t been peer-reviewed.\n\n6.4.0.1 Activity 2:\nAllow about 15 minutes.\nFind a preprint server for your discipline, or if one doesn’t exist then use OSF Preprints. Spend ten minutes looking for the most interesting article you can find, and identify which stage of the research process it has been uploaded to the preprint server. Use keywords you would usually use to search for an article in your discipline, just like searching for a published article. Tip: usually, researchers will identify on the title page if the article has been submitted to or accepted by a journal.\n\n  Show / Hide Discussion\n  \n  \nHopefully you could see whether preprints were published before or after publication in a journal. Preprints can be an excellent way to access the latest research findings in your area. Publishing a preprint allows you to gain feedback early. Preprints can also allow policy makers and practitioners to make decisions based on the latest research, and early-career researchers to build up a publication record quickly.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Accessibility: Making your research accessible online</span>"
    ]
  },
  {
    "objectID": "Week6.html#beyond-open-access-publishing",
    "href": "Week6.html#beyond-open-access-publishing",
    "title": "6  Accessibility: Making your research accessible online",
    "section": "6.5 Beyond open access publishing",
    "text": "6.5 Beyond open access publishing\nThere are many other accessibility needs to consider when thinking about how different people may access knowledge that is produced via research. Some people experience specific barriers, which we can help them to overcome. The image shows a hand holding up an equals sign which is crossed out.\nA blind person can benefit from text-to-speech software to access academic articles and textbooks. A deaf person can benefit from captioning when learning from a recorded lecture. Someone not familiar with technical language (e.g. a non-researcher member of the general public) might benefit from plain language summaries of the research and its potential use and impact, which could be through the form of a blog post for example (for more on diversity of scientific outputs see Week 8). Someone with dyslexia might find it difficult to read academic papers printed in a font that isn’t clear to read – yet there are dyslexia-friendly fonts readily available, that could make all the difference.\nIn this course, we will only touch on a few aspects of accessibility to knowledge produced by research, but we encourage you to think about other ways you can increase accessibility of your research.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Accessibility: Making your research accessible online</span>"
    ]
  },
  {
    "objectID": "Week6.html#quiz",
    "href": "Week6.html#quiz",
    "title": "6  Accessibility: Making your research accessible online",
    "section": "6.6 Quiz",
    "text": "6.6 Quiz\nThe quiz will help you consolidate what you have learned this week. The questions revise key terms related to accessibility, open access publishing and preprints. Make sure you read the feedback, whether you get the answers right or wrong.\n\n\n\nWhat does open access refer to in research? (Select one)\n\n\nMaking manuscripts freely availableCharging readers a fee to access manuscriptsRestricting access to manuscriptsLimiting the reuse of research findings\n\n\n\nOpen access means making manuscripts freely available to anyone who wants to read them! This can be done in different ways, depending on the open access model.\n\nMaking manuscripts freely available Correct\nCharging readers a fee to access manuscripts Incorrect\nRestricting access to manuscripts Incorrect\nLimiting the reuse of research findings Incorrect\n\n\n\n\n\n\nWhich type of open access involves making research openly accessible from a public repository? (Select one)\n\n\nDiamond open accessGold open accessRed open accessGreen open access\n\n\n\nFeedback: Green open access means the work is openly accessible from a public repository (e.g. a preprint server). This is a way researchers can provide access to their research without a cost to themselves or their readers.\n\nDiamond open access Incorrect\nGold open access Incorrect\nRed open access Incorrect\nGreen open access Correct\n\n\n\n\n\n\nWhat is the main difference between gold and diamond open access? (Select one)\n\n\nGold open access requires authors to pay a feeDiamond open access is free for both authors and readersDiamond open access requires authors to pay a feeGold open access is free for both authors and readers\n\n\n\nFeedback: Both gold and diamond open access make the work openly accessible through a journal, but in gold open access authors pay a fee, whereas in diamond open access the article is published openly without the authors having to pay.\n\nGold open access requires authors to pay a fee Correct\nDiamond open access is free for both authors and readers Incorrect\nDiamond open access requires authors to pay a fee Incorrect\nGold open access is free for both authors and readers Incorrect\n\n\n\n\n\n\nWhat is the main purpose of a preprint? (Select one or more)\n\n\nTo ensure that research findings are openly accessibleTo make sure researchers get credit for the work they’ve doneTo make researchers more likely to get a jobTo provide a way for researchers to monetise their work\n\n\n\nFeedback: The main purpose of a preprint is to ensure that research findings are openly accessible. However, preprints also contribute to making sure researchers get credit for the work that they’ve done, because they’re able to share that work before it’s published in a journal.\n\nTo ensure that research findings are openly accessible Correct\nTo make sure researchers get credit for the work they’ve done Correct\nTo make researchers more likely to get a job Incorrect\nTo provide a way for researchers to monetise their work Incorrect\n\n\n\n\n\n\nWhat are possible sources of revenue for for-profit academic publishers? (Select one or more)\n\n\nPay-per-view chargesCreative Commons licensesSubscription feesArticle processing charges (APCs)\n\n\n\nFeedback: These three are possible sources of revenue for for-profit academic publishers. Creative Commons licenses are not: they are free legal tools, which enable the open sharing and reuse of creativity and knowledge.\n\nPay-per-view charges Correct\nCreative Commons licenses Incorrect\nSubscription fees Correct\nArticle processing charges (APCs) Correct\n\n\n\n\n\n\nWhich journal model offers a combination of subscription-based and open access? (Select one)\n\n\nSociety or association-based modelHybrid modelAdvertising-supported modelPay-per-view model\n\n\n\nFeedback: A hybrid model offers both subscription-based and open access to authors, depending on whether or not they choose to pay a fee.\n\nSociety or association-based model Incorrect\nHybrid model Correct\nAdvertising-supported model Incorrect\nPay-per-view model Incorrect",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Accessibility: Making your research accessible online</span>"
    ]
  },
  {
    "objectID": "Week6.html#summary",
    "href": "Week6.html#summary",
    "title": "6  Accessibility: Making your research accessible online",
    "section": "6.7 Summary",
    "text": "6.7 Summary\nIn this week, you learned about different models of open access and how this relates to journal business modelsA business model is the plan of a company for how it will make a profit.. You also learned how preprints are an easy and helpful way to ensure that your work is openly accessible to everyone, and some tips for how and when to upload preprints. In the next week, you’ll be learning about other ways of making your research accessible to people around the world!",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Accessibility: Making your research accessible online</span>"
    ]
  },
  {
    "objectID": "Week6.html#references",
    "href": "Week6.html#references",
    "title": "6  Accessibility: Making your research accessible online",
    "section": "6.8 References",
    "text": "6.8 References\nAlperin, J. P. (2015): The public impact of Latin America’s approach to open access Stanford University.\nAvailable at: https://stacks.stanford.edu/file/druid:jr256tk1194/AlperinDissertationFinalPublicImpact-augmented.pdf\nAmerican Society for Cell Biology (2024): Declaration on Research Assessment (DORA).\nAvailable at: https://sfdora.org/\nBarnes, L. (2018): Green, gold, diamond black – what does it all mean?\nAvailable at: https://blogs.openbookpublishers.com/green-gold-diamond-black-what-does-it-all-mean/\nButler, L. A., Matthias, L., Simard, M. A., Mongeon, P., & Haustein, S. (2023): The oligopoly’s shift to open access: How the big five academic publishers profit from article processing charges. Quantitative Science Studies, 4(4), 778-799.\nAvailable at: https://doi.org/10.1162/qss_a_00272\nCenter for Open Science (2024): OSF Preprints\nAvailable at: https://osf.io/preprints\nCoalition S (2024): Plan S: making full and immediate open access a reality Available at: https://www.coalition-s.org/\nCold Spring Harbour Laboratory (2024): bioRxiv: the Preprint Server for Biology Available at: https://www.biorxiv.org/\nCreative Commons (2024): About CC licenses\nAvailable at: https://creativecommons.org/share-your-work/cclicenses/\nJISC Open Policy Finder (2025): Open Policy Finder\nAvailable at: https://openpolicyfinder.jisc.ac.uk/\nLinguistics in Open Access (LingOA, 2024): Glossa: a journal of general linguistics\nAvailable at: https://www.glossa-journal.org/\nNetwork of Scientific Journals from Latin America and the Caribbean, Spain and Portugal (2024): Redalyc\nAvailable at: https://www.redalyc.org/\nPhilPapers Foundation (2024): PhilPapers (index and bibliography of philosophy)\nAvailable at: https://philpapers.org/\nSciELO (2024): Scientific Electronic Library Online (SciELO)\nAvailable at: http://scielo.org/en/\nSociety for the Improvement of Psychological Science Preprints / OSF (2024): PsyArXiv\nAvailable at: https://osf.io/preprints/psyarxiv",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Accessibility: Making your research accessible online</span>"
    ]
  },
  {
    "objectID": "Week7.html",
    "href": "Week7.html",
    "title": "7  Accessibility: Academic privilege and diversity",
    "section": "",
    "text": "7.1 Privilege in academia\nEven if we were to implement all the open research practices outlined in the previous weeks, our research can’t be fully open unless it’s open to everyone. It isn’t equally easy for everyone to enter a career in academia, due to different kinds of systemic inequality.\nThis week, we will continue to explore the principle of accessibility(From FORRT Glossary) Accessibility refers to the ease of access and re-use of materials (e.g., data, code, outputs, publications) for academic purposes, particularly the ease of access is afforded to people with a chronic illness, disability and/or neurodivergence. by considering how open research can challenge such inequalities. You will discover how diversity can improve the quality of research and read inspiring examples of how ‘big science’ can be ‘good science’. By the end of this week, you will be ready for Week 8, where we help you to launch yourself into your open research future.\nInequities in academia and research are a big issue, showing up in various ways like gender, race, disability, and elitism. In Weeks 5 and 6, you discovered some examples of how researchers don’t all have equal access to opportunities. This relates to privilegePrivilege is unearned access or advantage, which specific groups of people have because of their membership of a particular social group., often described as unearned access or advantage, which specific groups of people have because of their membership of a particular social group.\nWomen and minorities often hit roadblocks when it comes to climbing the career ladder or getting access to key resources, which means they’re not as well represented in top positions or in prestigious research projects. People with disabilities face both physical challenges and unhelpful attitudes that can make it tough to fully take part. On top of that, elitism tends to favour those from more privileged backgrounds and institutions, keeping opportunities out of reach for many.\nEveryone working and studying in academia has a duty to support researchers who face greater barriers, and to influence their institutions and organisations to make positive change to encourage diversity, equity, and inclusion.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Accessibility: Academic privilege and diversity</span>"
    ]
  },
  {
    "objectID": "Week7.html#privilege-in-academia",
    "href": "Week7.html#privilege-in-academia",
    "title": "7  Accessibility: Academic privilege and diversity",
    "section": "",
    "text": "The Academic Wheel of Privilege\n\n\n\nActivity 1\nAllow about 10 minutes.\nThis activity allows you to reflect on your understanding of ‘accessibility(From FORRT Glossary) Accessibility refers to the ease of access and re-use of materials (e.g., data, code, outputs, publications) for academic purposes, particularly the ease of access is afforded to people with a chronic illness, disability and/or neurodivergence.’ and ‘privilege’ in academia. The diagram is adapted from Elsherif et al (2022), whose full article is in the references section.\nLook at the academic wheel of privilege above – which parts describe you? Spend ten minutes thinking about whether or not you feel that your experience of academia has been positively or negatively affected by your characteristics.\n In your notes, write down your thoughts.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Accessibility: Academic privilege and diversity</span>"
    ]
  },
  {
    "objectID": "Week7.html#diversity",
    "href": "Week7.html#diversity",
    "title": "7  Accessibility: Academic privilege and diversity",
    "section": "7.2 Diversity",
    "text": "7.2 Diversity\nWhen we think about making research more diverse, we can think about this at three several different levels, for example:\n\ndiversity of samples\ndiversity of researchers\ndiversity of methodology\ndiversity of outputs\n\nIt is important that we work towards diversity in each of these domains in our respective fields.\n\n\n\n\n\nDiversity of samples\n\n\nIn Week 3, you learned about generalisability. One facet of generalisability is whether or not your findings will apply in different cultures and contexts around the world. When collecting human data, a ‘sample’ is the group of people who take part in a research study. It’s important to think about ways to collect diverse samples for our research, as a more diverse sample will represent the wider population better than a less diverse one. Thus, sampling variationThe extent to which the data vary in different samples taken from the same population.n, which means the extent to which the data vary in different samples taken from the same population, is key to collecting and interpreting human data.\nAlthough researchers may not have the funds to collect data in multiple countries, there are smaller ways they can extend their samples, for example:\n\nCollecting data from multicultural populations in their own country\nCollaborating with a researcher in another country\nGetting involved in big team science\n\n\n\n\n\n\n\n\nDiversity of researchers\n\n\nIt is important to make sure your research teams are as diverse as possible. This is for reasons of equityEquity means the quality of being fair or impartial. In education, it is understood as presenting all scholars with the same opportunities, which sometimes requires making adjustments for their particular needs., but also because people coming from different perspectives are likely to bring different ideas and insights to the research, making it richer! Here are some examples of ways that a diverse team of researchers can help a project be better:\n\nA team with members from various backgrounds can offer unique insights into culturally-specific health behaviours or practices in medical research.\nIncluding researchers with disabilities can lead to innovative solutions for accessibility(From FORRT Glossary) Accessibility refers to the ease of access and re-use of materials (e.g., data, code, outputs, publications) for academic purposes, particularly the ease of access is afforded to people with a chronic illness, disability and/or neurodivergence. in technology design.\nA mix of genders on a team can provide a balanced approach to studying gender differences in workplace dynamics or tackling workplace harassment.\n\n\n\n\n\n\n\n\nDiversity of methodology\n\n\nWhen we have more diverse teams, this can open our eyes to new perspectives and lead to new methodological approaches. It’s possible that your existing methodology cannot just be copied and pasted into a new cultural context, and instead would need many modifications to be culturally appropriate. For instance, research exploring a global reading intervention that only considered reading text from right to left might not be appropriate in cultures where text is read left to right. There are lots of different ways that you can try to diversify your research methodology, for example:\n\nA quantitative researcher collaborating with a qualitative researcher.\nTalking to colleagues from different fields about how to improve your research methodology.\nCollaborating cross-culturally on a new study design or rolling out an old study design in a new context.\n\n\n\n\n\n\n\n\nDiversity of outputs\n\n\nThere are many ways of sharing research findings beyond academic journal articles (for example you have already learned about open data and open materials). Reviews themselves can also be made open, see for example the Publish Your Reviews initiative (ASAPBio, 2024). Platforms such as Jisc’s Octopus challenge conventional practices and promote transparency and collaboration through allowing researchers to publish a variety of outputs. Additionally, podcasts, blogs, videos, and social media also offer powerful ways to increase reach and engagement, ensuring research impacts broader audiences. Here are some examples of ways of diversifying the outputs of your research:\n\nAn educational psychologist could write a blog post summarising the results of their study, sharing this blog post with researchers, teachers, and parents/carers.\nA climate scientist could create a short, engaging video explaining their latest findings, tailored for a general audience and shared widely on social media.\nA historian could launch a podcast series discussing key insights from archival research, inviting guest experts and fostering a dialogue with listeners from diverse backgrounds.\n\n\n\n\nActivity 2\nAllow about 10 minutes.\nThis activity encourages you to reflect on practice in your own research setting.\nWrite down steps you could take to increase the diversity of your samples, collaborators, and methodology. This will be different depending on your field and career stage, but you should be able to think about at least one actionable step for each!",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Accessibility: Academic privilege and diversity</span>"
    ]
  },
  {
    "objectID": "Week7.html#equity-diversity-and-inclusion",
    "href": "Week7.html#equity-diversity-and-inclusion",
    "title": "7  Accessibility: Academic privilege and diversity",
    "section": "7.3 Equity, diversity and inclusion",
    "text": "7.3 Equity, diversity and inclusion\nThe next video is about a group of researchers who had the courage to confront some difficult questions. Dr Carina Bossu of the Open University’s Institute for Educational Technology tells the story of how her team took the challenges of equity, diversity and inclusion seriously. As you watch, think about the measures Carina’s team implemented, and whether these measures could apply in your own setting.\n\n\n\n\n\n\n\nVideo Transcript - Click to expand\n\n\n\n\n\nMy name is Carina Bossu. I’m a senior lecturer in academic professional development with the Institute of Educational Technology here at the Open University. I’m also a lead of the equity, diversity and inclusion project within the Go-GN network.\nThe Go-GN network, which is the global OER graduate network, as the name suggests, is a network to support researchers in open education in general, several fields of open education.\nThey have their own supervisors, they are enrolled in their own institutions, but they come to us for additional support.\nWe provide webinars, resources, and we have also our annual meeting where we bring these researchers together to be part of the broader network.\nThe idea of, you know, creating a project specifically focused on EDI, equity, diversity and inclusion, came because, you know, there is an assumption that because we work in open education or we work in open research, there is an assumption that the word ‘open’ means equitable, diverse and inclusive - and it’s not always the case.\nFor example, in Go-GN, the majority of our members are from the Global North, they are white and they speak English.\nWe realised that, and decided then to understand what could be a Go-GN that is more inclusive. So we applied for an additional grant and we set off to talk to people from the Global South. We went first in Africa and spoke with some experts there, and that first Phase, that’s what we called it, was then used to generate the first guidelines for EDI in Go-GN, but also informed Phase 2 of the project, which was in Latin America, where we then went there to speak with experts in open education and find out - what would look like a more equitable, diverse and inclusive network?\nAfter these two Phases, we then set out to start implementing the recommendations we received from participants.\nSo we have now implemented a lot of the recommendations into Go-GN, but we have also published that in forms of guidelines.\nWe have a paper, we have blog posts.\nSo just an example of some of the recommendations we received from experts is that, for example, in Go-GN, all the resources we provide are in English. And they wouldn’t be able to read that. So what we did, we translated a lot of those resources into Portuguese and Spanish. We have plans now to translate more resources into different languages.\nAnother way we try to be more inclusive is to provide on-demand translation during our webinar. So there is a software that can help us with that. So we are looking into this.\nWe are now offering scholarships to researchers to help them with their research, but also to help with their career progress, and we give priority to Global South candidates.\nEDI now is not a separate project, it is part of Go-GN, so it’s one of our strengths. And this means that the work that we do will always have an EDI focus, so then the work that we do also will help everyone that can benefit from it.\n\n\n\n\nPromoting equity, diversity and inclusion\nThink about the steps Carina and her colleagues at the Go-GN Network took. Could you do something similar in your own organisation?\nAllow about 10 minutes.\n Take some notes on what steps you might take.\n\n  Show / Hide Discussion\n  \n  \nCarina explains that she and her colleagues recognised a lack of diversity within their network. Once they had realised this, they sought research funding to address the issue. They went directly to people in the Global South, seeking their opinions about how the network could become more diverse and inclusive. These people pointed out barriers to diversity and inclusion, and challenged the researchers to address them. Their ideas are now being implemented, resulting in lasting change.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Accessibility: Academic privilege and diversity</span>"
    ]
  },
  {
    "objectID": "Week7.html#big-team-science",
    "href": "Week7.html#big-team-science",
    "title": "7  Accessibility: Academic privilege and diversity",
    "section": "7.4 Big team science",
    "text": "7.4 Big team science\nIn Week 3, you were introduced to ‘big team scienceA research project in which researchers from around the world conduct the same study and pool their results.’ – large-scale projects where researchers from around the world conduct the same study and pool their results. As well as having benefits for sample size and the ability to investigate generalisability of findings, big team science also has the potential to increase diversity, equity and inclusivity in research.\nHere are some examples of big team science projects.\n\nThe Human Genome Project aimed to map and understand all the genes of the human species, and in 2003 successfully identified the approximately twenty to twenty-five thousand genes in human DNA. The magnitude of this challenge brought together expertise of interdisciplinary groups from across the world, including experts in engineering, biology, computer science, and so on.\nCERN and the Large Hadron Collider aimed to explore fundamental questions about the universe, and in 2012, discovered the Higgs boson, confirming a key part of the Standard Model of particle physics. The project required the perspectives of over twelve thousand scientists, from more than one hundred nationalities. They collaborated in a culture where decisions were made through intense discussions about the scientific merits of rival proposals, rather than hierarchy.\nThe project ManyPrimates aims to study primate cognition and behaviour through large-scale, collaborative experiments across multiple primate research facilities. The study includes a systematic review, to challenge the idea that knowledge can be effectively generated by looking at a limited number of primate species at a few sites. The initial projects have focused on understanding the cognitive abilities of different primate species.\n\nYou can get involved in big team science either by joining an existing organisation or by starting a project yourself! If there is an existing big team science initiative in your field that is open to new members, this can be a good starting point. For example, the Psychological Science Accelerator brings psychology researchers together to pool resources for large global studies in psychology. Anyone can join an existing project in various roles, depending on their knowledge and experience including data collection and translation. Anyone can also propose their own project during open ‘calls for studies’.\nAlthough the term ‘big team science’ implies the research is scientific, there is no reason why some of the principles behind big team science can’t be applied to non-scientific research. There are inspiring collaborative projects in the humanities, too:\n\nReligious Peace and Toleration (RETOPEA) is an international community of researchers who develop educational tools and recommendations to promote peaceful understanding between young people of different religions, spiritualities and worldviews.\nThe Pelagios Network, which you looked at in Week 1, is a community of researchers, data scientists and curators who use linked data methods and tools to investigate the past.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Accessibility: Academic privilege and diversity</span>"
    ]
  },
  {
    "objectID": "Week7.html#limitations-of-big-team-science",
    "href": "Week7.html#limitations-of-big-team-science",
    "title": "7  Accessibility: Academic privilege and diversity",
    "section": "7.5 Limitations of big team science",
    "text": "7.5 Limitations of big team science\nIt is important to note that although big team science has the potential to increase diversity, equity and inclusion, this does not happen automatically. There are many ways that researchers can be inadvertently excluded from big team science, for example:\n\nResearchers are sometimes not paid to participate in these projects, and instead do so for academic ‘rewards’ such as authorship on the eventual paper. This means that those who cannot afford to do this unpaid work may not be able to participate.\nSometimes, the lead team can come up with the entire design for the study, without input from their international team, so many researchers end up only collecting data without having wider input in the study.\nUsually, all communication about a big team science study is done in one language, so researchers who do not speak that language will be unable to collaborate on the project, and those who only speak some of that language may struggle to understand what is needed of them.\n\n\nAs with all research, an active effort needs to be made to include a diverse range of researchers in a project. Big team science does pose a good starting model for this, and many researchers are currently working on ways to make these kinds of projects more inclusive, for example through on-boarding collaborators at the design stage so that they can have input very early on in the project, and creating training materials for researchers. For example, ManyBabies – a big team science project for developmental research – has several initiatives to try to increase diverse participation. For example, ManyBabies has a student advisor, monthly drop-in hours, and hosts training workshops on different research-relevant topics (e.g. behavioural coding).\n\nActivity 3\nAllow about 20 minutes.\nImagine you received a huge grant for a big team science project in your field. Which questions would you prioritise answering? How would you encourage participation from a diverse range of collaborators? How would you coordinate everything logistically?\n\n\n\n\n\n\n  Show / Hide Discussion\n  \n  \nThere are many things you might have thought about, depending on your research area! \nYou may have thought about which questions would be most important to answer in your field, or which questions would most benefit from having global data collection.\nYou might have thought about ways that you could encourage participation from diverse collaborators including offering clear documentation, training, and reaching out to your extended networks.\nYou might have thought of logistic concerns such as how you’d track the progress of the project, how you’d communicate with your collaborators, and how you’d ensure the project progressed through different stages.\n\nFor some advice on how to manage a big team science project, see these slides.\n  \n\n\n\n7.5.1 The open research decision tree\nHere’s another chance to explore the decision tree. It has been designed to help you conduct open research in the future, by reminding you about the principles of open research and what actions you can take to make your research open, at any stage of your research project.\n\n\n\nClick to open an interactive tool created by Open University.\n\n\n\nActivity 4\nAllow around 10 minutes.\nClick the image to open an interactive tool created by Open University.\n\nUse the open research decision tree to remind yourself about principles in open research. Imagine you wanted to remind yourself about open access journals. You learned about this in Week 6. To do this, click the Principles button, then the Accessibility button. Then select the Open access articles and journal models option. What do you find there? How is the Principles branch of the decision tree organised?\nNow think about how you can apply open research principles (such as replicability, generalisability and robustness) to a research project you have already started. If you don’t have one in mind, think of an imaginary project. Use the open research decision tree to consider what actions you can take to make your project more accessible. To do this, go back to the beginning of the decision tree, click the Actions button, then I’ve started. Select Collaborating with others and publishing your paper. That will take you to parts of this course that relate to accessibility. Can you relate the actions to your project?\nNow compare what happens if you have finished your project. Think of an ongoing project, or an imaginary one. Go back to the beginning of the decision tree, click the Actions button, then I’ve finished. Select Making data and materials accessible. Again, you will find various links to the course about how you can make your research accessible. What are they? Can you find any other actions that relate to accessibility?\n\n Take notes on what you find out.\n\n  Show / Hide Discussion\n  \n  \nIn Part 1, you should have been able to find your way to the section of Week 6 that refers to open access publishing. In other words, you moved from the principles of accessibility and open action to the action of publishing.\n\nIn Part 2, you may have found your way through actions like collaborating with others, publishing a preprint or publishing open access to ideas that relate to the principle of accessibility.\n\nIn Part 3, a prompt to check for geographical, cultural and language barriers may have brought you back to ideas of accessibility you learned in this week. The open research decision tree is organised in a way that throws up ideas and offers a quick way of accessing information from the course.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Accessibility: Academic privilege and diversity</span>"
    ]
  },
  {
    "objectID": "Week7.html#quiz",
    "href": "Week7.html#quiz",
    "title": "7  Accessibility: Academic privilege and diversity",
    "section": "7.6 Quiz",
    "text": "7.6 Quiz\nBy now, you should now be pretty well-grounded in the principles of open research! The quiz will help you consolidate the knowledge you have gained in this week.\n\n\n\nWhich type of diversity enables you to collect data that better represents the wider population? (Select one)\n\n\nDiversity of samplesDiversity of methodologyDiversity of studentsDiversity of researchers\n\n\n\nFeedback: When collecting human data, it’s important to collect diverse samples, as a more diverse sample will represent the wider population better than a less diverse one.\n\nDiversity of samples Correct\nDiversity of methodology Incorrect\nDiversity of students Incorrect\nDiversity of researchers Incorrect\n\n\n\n\n\n\nWhich type of diversity helps you bring different ideas and perspectives to research? (Select one)\n\n\nDiversity of studentsDiversity of researchersDiversity of methodologyDiversity of samples\n\n\n\nFeedback: Diverse researchers can offer unique insights, innovative solutions, and a balanced approach to the research project.\n\nDiversity of students Incorrect\nDiversity of researchers Correct\nDiversity of methodology Incorrect\nDiversity of samples Incorrect\n\n\n\n\n\n\nWhy is diverse methodology important? (Select one or more)\n\n\nThere is always ample funding to use many methodologiesIt means projects do not have to consider diversity of samples or researchersCollaboration between researchers from different disciplines could expand or enrich a methodologyA method that is appropriate for one context might not be appropriate for anotherThere is always ample time to use many methodologies\n\n\n\nFeedback: Diverse methodologies are important as they consider different contexts and perspectives.\n\nThere is always ample funding to use many methodologies Incorrect\nIt means projects do not have to consider diversity of samples or researchers Incorrect\nCollaboration between researchers from different disciplines could expand or enrich a methodology Correct\nA method that is appropriate for one context might not be appropriate for another Correct\nThere is always ample time to use many methodologies Incorrect\n\n\n\n\n\n\nWhich of the following are benefits of big team science? (Select one or more)\n\n\nSample size and generalisabilityYou can join an existing organisationDiversity, equity and inclusivitySome projects provide workshops and/or training materials for researchersYou can start a project yourself\n\n\n\nFeedback: All the options can be benefits of big team science.\n\nSample size and generalisability Correct\nYou can join an existing organisation Correct\nDiversity, equity and inclusivity Correct\nSome projects provide workshops and/or training materials for researchers Correct\nYou can start a project yourself Correct\n\n\n\n\n\n\nCan the idea behind big team science be used in non-scientific research? (Select one)\n\n\nNo, it is only suitable for mixed methods researchYes, it can be used in non-scientific researchYes, but it is only suitable for quantitative researchYes, but it is only suitable for qualitative research\n\n\n\nFeedback: The idea behind big team science can be used for non-scientific research, despite the name!\n\nNo, it is only suitable for mixed methods research Incorrect\nYes, it can be used in non-scientific research Correct\nYes, but it is only suitable for quantitative research Incorrect\nYes, but it is only suitable for qualitative research Incorrect",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Accessibility: Academic privilege and diversity</span>"
    ]
  },
  {
    "objectID": "Week7.html#summary",
    "href": "Week7.html#summary",
    "title": "7  Accessibility: Academic privilege and diversity",
    "section": "7.7 Summary",
    "text": "7.7 Summary\nThis week you learned about how important diversity, equity, and inclusion is in open research. You discovered how people in research have different amounts and types of privilege, and that this might affect their journey through academia. You explored different aspects of diversity, and how we can think about increasing diversity in our own research. You also learned about how big team science is a promising avenue for increasing diversity in research.\nNow you have learned about transparency, credibility, and accessibility, the underlying principles of open research, in Week 8 you will explore some real-world practicalities about how to commit to open research. You will discover different ways to integrate open research practices into your own work.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Accessibility: Academic privilege and diversity</span>"
    ]
  },
  {
    "objectID": "Week7.html#references",
    "href": "Week7.html#references",
    "title": "7  Accessibility: Academic privilege and diversity",
    "section": "7.8 References",
    "text": "7.8 References\nASAPBio (2024) Publish your reviews\nAvailable at: https://asapbio.org/publishyourreviews\nCERN (2024): The large hadron collider\nAvailable at: https://home.cern/science/accelerators/large-hadron-collider\nBossu, C., Iniesto, F., Vladimirschi, V, Jordan, K., and Pete, J. (2023): GO-GN Guidelines for Equity Diversity and Inclusion in Open Education with a focus on Africa and Latin America, Global OER Graduate Network (GO-GN). The Open University (UK).\nAvailable at: https://go-gn.net/gogn_outputs/edi-guidelines\nBossu, C., Vladimirschi, V, (2020): Diversity, equity and inclusion in Latin America in the context of an open education initiative, OE Global Connect (presentation).\nAvailable at: https://connect.oeglobal.org/t/diversity-equity-and-inclusion-in-latin-america-in-the-context-of-an-open-education-initiative/387\nElsherif, M., Middleton, S., Azevedo, F., Iley, B., Grosse-Hodge, M., Tyler, S., Kapp, S., Gourdon-Kanhukamwe, A., Grafton-Clark, D., Yeung, S., Shaw, J., Hartmann, H. Dokovova, M. (2022): Bridging neurodiversity and open scholarship: how shared values can guide best practices for research integrity, social justice, and principled education, MetaArXiv Preprints.\nAvailable at: https://osf.io/preprints/metaarxiv/k7a9p\nFarran, E. K., Silverstein, P., Ameen, A. A., Misheva, I., Gilmore, C. Open Research: examples of good practice and resources across disciplines\nAvailable at: https://osf.io/preprints/osf/3r8hb\nIniesto, F. and Bossu, C. (2023).: Equity, diversity, and inclusion in open education: A systematic literature review, Distance Education, 44:4, 694-711\nAvailable at: https://doi.org/10.1080/01587919.2023.2267472\nKathawalla, U., Silverstone, P., Syed, M, (2021): Easing into open science: a guide for graduate students and their advisors, University of California Press\nAvailable at: https://doi.org/10.1525/collabra.18684\nManyPrimates (2024): Many Primates\nAvailable at: https://manyprimates.github.io/\nManyPrimates (2019): Collaborative open science as a way to reproducibility and new insights in primate cognition research, Japanese Psychological Review, Vol. 62, No. 3, 205-220.\nAvailable at: https://manyprimates.github.io/assets/pdfs/ManyPrimates_JPR_2019.pdf\nThe Many Babies Consortium (2024): Many Babies\nAvailable at: https://manybabies.org/\nThe National Human Genome Research Institute (2024): The Human genome project\nAvailable at: https://www.genome.gov/human-genome-project\nOctopus (2025): Octopus (website)\nAvailable at: https://www.octopus.ac/\nPelagios Network (2024): The Pelagios Network\nAvailable at: https://pelagios.org/\nThe Psychological Science Accelerator (2024): About the psychological science accelerator\nAvailable at: https://psysciacc.org/about.html\nSociety for the Improvement of Psychological Sciences (2024): How to manage big team science projects in psychology\nAvailable at: https://docs.google.com/presentation/d/15s7Mo7GMb7Jjs6i-Cl2sF4KmOPx8X6eoilyhhcNGHGw/edit#slide=id.p",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Accessibility: Academic privilege and diversity</span>"
    ]
  },
  {
    "objectID": "Week8.html",
    "href": "Week8.html",
    "title": "8  Committing to open research",
    "section": "",
    "text": "8.1 Behaviour change\nIn Weeks 1 to 7, you learned about different aspects of transparency, integrity, and accessibility in open research. You discovered why these principles are important, and which open practices you can enact to ensure your own research is more in line with them.\nNow is the time to find out how you can commit to open research and make these practices a part of your research habits and norms!\nResearch is behaviour – we do research. Engaging in open research means engaging in a variety of specific behaviours. Some of these behaviours may have even been discouraged in some of the research training you have received, depending on when you did your research training. For this reason, it can be useful to think of engaging in open research as just another behaviour that you can think about changing, like healthy eating or exercising!\nThe COM-B model proposes that capability, opportunity, and motivation are necessary for behaviour change. The diagram below summarises what the COM-B model says about the conditions that are most likely to lead to effective behaviour change.\nIn a survey of researchers in psychology departments across the UK and Ireland, researchers found that capability, opportunity, and motivation all affected someone’s likelihood to engage in open research practices (e.g. preregistration, and open data and materials). However, the strongest predictor was automatic motivation – that is, the researcher agrees with these statements:\nDo you agree with these statements?",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Committing to open research</span>"
    ]
  },
  {
    "objectID": "Week8.html#behaviour-change",
    "href": "Week8.html#behaviour-change",
    "title": "8  Committing to open research",
    "section": "",
    "text": "COM-B Model\n\n\n\n\nI have developed the habit of engaging in open research practices as an everyday part of my research process.\nWhen I think about my research, I automatically think about the open research elements as well.\n\n\n\nActivity 1\nAllow about 10 minutes.\nThink about what you’ve learned so far this course. Write down your ideas about how you could implement open research as part of your everyday research habits.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Committing to open research</span>"
    ]
  },
  {
    "objectID": "Week8.html#open-access-repositories",
    "href": "Week8.html#open-access-repositories",
    "title": "8  Committing to open research",
    "section": "8.2 Open access repositories",
    "text": "8.2 Open access repositories\nOne of the things that can make open research difficult to ease into is that there are many different resources, with contradictory or confusing advice on the best ways to engage in different open research practices. It can be onerous to find and navigate the multiple platforms, software packages and systems.\nLuckily, the Open Science Framework (OSF) does a lot of this work for us. The OSF is a free, open platform that supports research and enables collaboration. It also provides guides on different aspects of open research. The OSF is not the only way to engage with different open research practices, but since it has functionality that covers several open research practices at once, it can be a good place to start. Some of the ways that you can use the OSF are outlined below.\nProjects\nOSF projects allows you to plan, collaborate, and organise your research studies. First, you create an OSF account. Then create a project: think of it as a folder for everything to do with one study. You can add collaborators, upload files, and review any additional capabilities that you may or may not want to use (e.g. integration with different software like Google docs or GitHub). Projects can be kept private or made public, so this can be a great way to share your data and materials publicly when they’re ready. Some people find it helpful to add materials as they progress with a study, and others just upload everything when finished.\nPreregistration\nYou can also use the OSF to preregister your studies. Preregistration plans can be of various levels of specificity (from answering a few quick questions to creating extensive documents including analysis plans), and these different levels can all be preregistered on the OSF with a variety of templates for research from different disciplines or methodologies. After you have drafted your preregistration, once you ‘register’ them officially, they get locked and timestamped. You can link your preregistration to your OSF project, which also enables you to include any additional documents related to your project.\nPreprints\nYou can also use the OSF to upload a preprintAn open-access version of your work (either before, after, or instead of publication in a journal) hosted on a preprint server. Preprints are a way to ensure that your work is openly accessible to others, regardless of where you publish your research. of your work. As you learned in Week 6, a preprint is an open-access version of your work. A preprint server is the platform that hosts your preprint: it is free to access, both for you, the uploader, and your readers. Preprint servers are usually by research discipline, but can also be organised in other ways, e.g. AfricaArXiv is a preprint server for research done by African researchers across all disciplines. Several preprint servers are hosted through the OSF (including, but not limited to, PsyArXiv, SocArXiv, and SportRxiv. If none of the listed servers represent your work well then you can also upload your preprint under the general ‘OSF preprints’. You can also link the preprint to your OSF project, so readers can easily access other materials related to your project.\nIn general, the OSF is a great ‘one-stop shop’ for enacting many of the open research practices that you have learned about in this course. By learning how to navigate and use this one platform, you can integrate many open research practices into your research habits. But it is not the only trusted repository – as you learned in Week 2, there are various institutional and discipline repositories. The Open University also has its own research repository for collaborating, planning and organising research projects, called ORDO.\n\nActivity 2\nAllow about 20 minutes.\nThis activity will familiarise you with two open access repositories: ORDO and OSF.\n\n\nActivity 2.1\nBrowse through ORDO and see if you can find a dataset for a project called ‘Building trust in digital policing: A scoping review of community policing apps’ published by an author of this course. How many categories (fields) are included in this project?\n\n  Show / Hide Discussion\n  \n  \nYou should have been able to locate the dataset. It was part of a research project which included seven fields of study, and the dataset has been downloaded several hundred times. It is stored on ORDO under a permanent, citable web link.\n  \n\n\n\nActivity 2.2\nNow, we turn our attention to the OSF. If you belong to a discipline for which the OSF would not be a natural choice, you can substitute a different repository that is targeted to your discipline.\nMake an OSF account (if you don’t already have one), and create a project for one of your research studies. You can keep it private so don’t worry about making it perfect! Go through some of the OSF guides, then upload some documents and organise your project into different components and subfolders.\n\n  Show / Hide Discussion\n  \n  \nYou have now set up your own OSF account and created a project. You can choose to make the elements of your project public when you’re ready, or if you are using this as a private practice run, that’s okay too. It’s useful to keep OSF guides nearby while you familiarise yourself with the OSF platform. Keep practicing and if you like, explore other features e.g. adding collaborators (contributors) to projects!",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Committing to open research</span>"
    ]
  },
  {
    "objectID": "Week8.html#finding-your-community",
    "href": "Week8.html#finding-your-community",
    "title": "8  Committing to open research",
    "section": "8.3 Finding your community",
    "text": "8.3 Finding your community\nHaving access to resources that help you engage in open research practices is a great first step, but navigating your open research journey will be so much easier if you surround yourself with like-minded people who can help each other. Being a part of a community means you have people you can turn to if you have questions: you can learn from each other’s mistakes and successes, and maybe even forge collaborations!\n\nNowhere Lab\nNowhere Lab is an online community that anyone can join that holds weekly Zoom meetings and has an active Slack communityA Slack is a simple discussion forum, with different channels helping to organise separate conversations for specific subgroups.. It is hosted by the lead author of this course. Although Nowhere Lab is not explicitly focused on open research, open research is a topic that is heavily covered, whether that be through discussion sessions, journal clubs (where members discuss a paper together), or training on different open research practices.\n\n\n\n\nFORRT\nThe Framework for Open and Reproducible Research Training (FORRT) is a community of educators who wish to integrate open science principles into their teaching. They strive for open and reproducible research training, advancing research transparency, reproducibility, rigour, and ethics through educational reform. FORRT provides educational infrastructure and resources designed to support the teaching and mentoring of open and reproducible science. You can explore their resources directly to learn more about open research, and join their Slack community.\n\n\n8.3.1 Open research across disciplines\nInterdisciplinary communities can be great for learning about how open research affects different fields differently. They can also be helpful for finding out how open research is done in your specific field. For this, check out Open Research Across Disciplines – a tool for exploring open research resources and case studies across fields. You can also use this resource to find people working on open research in your field and even reach out to them!\nBig team science\nBig team science has been mentioned a few times in this course, and it’s worth noting that as well as the benefits for credibility and accessibility(From FORRT Glossary) Accessibility refers to the ease of access and re-use of materials (e.g., data, code, outputs, publications) for academic purposes, particularly the ease of access is afforded to people with a chronic illness, disability and/or neurodivergence. of research, big team science can also be a great way of finding and building community. Joining a big team science project in your field can be a great way to learn about open research and get started in some open research practices before applying them to your own research.\n\nActivity 3.1\nAllow about 10 minutes.\nUse the Open Research Across Disciplines tool to find resources for open research in your field. Think about how you could apply these tools or ideas to your own research habits.\nGo back to your notes for Activity 1 of this week, where you were asked to write down ideas of how you could implement open research as part of your everyday research habits. Now, think about how you can share your data and materials from a research project you have finished. If you have not finished a project yet, you can use an imaginary one.\n\n\n\n\n\n\n\nActivity 3.2\nAllow about 10 minutes\nClick the image to open an interactive tool created by Open University.\n\n\n\nClick to open an interactive tool created by Open University.\n\n\nUse the open research decision tree to look up some possibilities. Click on the link to the open research decision tree, click the Actions button, then the I’ve finished button. This will take you to about ten possible actions you could take. What are they? Not all of these actions may be appropriate or achievable in your particular project – that’s fine! Once you have lined up some possible courses of action, you can choose the ones that are most practicable.\n Record in your notes what you find.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Committing to open research</span>"
    ]
  },
  {
    "objectID": "Week8.html#quiz",
    "href": "Week8.html#quiz",
    "title": "8  Committing to open research",
    "section": "8.4 Quiz",
    "text": "8.4 Quiz\nAre you ready to test your knowledge and show yourself how much you have learned? Take the quiz now!\n\n\n\nWhen can you publish a preprint? (Select one)\n\n\nEither before, after, or instead of publication in a journalOnly after publishing in a journalOnly instead of publishing in a journalOnly before publishing in a journal\n\n\n\nFeedback: Despite the name, a preprint can be published whether or not you have published or intend to publish in a journal (as long as the publisher allows this). Reread Week 6 to remind yourself of different publishing models and check different publishers’ rules on preprints in Sherpa Romeo, https://www.sherpa.ac.uk/romeo/.\n\nEither before, after, or instead of publication in a journal Correct\nOnly after publishing in a journal Incorrect\nOnly instead of publishing in a journal Incorrect\nOnly before publishing in a journal Incorrect\n\n\n\n\n\n\nDo I have to do everything mentioned in the course for my research to be open? (Select one)\n\n\nAs long as it is accessible and transparent, it does not matter if it does not have integrityAs long as it has integrity, it does not matter if it is not transparent or accessibleYes, otherwise it is not openNo, just do as much as you can or is appropriate for your project\n\n\n\nFeedback: Open research means different things in different disciplines, and there are different issues and requirements across these different approaches. If you apply any of the principles covered in this course to your work, you have committed to open research.\n\nAs long as it is accessible and transparent, it does not matter if it does not have integrity Incorrect\nAs long as it has integrity, it does not matter if it is not transparent or accessible Incorrect\nYes, otherwise it is not open Incorrect\nNo, just do as much as you can or is appropriate for your project Correct\n\n\n\n\n\n\nCan I use open research practices if my field, discipline or methodology is not explicitly mentioned in this course? (Select one)\n\n\nNo, open research is only appropriate for certain disciplinesNo, open research is only appropriate for certain fieldsYes you canNo, open research is only appropriate for certain methodologies\n\n\n\nFeedback: Open research is suitable for any field, discipline or method of study, but not every action or principle will apply to every project. You will find that some practices are appropriate for you, while others are not. However, knowing about open research issues and the practices of researchers working on other projects will help you to evaluate the integrity of their work.\n\nNo, open research is only appropriate for certain disciplines Incorrect\nNo, open research is only appropriate for certain fields Incorrect\nYes you can Correct\nNo, open research is only appropriate for certain methodologies Incorrect\n\n\n\n\n\n\nWhat are the principles of open research? (Select one)\n\n\nTo use quantitative research methodsTo publicise all your raw data to the widest possible audienceTo use qualitative research methodsTransparency, integrity, and accessibility\n\n\n\nFeedback: The principles of open research have been defined in this course as transparency (being open and honest about all aspects of the research process), integrity (the degree of trustworthiness or believability of research findings), and accessibility (ensuring that all who are interested are able to consume, evaluate, and otherwise interact with research products and processes).\n\nTo use quantitative research methods Incorrect\nTo publicise all your raw data to the widest possible audience Incorrect\nTo use qualitative research methods Incorrect\nTransparency, integrity, and accessibility Correct\n\n\n\n\n\n\nCan I apply open research to my finished projects? (Select one)\n\n\nNo, if you have finished your project, you’re too lateYes you can, but not all practices will be suitable or possible at all stages of a projectYes, all open research practices are suitable for finished projectsNo, you can only apply open research practices to projects you’re actively carrying out, and have already started collecting data forNo, you can only apply open research practices to projects at the planning stage\n\n\n\nFeedback: It can feel as though open research is only possible for new projects, but this is not the case. While some actions can only be taken at the planning stage of a project and some only as you are actively doing research, there are still things you can do to make your finished research projects open. To find out what actions are suitable for your finished project, use our Open Research Decision Tree.\n\nNo, if you have finished your project, you’re too late Incorrect\nYes you can, but not all practices will be suitable or possible at all stages of a project Correct\nYes, all open research practices are suitable for finished projects Incorrect\nNo, you can only apply open research practices to projects you’re actively carrying out, and have already started collecting data for Incorrect\nNo, you can only apply open research practices to projects at the planning stage Incorrect",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Committing to open research</span>"
    ]
  },
  {
    "objectID": "Week8.html#summary",
    "href": "Week8.html#summary",
    "title": "8  Committing to open research",
    "section": "8.5 Summary",
    "text": "8.5 Summary\nCongratulations – you’ve reached the end of the final week of the course! This week, you explored how to incorporate open research into your research routine by using the support and resources that are out there, and discovering your own open research community.\nOver this whole open research course, you’ve learned about why transparency, credibility, and accessibility(From FORRT Glossary) Accessibility refers to the ease of access and re-use of materials (e.g., data, code, outputs, publications) for academic purposes, particularly the ease of access is afforded to people with a chronic illness, disability and/or neurodivergence.are so important in open research, and how to apply these values to your own research. You have explored some of the actions that you can take in order to ensure your research complies with these. You have developed skills in key processes of open research, such as replication, preregistration, transparent writing, robustness analysis and open publishing.\nWe hope you have enjoyed the course, and that you will continue enjoy taking what you have learned here into the wider world of open research.",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Committing to open research</span>"
    ]
  },
  {
    "objectID": "Week8.html#references",
    "href": "Week8.html#references",
    "title": "8  Committing to open research",
    "section": "8.6 References",
    "text": "8.6 References\nCenter for Open Science (2024): OSF Preprints\nAvailable at: https://osf.io/preprints\nFarran, E. K., Silverstein, P., Ameen, A. A., Misheva, I., Gilmore, C. Open Research: examples of good practice and resources across disciplines\nAvailable at: https://osf.io/preprints/osf/3r8hb\nKathawalla, U., Silverstone, P., Syed, M, (2021): Easing into open science: a guide for graduate students and their advisors, University of California Press\nAvailable at: https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1111/bjop.12700\nSilverstein, P, Pennington, C, Branney, P, O’Connor, D, Lawlor, E, O’Brien, E, Lynott, D (2024): A registered report survey of open research practices in psychology departments in the UK and Ireland, British Journal of Psychology; 115: 497-534\nAvailable at: https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1111/ bjop.12700\nSilverstein, P (2024): Nowhere lab\nAvailable at: http://nowherelab.com/\nThe Open University (2024): Open Research Data Online (ORDO)\nAvailable at: https://ordo.open.ac.uk/\nThe Framework for Open and Reproducible Research Training (FORTT)\nAvailable at: https://forrt.org/\nUbuntuNet Alliance (2024): AfricArxiv\nAvailable at: https://info.africarxiv.org/\nUK Reproducibility Network (2024): Open research across disciplines\nAvailable at: https://www.ukrn.org/",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Committing to open research</span>"
    ]
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "Week 2: Transparency: As open as possible\nAccessible: Research data is accessible if it can be accessed by anyone in the world, either openly or through an authentication or authorisation process. This requires metadata describing it in a standardised format.\nData: The information or facts collected, observed, or generated during the course of a study or investigation.\nData dictionary: A data dictionary is a collection of names, definitions, and attributes about data elements being used in shared data.\nFindable: Research data is more findable by interested parties if it is stored in a well-organised repository with detailed metadata and persistent identifiers.\nInteroperable: Datasets are interoperable if they can be used together to generate new studies. The metadata uses standard vocabularies, which are consistent across lots of different datasets.\nOpen data and materials: Data and materials from an open study are freely available to be used, reused, and redistributed by anyone.\nMaterials: Anything used in a study, eg: questionnaires, consent forms, protocols outlining what was done, the code used to run any statistical analyses, etc.\nMetadata: Information that accompanies a piece of research, organising the materials, data and publications.\nReproducibility: A study is reproducible if, when you run the same analyses on the same data, you get the same results.\nOpen access repository: An open access repository is a digital platform that holds research output and provides free, immediate and permanent access to research data and materials.\nQualitative: A qualitative method is used to identify, analyse and report patterns (themes) in non-numerical data.\nQuantitative: Quantitative methods deal with numbers, aiming to quantify phenomena and establish patterns or relationships.\nReusable: Research data is reusable if it can be used, modified or analysed, potentially by other researchers, to generate new knowledge. It needs to include clear information to facilitate re-use.\nSecondary data analysis: A type of study where you use existing data to answer new questions.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "glossary.html#chapter-2-transparency-as-open-as-possible",
    "href": "glossary.html#chapter-2-transparency-as-open-as-possible",
    "title": "Glossary",
    "section": "",
    "text": "Accessible\n\nResearch data is accessible if it can be accessed by anyone in the world, either openly or through an authentication or authorisation process. This requires metadata describing it in a standardised format.\n\nData\n\nThe information or facts collected, observed, or generated during the course of a study or investigation.\n\nData dictionary\n\nA data dictionary is a collection of names, definitions, and attributes about data elements being used in shared data.\n\nFindable\n\nResearch data is more findable by interested parties if it is stored in a well-organised repository with detailed metadata and persistent identifiers.\n\nInteroperable\n\nDatasets are interoperable if they can be used together to generate new studies. The metadata uses standard vocabularies, which are consistent across lots of different datasets.\n\nOpen data and materials\n\nData and materials from an open study are freely available to be used, reused, and redistributed by anyone.\n\nMaterials\n\nAnything used in a study, eg: questionnaires, consent forms, protocols outlining what was done, the code used to run any statistical analyses, etc.\n\nMetadata\n\nInformation that accompanies a piece of research, organising the materials, data and publications.\n\nReproducibility\n\nA study is reproducible if, when you run the same analyses on the same data, you get the same results.\n\nOpen access repository\n\nAn open access repository is a digital platform that holds research output and provides free, immediate and permanent access to research data and materials.\n\nQualitative\n\nA qualitative method is used to identify, analyse and report patterns (themes) in non-numerical data.\n\nQuantitative\n\nQuantitative methods deal with numbers, aiming to quantify phenomena and establish patterns or relationships.\n\nReusable\n\nResearch data is reusable if it can be used, modified or analysed, potentially by other researchers, to generate new knowledge. It needs to include clear information to facilitate re-use.\n\nSecondary data analysis\n\nA type of study where you use existing data to answer new questions.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "glossary.html#chapter-3-integrity-challenging-questionable-research-practices",
    "href": "glossary.html#chapter-3-integrity-challenging-questionable-research-practices",
    "title": "Glossary",
    "section": "Chapter 3: Integrity: Challenging Questionable Research Practices",
    "text": "Chapter 3: Integrity: Challenging Questionable Research Practices\n\nBig team science\n\nA research project in which researchers from around the world conduct the same study and pool their results.\n\nConceptual replications\n\nA type of replication study which aims to vary some aspect of the original study, in order to better understand the underlying phenomenon.\n\nConstraints on generality\n\nA statement identifying populations sampled in the study and potential limits to the samples and methods, enabling others to assess the extent to which results can be generalised.\n\nDirect replications\n\nA type of replication study which aims to stay as close to the original study as possible.\n\nFalse positive\n\nAn error that occurs when a researcher believes that there is a genuine effect or difference when there is not (e.g. a person has a positive Covid test although they do not have Covid).\n\nFalse negative\n\nAn error that occurs when a researcher believes that there is no effect or difference, when actually there is (e.g. a person has a negative Covid test although they do have Covid).\n\nGeneralisability\n\nThe extent to which the findings of a study can be generalised to other situations, beyond the specific participants and conditions of the study.\n\nHARK-ing\n\nResearchers are HARK-ing if they write papers as if they had a hypothesis they wanted to test in their study, whereas in reality, they made up the hypothesis after seeing the results.\n\nP-hacking\n\nIn quantitative research, exploiting techniques that increase the likelihood of obtaining a statistically significant result.\n\nPost-hoc justifications\n\nResearchers write up justifications for their actions after a study – these justifications were not planned or decided before the study happened.\n\nReproducibility\n\nA study is reproducible if you are able to get the same results when conducting the same analyses on the same data as the original study.\n\nReplicability\n\nA study is replicable if you are able to conduct the same study again, generate new data, and still get the same results as the original study.\n\nSelective reporting\n\nResearchers are selective reporting if their results are deliberately not fully or accurately reported, in order to suppress negative or undesirable findings.\n\nSystematic review\n\nA structured literature review, which analyses existing research evidence according to a fixed set of criteria, then synthesises what the research evidence shows.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "glossary.html#chapter-4-documenting-decisions-transparently",
    "href": "glossary.html#chapter-4-documenting-decisions-transparently",
    "title": "Glossary",
    "section": "Chapter 4: Documenting Decisions Transparently",
    "text": "Chapter 4: Documenting Decisions Transparently\n\n‘Between’, ‘within’ or ‘mixed’ study design\n\nA ‘between’ study design compares different conditions between groups, a ‘within’ design compares different conditions within the same group, and a ‘mixed’ study combines the two.\n\nConfirmatory analyses\n\nAnalyses set before data collection or examination: their role is to test hypotheses.\n\nCounterbalancing\n\nA technique used by psychologists to deal with order effects when conducting repetitive tests, giving half the participants the tests in one order, the other half in the reverse order.\n\nDependent variable\n\nIn a scientific experiment design, this is the variable that changes as a result of an intervention: the researcher is interested in recording these changes.\n\nExperimental conditions\n\nIn a scientific experiment design, these are the factors that are controlled during the experiment.\n\nExploratory analyses\n\nAnalyses set after an initial data set and hypothesis have been generated: they are useful for discovering patterns in data, in order to foster hypothesis development and refinement.\n\nIndependent variable\n\nIn a scientific experiment design, this is the variable that the researcher manipulates in order to investigate its effect.\n\nPreregistration\n\nThe practice of publishing the plan for a study, such as research questions, hypotheses, research design, or data analysis plans before the data has been collected or examined.\n\nRegistration\n\nSome disciplines differentiate between ‘preregistration’ and ‘registration’, but the broad purpose is often similar.\n\nResearch degrees of freedom\n\nThe flexibility inherent in research, from hypothesis generation, designing and conducting a research study, to processing and analysing the data and interpreting and reporting results.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "glossary.html#chapter-5-integrity-supporting-robust-interpretations",
    "href": "glossary.html#chapter-5-integrity-supporting-robust-interpretations",
    "title": "Glossary",
    "section": "Chapter 5: Integrity: Supporting Robust Interpretations",
    "text": "Chapter 5: Integrity: Supporting Robust Interpretations\n\nMultiverse analysis\n\nSystematically sampling a vast set of specifications, known as a multiverse, to estimate the uncertainty surrounding the validity of a scientific claim.\n\nPositionality\n\nRefers to an individual’s social and political position within society, including their identity, background, experiences, and beliefs.\n\nP-value\n\nA p-value is a statistical measurement used to validate a hypothesis against observed data. The lower the p-value, the greater the significance of the observed difference.\n\nPreregistration\n\nThe practice of publishing the plan for a study, including research questions/hypotheses, research design, and/or data analysis plans, before the data has been collected or examined.\n\nReflexivity\n\nAn idea borrowed from qualitative research, reflexivity involves critical reflection on the researcher’s position and how it influences the research process.\n\nRobustness\n\nRefers to the strength and reliability of results.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "glossary.html#chapter-6-accessibility-making-your-research-accessible-online",
    "href": "glossary.html#chapter-6-accessibility-making-your-research-accessible-online",
    "title": "Glossary",
    "section": "Chapter 6: Accessibility: Making your research accessible online",
    "text": "Chapter 6: Accessibility: Making your research accessible online\n\nAccessible research\n\nResearch is accessible if all who are interested can consume, evaluate, and otherwise interact with research products and processes.\n\nBusiness models\n\nA private company’s business model is the company’s plan for how it will make a profit.\n\nCreative Commons license\n\nA Creative Commons license enables re-users to distribute, remix, adapt and build upon the material, as long as they abide by conditions set by the author.\n\nIntegrity\n\nThe principle of integrity refers to the degree of trustworthiness or believability of research findings.\n\nOpen access\n\nOpen access is the free, immediate, online availability of research outputs such as journal articles without having to pay a fee, combined with the rights to use these outputs fully in the digital environment.\n\nPreprints\n\nPreprints are a way to ensure that your work is openly accessible to others, regardless of where you publish your research.\n\nTransparent\n\nThe principle of transparency in research refers to the practice of being open and honest about all aspects of the research process.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "glossary.html#chapter-7-accessibility-academic-privilege-and-diversity",
    "href": "glossary.html#chapter-7-accessibility-academic-privilege-and-diversity",
    "title": "Glossary",
    "section": "Chapter 7: Accessibility: Academic privilege and diversity",
    "text": "Chapter 7: Accessibility: Academic privilege and diversity\n\nBig team science\n\nA research project in which researchers from around the world conduct the same study and pool their results.\n\nEquity\n\nEquity means the quality of being fair or impartial. In education, it is understood as presenting all scholars with the same opportunities, which sometimes requires making adjustments for their particular needs.\n\nPrivilege\n\nPrivilege is unearned access or advantage, which specific groups of people have because of their membership of a particular social group.\n\nSampling variation\n\nThe extent to which the data vary in different samples taken from the same population.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "glossary.html#chapter-8-committing-to-open-research",
    "href": "glossary.html#chapter-8-committing-to-open-research",
    "title": "Glossary",
    "section": "Chapter 8: Committing to open research",
    "text": "Chapter 8: Committing to open research\n\nPreprint\n\nAn open-access version of your work (either before, after, or instead of publication in a journal) hosted on a preprint server.\n\nSlack community\n\nA slack community is a simple discussion forum, with different channels helping to organise separate conversations for specific subgroups.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Open Research",
    "section": "License",
    "text": "License\nOur course and the original Open University course are both governed by the Creative Commons CC-BY-SA 4.0 license.\n\n\n\n\n\n\nCitation\n\n\n\nSilverstein, P. (2025) Open Research. Framework for Open and Reproducible Research Training (FORRT). https://github.com/forrtproject/Open-Research-course\n\n\nR version: This is a Quarto book built with the R bookdown package. See Github for the source files.\nContact us: If you find errors or typos, have questions or suggestions, please file an issue at Github, or use this Google Form. Thanks!",
    "crumbs": [
      "Overview",
      "Overview"
    ]
  },
  {
    "objectID": "glossary.html#week-2-transparency-as-open-as-possible",
    "href": "glossary.html#week-2-transparency-as-open-as-possible",
    "title": "Glossary",
    "section": "",
    "text": "Accessible\n\nResearch data is accessible if it can be accessed by anyone in the world, either openly or through an authentication or authorisation process. This requires metadata describing it in a standardised format.\n\nData\n\nThe information or facts collected, observed, or generated during the course of a study or investigation.\n\nData dictionary\n\nA data dictionary is a collection of names, definitions, and attributes about data elements being used in shared data.\n\nFindable\n\nResearch data is more findable by interested parties if it is stored in a well-organised repository with detailed metadata and persistent identifiers.\n\nInteroperable\n\nDatasets are interoperable if they can be used together to generate new studies. The metadata uses standard vocabularies, which are consistent across lots of different datasets.\n\nOpen data and materials\n\nData and materials from an open study are freely available to be used, reused, and redistributed by anyone.\n\nMaterials\n\nAnything used in a study, eg: questionnaires, consent forms, protocols outlining what was done, the code used to run any statistical analyses, etc.\n\nMetadata\n\nInformation that accompanies a piece of research, organising the materials, data and publications.\n\nReproducibility\n\nA study is reproducible if, when you run the same analyses on the same data, you get the same results.\n\nOpen access repository\n\nAn open access repository is a digital platform that holds research output and provides free, immediate and permanent access to research data and materials.\n\nQualitative\n\nA qualitative method is used to identify, analyse and report patterns (themes) in non-numerical data.\n\nQuantitative\n\nQuantitative methods deal with numbers, aiming to quantify phenomena and establish patterns or relationships.\n\nReusable\n\nResearch data is reusable if it can be used, modified or analysed, potentially by other researchers, to generate new knowledge. It needs to include clear information to facilitate re-use.\n\nSecondary data analysis\n\nA type of study where you use existing data to answer new questions.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "glossary.html#week-3-integrity-challenging-questionable-research-practices",
    "href": "glossary.html#week-3-integrity-challenging-questionable-research-practices",
    "title": "Glossary",
    "section": "Week 3: Integrity: Challenging Questionable Research Practices",
    "text": "Week 3: Integrity: Challenging Questionable Research Practices\nBig team science: A research project in which researchers from around the world conduct the same study and pool their results.\nConceptual replications: A type of replication study which aims to vary some aspect of the original study, in order to better understand the underlying phenomenon.\nConstraints on generality: A statement identifying populations sampled in the study and potential limits to the samples and methods, enabling others to assess the extent to which results can be generalised.\nDirect replications: A type of replication study which aims to stay as close to the original study as possible.\nFalse positive: An error that occurs when a researcher believes that there is a genuine effect or difference when there is not (e.g. a person has a positive Covid test although they do not have Covid).\nFalse negative: An error that occurs when a researcher believes that there is no effect or difference, when actually there is (e.g. a person has a negative Covid test although they do have Covid).\nGeneralisability: The extent to which the findings of a study can be generalised to other situations, beyond the specific participants and conditions of the study.\nHARK-ing: Researchers are HARK-ing if they write papers as if they had a hypothesis they wanted to test in their study, whereas in reality, they made up the hypothesis after seeing the results.\nP-hacking: In quantitative research, exploiting techniques that increase the likelihood of obtaining a statistically significant result.\nPost-hoc justifications: Researchers write up justifications for their actions after a study – these justifications were not planned or decided before the study happened.\nReproducibility: A study is reproducible if you are able to get the same results when conducting the same analyses on the same data as the original study.\nReplicability: A study is replicable if you are able to conduct the same study again, generate new data, and still get the same results as the original study.\nSelective reporting: Researchers are selective reporting if their results are deliberately not fully or accurately reported, in order to suppress negative or undesirable findings.\nSystematic review: A structured literature review, which analyses existing research evidence according to a fixed set of criteria, then synthesises what the research evidence shows.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "glossary.html#week-4-documenting-decisions-transparently",
    "href": "glossary.html#week-4-documenting-decisions-transparently",
    "title": "Glossary",
    "section": "Week 4: Documenting Decisions Transparently",
    "text": "Week 4: Documenting Decisions Transparently\n‘Between’, ‘within’ or ‘mixed’ study design: A ‘between’ study design compares different conditions between groups, a ‘within’ design compares different conditions within the same group, and a ‘mixed’ study combines the two.\nConfirmatory analyses: Analyses set before data collection or examination: their role is to test hypotheses.\nCounterbalancing: A technique used by psychologists to deal with order effects when conducting repetitive tests, giving half the participants the tests in one order, the other half in the reverse order.\nDependent variable: In a scientific experiment design, this is the variable that changes as a result of an intervention: the researcher is interested in recording these changes.\nExperimental conditions: In a scientific experiment design, these are the factors that are controlled during the experiment.\nExploratory analyses: Analyses set after an initial data set and hypothesis have been generated: they are useful for discovering patterns in data, in order to foster hypothesis development and refinement.\nIndependent variable: In a scientific experiment design, this is the variable that the researcher manipulates in order to investigate its effect.\nPreregistration: The practice of publishing the plan for a study, such as research questions, hypotheses, research design, or data analysis plans before the data has been collected or examined.\nRegistration: Some disciplines differentiate between ‘preregistration’ and ‘registration’, but the broad purpose is often similar.\nResearch degrees of freedom: The flexibility inherent in research, from hypothesis generation, designing and conducting a research study, to processing and analysing the data and interpreting and reporting results.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "glossary.html#week-5-integrity-supporting-robust-interpretations",
    "href": "glossary.html#week-5-integrity-supporting-robust-interpretations",
    "title": "Glossary",
    "section": "Week 5: Integrity: Supporting Robust Interpretations",
    "text": "Week 5: Integrity: Supporting Robust Interpretations\nMultiverse analysis: Systematically sampling a vast set of specifications, known as a multiverse, to estimate the uncertainty surrounding the validity of a scientific claim.\nPositionality: Refers to an individual’s social and political position within society, including their identity, background, experiences, and beliefs.\nP-value: A p-value is a statistical measurement used to validate a hypothesis against observed data. The lower the p-value, the greater the significance of the observed difference.\nPreregistration: The practice of publishing the plan for a study, including research questions/hypotheses, research design, and/or data analysis plans, before the data has been collected or examined.\nReflexivity: An idea borrowed from qualitative research, reflexivity involves critical reflection on the researcher’s position and how it influences the research process.\nRobustness: Refers to the strength and reliability of results.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "glossary.html#week-6-accessibility-making-your-research-accessible-online",
    "href": "glossary.html#week-6-accessibility-making-your-research-accessible-online",
    "title": "Glossary",
    "section": "Week 6: Accessibility: Making your research accessible online",
    "text": "Week 6: Accessibility: Making your research accessible online\nAccessible research: Research is accessible if all who are interested can consume, evaluate, and otherwise interact with research products and processes.\nBusiness models: A private company’s business model is the company’s plan for how it will make a profit.\nCreative Commons license: A Creative Commons license enables re-users to distribute, remix, adapt and build upon the material, as long as they abide by conditions set by the author.\nIntegrity: The principle of integrity refers to the degree of trustworthiness or believability of research findings.\nOpen access: Open access is the free, immediate, online availability of research outputs such as journal articles without having to pay a fee, combined with the rights to use these outputs fully in the digital environment.\nPreprints: Preprints are a way to ensure that your work is openly accessible to others, regardless of where you publish your research.\nTransparent: The principle of transparency in research refers to the practice of being open and honest about all aspects of the research process.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "glossary.html#week-7-accessibility-academic-privilege-and-diversity",
    "href": "glossary.html#week-7-accessibility-academic-privilege-and-diversity",
    "title": "Glossary",
    "section": "Week 7: Accessibility: Academic privilege and diversity",
    "text": "Week 7: Accessibility: Academic privilege and diversity\nBig team science: A research project in which researchers from around the world conduct the same study and pool their results.\nEquity: Equity means the quality of being fair or impartial. In education, it is understood as presenting all scholars with the same opportunities, which sometimes requires making adjustments for their particular needs.\nPrivilege: Privilege is unearned access or advantage, which specific groups of people have because of their membership of a particular social group.\nSampling variation: The extent to which the data vary in different samples taken from the same population.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "glossary.html#week-8-committing-to-open-research",
    "href": "glossary.html#week-8-committing-to-open-research",
    "title": "Glossary",
    "section": "Week 8: Committing to open research",
    "text": "Week 8: Committing to open research\nPreprint: An open-access version of your work (either before, after, or instead of publication in a journal) hosted on a preprint server.\nSlack community: A slack community is a simple discussion forum, with different channels helping to organise separate conversations for specific subgroups.\n\nWould you like to explore a comprehensive glossary of open scholarship terms? Check out the  FORRT Glossary, a community-sourced glossary currently available in English, German, and Arabic.",
    "crumbs": [
      "Appendices",
      "Glossary"
    ]
  },
  {
    "objectID": "Week2.html#references",
    "href": "Week2.html#references",
    "title": "2  Transparency: As open as possible",
    "section": "2.10 References",
    "text": "2.10 References\nCenter for Open Science (2024): Open Science Framework\nAvailable at: https://osf.io/\nCenter for Qualitative and Multi-Method Inquiry, Maxwell School of Citizenship and Public Affairs, Syracuse University (2023): The Qualitative Data Repository\nAvailable at: https://qdr.syr.edu/\nCreative Commons (2024): Share your work\nAvailable at: https://creativecommons.org/share-your-work\nEuropean Organization for Nuclear Research and OpenAIRE (2024): Zenodo\nAvailable at: https://zenodo.org\nFORRT (2024): Lesson plan 8: open data and qualitative research (lesson template with a CC-By Attribution 4.0 licence).\nAvailable at: https://osf.io/nyfqx\nKanter, D (2024): Open data relating to ‘Collecting and connecting portrait sittings: a re-evaluation of portrait-sitting accounts in enhancing knowledge and understanding of British portraiture 1900-1960’.\nAvailable at: https://doi.org/10.21954/ou.rd.c.6693558\nLia, A, Dowle, A, Taylor, C, Santino A, Roversi, P (2020): Partial catalytic Cys oxidation of human GAPDH to Cys sulfonic acid\nAvailable at: https://wellcomeopenresearch.org/articles/5-114/v2\nThe Open University (2024): Open Research Data Online (ORDO)\nAvailable at: https://ordo.open.ac.uk/\nPrinizing, M (2023): Pro-environmental behavior increases subjective well-being: evidence from an experience sampling study and a randomized experiment\nAvailable at: https://osf.io/preprints/psyarxiv/ac89k\nPlay and Learning across a Year (PLAY)\nAvailable at: https://play-project.org/index.html\nRCSB (2024): Protein Data Bank\nAvailable at: https://www.rcsb.org/\nSilverstein, P (2020): Evaluating the replicability and specificity of evidence for natural pedagogy theory\nAvailable at: https://www.research.lancs.ac.uk/ portal/ en/ publications/ evaluating-the-replicability-and-specificity-of-evidence-for-natural-pedagogy-theory(39b30b8b-7701-45b9-9009-d2d43bd5a006).html",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Transparency: As open as possible</span>"
    ]
  },
  {
    "objectID": "Week1.html#references",
    "href": "Week1.html#references",
    "title": "1  What is Open Research",
    "section": "1.9 References",
    "text": "1.9 References\nBarker et al (2024): Digital Periegesis (GAMA)\nAvailable at: https://www.periegesis.org/en/ articles.php?acid=1\nDriver et al (2009): GAMA: towards a physical understanding of galaxy formation, Astronomy & Geophysics, Volume 50, Issue 5, pp. 5.12-5.19.\nAvailable at: https://academic.oup.com/astrogeo/article/50/5/5.12/194415\nEEF (2024): A School’s Guide to Implementation\nAvailable at: https://educationendowmentfoundation.org.uk\nFarran, E. K., Silverstein, P., Ameen, A. A., Misheva, I., Gilmore, C.: Open Research: examples of good practice and resources across disciplines\nAvailable at: https://osf.io/preprints/osf/3r8hb\nGAMA Team (2024): The Galaxy and Mass Assemby (GAMA)\nAvailable at: https://www.gama-survey.org/\nHanisch, R and Quinn, P (2003): The International Virtual Observatory\nAvailable at: https://www.ivoa.net/about/TheIVOA.pdf\nInternational Virtual Observatory Alliance (2024): The Virtual Observatory (IVOA) Available at: https://www.ivoa.net\nPelagios Network (2024): The Pelagios Network\nAvailable at: https://pelagios.org\nPelagios Network (2024): What is linked open data?\nAvailable at: https://pelagios.org/linked-data\nUKRI (2025): Ensuring Open Research\nAvailable at: https://www.ukri.org/what-we-do/supporting-healthy-research-and-innovation-culture/open-research/\nWellcome (2025): What is Open research?\nAvailable at: https://wellcome.org/what-we-do/our-work/research-enviornment/open-research\nWHO (2024): The mRNA vaccine technology transfer hub\nAvailable at: https://www.who.int/initiatives/the-mrna-vaccine-technology-transfer-hub",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Open Research</span>"
    ]
  },
  {
    "objectID": "Week3.html#references",
    "href": "Week3.html#references",
    "title": "3  Integrity: Challenging questionable research practices",
    "section": "3.10 References",
    "text": "3.10 References\nCamerer, C, Dreber, A, Forsell, E, Ho, T, Huber, J, Johannesson, M, Kirchler, M, Almenberg, J, Altmejd, A, Chan, T, Heikensten, E, Holzmeister, F, Imai, T, Isaksson, S, Nave, G, Pfeiffer, T, Razen, M, Wu, H (2016): Evaluating replicability of laboratory experiments in Economics. Science, 3 Mar 2016, Vol 351, Issue 6280, pp. 1433-1436.\nAvailable at: https://doi.org/10.1126/science.aaf0918\nCova, F, Strickland, B, Abatista, A, (2021): Estimating the reproducibility of experimental philosophy. Review of Philosophy and Psychology 12(1):9-44\nAvailable at: https://www.researchgate.net/publication/325216701_Estimating_the_Reproducibility_of_Experimental_Philosophy\nEbersole CR, Mathur MB, Baranski E, et al (2020): Many labs 5: Testing pre-data-collection peer review as an intervention to increase replicability. Advances in Methods and Practices in Psychological Science. 2020;3(3):309-33\nAvailable at: https://doi.org/10.1177/2515245920958687\nEbersole C. R., Atherton O. E., Belanger A. L., Skulborstad H. M., Allen J. M., Banks J. B., … Nosek B. A. (2016): Many Labs 3: Evaluating participant pool quality across the academic semester via replication. Journal of Experimental Social Psychology, 67, 68–82.\nAvailable at: https://doi.org/10.1016/j.jesp.2015.10.012\nErrington, T, Mathur, M, Soderberg, C, Denis, A, Perfito, N, Iorns, E, Nosek, B, (2021): Investigating the replicability of preclinical cancer biology, eLife.\nAvailable at: https://doi.org/10.7554/eLife.71601\nFifethirtyeight.com: Hack your way to scientific glory (website)\nAvailable at: https://projects.fivethirtyeight.com/ p-hacking/\nFORRT (2024): Lesson plan 8: open data and qualitative research (lesson template with a CC-By Attribution 4.0 licence).\nAvailable at: https://osf.io/nyfqx\nHofstede, G. (1980): Culture’s consequences: international differences in work-related values. Beverly Hills, CA: Sage Publications.\nAvailable at: https://books.google.co.uk/books/about/Culture_s_Consequences.html?id=Cayp_Um4O9gC&redir_esc=y\nKlein, R. A., Ratliff, K. A., Vianello, M., Adams, R. B., Jr., Bahník, Š., Bernstein, M. J., Bocian, K., Brandt, M. J., Brooks, B., Brumbaugh, C. C., Cemalcilar, Z., Chandler, J., Cheong, W., Davis, W. E., Devos, T., Eisner, M., Frankowska, N., Furrow, D., Galliani, E. M., . . . Nosek, B. A. (2014). Investigating variation in replicability: A ‘many labs’ replication project. Social Psychology, 45(3), 142–152.\nAvailable at: https://doi.org/10.1027/1864-9335/a000178\nManyGoats (2025): https://www.themanygoatsproject.com/\nOpen Science Collaboration (2015): Estimating the reproducibility of psychological science Science, 349 aac4716.\nAvailable at: https://doi.org/10.1126/science.aac4716\nSilverstein, P. (2020): Evaluating the replicability and specificity of evidence for natural pedagogy theory\nAvailable at: https://www.research.lancs.ac.uk/portal/en/publications/ evaluating-the-replicability-and-specificity-of-evidence-for-natural-pedagogy-theory(39b30b8b-7701-45b9-9009-d2d43bd5a006).html\nSilverstein, P., Gliga, T., Westermann, G., Parise, E.: Probing communication induced biases in preverbal infants: two replication attempts of Yoon, Johnson and Csibra Infant Behaviour and Development, 55, 77-87.\nAvailable at: https://www.sciencedirect.com/science/article/pii/ S0163638318301474?via%3Dihub\nSimons, D. J., Shoda, Y., & Lindsay, D. S. (2017): Constraints on Generality (COG): A proposed addition to all empirical papers. Perspectives on Psychological Science, 12(6), 1123-1128.\nAvailable at: https://doi.org/10.1177/1745691617708630\nUNICEF Innocenti (2022): Evidence and Gap Map Research Briefs: UNICEF Strategic Plan 2018–2021 Goal Areas.\nAvailable at: https://www.unicef.org/innocenti/reports/evidence-and-gap-map-research-briefs",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Integrity: Challenging questionable research practices</span>"
    ]
  },
  {
    "objectID": "Week1.html#quiz-1",
    "href": "Week1.html#quiz-1",
    "title": "1  Week 1: What is Open Research",
    "section": "1.7 Quiz 1",
    "text": "1.7 Quiz 1\nHow much have you learned? Take the self-test quiz below to find out!\n\n\n\nWhich of the following statements is not true:\n\n\nResearch can be accessible without being credibleResearch can be transparent without having integrityResearch can be transparent without being accessibleResearch can have integrity without being transparent\n\n\n\nFeedback: Without transparency, we cannot assess whether or not research has integrity.\n\nResearch can be accessible without being credible. False\nResearch can be transparent without having integrity. False\nResearch can be transparent without being accessible. False\nResearch can have integrity without being transparent. True\n\n\n\n\n\n\nWhat does the principle of ‘integrity’ refer to in research?\n\n\nEnsuring that everyone has access to all research outputsWhether or not a study is replicableBeing open and honest about all aspects of the research processThe believability or trustworthiness of research findings\n\n\n\nFeedback: Being open and honest about all aspects of the research process relates to transparency, and ensuring that everyone has access to all research outputs is accessibility. Some would consider whether or not a study is replicable to be an aspect of integrity, but integrity encompasses many other factors.\n\nEnsuring that everyone has access to all research outputs False\nWhether or not a study is replicable False\nBeing open and honest about all aspects of the research process False\nThe believability or trustworthiness of research findings True\n\n\n\n\n\n\nWhy is it important for researchers to provide detailed information about how a study was conducted? (Select one or more)\n\n\nTo prove that the researcher’s work is outstandingSo that other researchers can repeat the same study againTo make it easier for readers to understand what was done in the studyTo enable other researchers to better assess the integrity of the study\n\n\n\nFeedback: These three are important academic reasons to provide detailed information about how a study was conducted – the researcher’s ego is not!\n\nTo prove that the researcher’s work is outstanding False\nSo that other researchers can repeat the same study again True\nTo make it easier for readers to understand what was done in the study True\nTo enable other researchers to better assess the integrity of the study True\n\n\n\n\n\n\nWhat is an example of a lack of transparency? (Select one)\n\n\nSharing participants’ identifiable informationNot fully describing how you conducted your studyUsing an out-dated statistical methodPublishing your article behind a paywall\n\n\n\nFeedback: By not being transparent about how you conducted your study, others will find it difficult to understand what was done, assess the credibility of your study, and repeat the same study again. The other options do not refer to transparency, they relate to other principles of open research.\n\nSharing participants’ identifiable information False\nNot fully describing how you conducted your study True\nUsing an out-dated statistical method False\nPublishing your article behind a paywall False\n\n\n\n\n\n\nWhat is an example of a lack of accessibility?\n\n\nAn article published on publicly accessible websiteA research paper written using green and red textAn article written in a very technical way, with no summary for the publicResearchers having to pay thousands of pounds to publish their articleAn article published in an online journal which readers have to pay to download articles from\n\n\n\nFeedback: If an article is published in a journal behind a paywall, only those who can afford it can access it. Similarly, if researchers must pay to publish their article, then only researchers who have the funding to do this can publish. Red and green text could make an article less accessible for those with one type of colour-blindness. Even if an article is published openly, if there is no non-specialist summary for the public, then they still may not be able to learn from the research.\n\nAn article published on publicly accessible website False\nA research paper written using green and red text True\nAn article written in a very technical way, with no summary for the public True\nResearchers having to pay thousands of pounds to publish their article True\nAn article published in an online journal which readers have to pay to download articles from True",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1: What is Open Research</span>"
    ]
  },
  {
    "objectID": "reference.html",
    "href": "reference.html",
    "title": "Reference",
    "section": "",
    "text": "Week 1: What is Open Research\nBarker et al (2024): Digital Periegesis (GAMA)\nAvailable at: https://www.periegesis.org/en/ articles.php?acid=1\nDriver et al (2009): GAMA: towards a physical understanding of galaxy formation, Astronomy & Geophysics, Volume 50, Issue 5, pp. 5.12-5.19.\nAvailable at: https://academic.oup.com/astrogeo/article/50/5/5.12/194415\nEEF (2024): A School’s Guide to Implementation\nAvailable at: https://educationendowmentfoundation.org.uk\nFarran, E. K., Silverstein, P., Ameen, A. A., Misheva, I., Gilmore, C.: Open Research: examples of good practice and resources across disciplines\nAvailable at: https://osf.io/preprints/osf/3r8hb\nGAMA Team (2024): The Galaxy and Mass Assemby (GAMA)\nAvailable at: https://www.gama-survey.org/\nHanisch, R and Quinn, P (2003): The International Virtual Observatory\nAvailable at: https://www.ivoa.net/about/TheIVOA.pdf\nInternational Virtual Observatory Alliance (2024): The Virtual Observatory (IVOA) Available at: https://www.ivoa.net\nPelagios Network (2024): The Pelagios Network\nAvailable at: https://pelagios.org\nPelagios Network (2024): What is linked open data?\nAvailable at: https://pelagios.org/linked-data\nUKRI (2025): Ensuring Open Research\nAvailable at: https://www.ukri.org/what-we-do/supporting-healthy-research-and-innovation-culture/open-research/\nWellcome (2025): What is Open research?\nAvailable at: https://wellcome.org/what-we-do/our-work/research-enviornment/open-research\nWHO (2024): The mRNA vaccine technology transfer hub\nAvailable at: https://www.who.int/initiatives/the-mrna-vaccine-technology-transfer-hub",
    "crumbs": [
      "Appendices",
      "Reference"
    ]
  },
  {
    "objectID": "reference.html#week-2-transparency-as-open-as-possible",
    "href": "reference.html#week-2-transparency-as-open-as-possible",
    "title": "Reference",
    "section": "Week 2: Transparency: As open as possible",
    "text": "Week 2: Transparency: As open as possible\nCenter for Open Science (2024): Open Science Framework\nAvailable at: https://osf.io/\nCenter for Qualitative and Multi-Method Inquiry, Maxwell School of Citizenship and Public Affairs, Syracuse University (2023): The Qualitative Data Repository\nAvailable at: https://qdr.syr.edu/\nCreative Commons (2024): Share your work\nAvailable at: https://creativecommons.org/share-your-work\nEuropean Organization for Nuclear Research and OpenAIRE (2024): Zenodo\nAvailable at: https://zenodo.org\nFORRT (2024): Lesson plan 8: open data and qualitative research (lesson template with a CC-By Attribution 4.0 licence).\nAvailable at: https://osf.io/nyfqx\nKanter, D (2024): Open data relating to ‘Collecting and connecting portrait sittings: a re-evaluation of portrait-sitting accounts in enhancing knowledge and understanding of British portraiture 1900-1960’.\nAvailable at: https://doi.org/10.21954/ou.rd.c.6693558\nLia, A, Dowle, A, Taylor, C, Santino A, Roversi, P (2020): Partial catalytic Cys oxidation of human GAPDH to Cys sulfonic acid\nAvailable at: https://wellcomeopenresearch.org/articles/5-114/v2\nThe Open University (2024): Open Research Data Online (ORDO)\nAvailable at: https://ordo.open.ac.uk/\nPrinizing, M (2023): Pro-environmental behavior increases subjective well-being: evidence from an experience sampling study and a randomized experiment\nAvailable at: https://osf.io/preprints/psyarxiv/ac89k\nPlay and Learning across a Year (PLAY)\nAvailable at: https://play-project.org/index.html\nRCSB (2024): Protein Data Bank\nAvailable at: https://www.rcsb.org/\nSilverstein, P (2020): Evaluating the replicability and specificity of evidence for natural pedagogy theory\nAvailable at: https://www.research.lancs.ac.uk/ portal/ en/ publications/ evaluating-the-replicability-and-specificity-of-evidence-for-natural-pedagogy-theory(39b30b8b-7701-45b9-9009-d2d43bd5a006).html",
    "crumbs": [
      "Appendices",
      "Reference"
    ]
  },
  {
    "objectID": "reference.html#week-3-integrity-challenging-questionable-research-practices",
    "href": "reference.html#week-3-integrity-challenging-questionable-research-practices",
    "title": "Reference",
    "section": "Week 3: Integrity: Challenging Questionable Research Practices",
    "text": "Week 3: Integrity: Challenging Questionable Research Practices\nCamerer, C, Dreber, A, Forsell, E, Ho, T, Huber, J, Johannesson, M, Kirchler, M, Almenberg, J, Altmejd, A, Chan, T, Heikensten, E, Holzmeister, F, Imai, T, Isaksson, S, Nave, G, Pfeiffer, T, Razen, M, Wu, H (2016): Evaluating replicability of laboratory experiments in Economics. Science, 3 Mar 2016, Vol 351, Issue 6280, pp. 1433-1436.\nAvailable at: https://doi.org/10.1126/science.aaf0918\nCova, F, Strickland, B, Abatista, A, (2021): Estimating the reproducibility of experimental philosophy. Review of Philosophy and Psychology 12(1):9-44\nAvailable at: https://www.researchgate.net/publication/325216701_ Estimating_the_Reproducibility_of_Experimental_Philosophy\nEbersole CR, Mathur MB, Baranski E, et al (2020): Many labs 5: Testing pre-data-collection peer review as an intervention to increase replicability. Advances in Methods and Practices in Psychological Science. 2020;3(3):309-33\nAvailable at: https://doi.org/10.1177/2515245920958687\nEbersole C. R., Atherton O. E., Belanger A. L., Skulborstad H. M., Allen J. M., Banks J. B., … Nosek B. A. (2016): Many Labs 3: Evaluating participant pool quality across the academic semester via replication. Journal of Experimental Social Psychology, 67, 68–82.\nAvailable at: https://doi.org/10.1016/j.jesp.2015.10.012\nErrington, T, Mathur, M, Soderberg, C, Denis, A, Perfito, N, Iorns, E, Nosek, B, (2021): Investigating the replicability of preclinical cancer biology, eLife.\nAvailable at: https://doi.org/10.7554/eLife.71601\nFifethirtyeight.com: Hack your way to scientific glory (website)\nAvailable at: https://projects.fivethirtyeight.com/ p-hacking/\nFORRT (2024): Lesson plan 8: open data and qualitative research (lesson template with a CC-By Attribution 4.0 licence).\nAvailable at: https://osf.io/nyfqx\nHofstede, G. (1980): Culture’s consequences: international differences in work-related values. Beverly Hills, CA: Sage Publications.\nAvailable at: https://books.google.co.uk/books/about/Culture_s_Consequences.html?id=Cayp_Um4O9gC&redir_esc=y\nKlein, R. A., Ratliff, K. A., Vianello, M., Adams, R. B., Jr., Bahník, Š., Bernstein, M. J., Bocian, K., Brandt, M. J., Brooks, B., Brumbaugh, C. C., Cemalcilar, Z., Chandler, J., Cheong, W., Davis, W. E., Devos, T., Eisner, M., Frankowska, N., Furrow, D., Galliani, E. M., . . . Nosek, B. A. (2014). Investigating variation in replicability: A ‘many labs’ replication project. Social Psychology, 45(3), 142–152.\nAvailable at: https://doi.org/10.1027/1864-9335/a000178\nManyGoats (2025): https://www.themanygoatsproject.com/\nOpen Science Collaboration (2015): Estimating the reproducibility of psychological science Science, 349 aac4716.\nAvailable at: https://doi.org/10.1126/science.aac4716\nSilverstein, P. (2020): Evaluating the replicability and specificity of evidence for natural pedagogy theory\nAvailable at: https://www.research.lancs.ac.uk/portal/en/publications/ evaluating-the-replicability-and-specificity-of-evidence-for-natural-pedagogy-theory(39b30b8b-7701-45b9-9009-d2d43bd5a006).html\nSilverstein, P., Gliga, T., Westermann, G., Parise, E.: Probing communication induced biases in preverbal infants: two replication attempts of Yoon, Johnson and Csibra Infant Behaviour and Development, 55, 77-87.\nAvailable at: https://www.sciencedirect.com/science/article/pii/ S0163638318301474?via%3Dihub\nSimons, D. J., Shoda, Y., & Lindsay, D. S. (2017): Constraints on Generality (COG): A proposed addition to all empirical papers. Perspectives on Psychological Science, 12(6), 1123-1128.\nAvailable at: https://doi.org/10.1177/1745691617708630\nUNICEF Innocenti (2022): Evidence and Gap Map Research Briefs: UNICEF Strategic Plan 2018–2021 Goal Areas.\nAvailable at: https://www.unicef.org/innocenti/reports/evidence-and-gap-map-research-briefs",
    "crumbs": [
      "Appendices",
      "Reference"
    ]
  },
  {
    "objectID": "reference.html#week-4-documenting-decisions-transparently",
    "href": "reference.html#week-4-documenting-decisions-transparently",
    "title": "Reference",
    "section": "Week 4: Documenting Decisions Transparently",
    "text": "Week 4: Documenting Decisions Transparently\nEnhancing the QUAlity and Transparency Of health Research (EQUATOR) Network (2024): Reporting guidelines for main study types\nAvailable at: https://www.equator-network.org/\nEnhancing the QUAlity and Transparency Of health Research (EQUATOR) Network (2024): What is a reporting guideline?\nAvailable at: https://www.equator-network.org/ about-us/ what-is-a-reporting-guideline/\nOpen Science Framework (2024): Registrations and preregistrations\nAvailable at: https://help.osf.io/article/ 330-welcome-to-registrations\nSilverstein, P., Gliga, T., Westermann, G., Parise, E. (2019): Probing communication-induced memory biases in preverbal infants: Two replication attempts of Yoon, Johnson and Csibra (2008), Infant Behaviour and Development, 55, 77-87.\nAvailable at: https://doi.org/ 10.1016/ j.infbeh.2019.03.005\nTong, A, Sainsbury, P, Craig, J (2007): Consolidated criteria for reporting qualitative research (COREQ): a 32-item checklist for interviews and focus groups. International Journal for Quality in Health Care, Volume 19, Issue 6, December 2007, 349–357.\nAvailable at: https://doi.org/ 10.1093/ intqhc/ mzm042\nThe Open University (2024): The open research decision tree\nAvailable at: https://www.open.edu/openlearncreate/course/view.php?id=11974\nvon Elm E, Altman D G, Egger M, Pocock S J, Gøtzsche P C, Vandenbroucke J P; STROBE Initiative (2007): The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement: guidelines for reporting observational studies. The Lancet, 370(9596): 1453-7\nAvailable at: https://doi.org/ 10.1016/ S0140-6736(07)61602-X",
    "crumbs": [
      "Appendices",
      "Reference"
    ]
  },
  {
    "objectID": "reference.html#week-5-integrity-supporting-robust-interpretations",
    "href": "reference.html#week-5-integrity-supporting-robust-interpretations",
    "title": "Reference",
    "section": "Week 5: Integrity: Supporting Robust Interpretations",
    "text": "Week 5: Integrity: Supporting Robust Interpretations\nFivethirtyeight.com: Hack your way to scientific glory\nAvailable at: https://projects.fivethirtyeight.com/p-hacking/\nLacy, M. (2017): Just tell me what I need to know: reflexivity and positionality statements\nAvailable at: https://medium.com/@Marvette/ just-tell-me-what-i-need-to-know-reflexivity-and-positionality-statements-fb52ec0f4e17\nThe Open University (2024): The open research decision tree.\nAvailable at: https://www.open.edu/openlearncreate/course/view.php?id=11974",
    "crumbs": [
      "Appendices",
      "Reference"
    ]
  },
  {
    "objectID": "reference.html#week-6-accessibility-making-your-research-accessible-online",
    "href": "reference.html#week-6-accessibility-making-your-research-accessible-online",
    "title": "Reference",
    "section": "Week 6: Accessibility: Making your research accessible online",
    "text": "Week 6: Accessibility: Making your research accessible online\nAlperin, J. P. (2015): The public impact of Latin America’s approach to open access Stanford University.\nAvailable at: https://stacks.stanford.edu/file/druid:jr256tk1194/AlperinDissertationFinalPublicImpact-augmented.pdf\nAmerican Society for Cell Biology (2024): Declaration on Research Assessment (DORA).\nAvailable at: https://sfdora.org/\nBarnes, L. (2018): Green, gold, diamond black – what does it all mean?\nAvailable at: https://blogs.openbookpublishers.com/green-gold-diamond-black-what-does-it-all-mean/\nButler, L. A., Matthias, L., Simard, M. A., Mongeon, P., & Haustein, S. (2023): The oligopoly’s shift to open access: How the big five academic publishers profit from article processing charges. Quantitative Science Studies, 4(4), 778-799.\nAvailable at: https://doi.org/10.1162/qss_a_00272\nCenter for Open Science (2024): OSF Preprints\nAvailable at: https://osf.io/preprints\nCoalition S (2024): Plan S: making full and immediate open access a reality Available at: https://www.coalition-s.org/\nCold Spring Harbour Laboratory (2024): bioRxiv: the Preprint Server for Biology Available at: https://www.biorxiv.org/\nCreative Commons (2024): About CC licenses\nAvailable at: https://creativecommons.org/share-your-work/cclicenses/\nJISC Open Policy Finder (2025): Open Policy Finder\nAvailable at: https://openpolicyfinder.jisc.ac.uk/\nLinguistics in Open Access (LingOA, 2024): Glossa: a journal of general linguistics\nAvailable at: https://www.glossa-journal.org/\nNetwork of Scientific Journals from Latin America and the Caribbean, Spain and Portugal (2024): Redalyc\nAvailable at: https://www.redalyc.org/\nPhilPapers Foundation (2024): PhilPapers (index and bibliography of philosophy)\nAvailable at: https://philpapers.org/\nSciELO (2024): Scientific Electronic Library Online (SciELO)\nAvailable at: http://scielo.org/en/\nSociety for the Improvement of Psychological Science Preprints / OSF (2024): PsyArXiv\nAvailable at: https://osf.io/preprints/psyarxiv",
    "crumbs": [
      "Appendices",
      "Reference"
    ]
  },
  {
    "objectID": "reference.html#week-7-accessibility-academic-privilege-and-diversity",
    "href": "reference.html#week-7-accessibility-academic-privilege-and-diversity",
    "title": "Reference",
    "section": "Week 7: Accessibility: Academic privilege and diversity",
    "text": "Week 7: Accessibility: Academic privilege and diversity\nASAPBio (2024) Publish your reviews\nAvailable at: https://asapbio.org/publishyourreviews\nCERN (2024): The large hadron collider\nAvailable at: https://home.cern/science/accelerators/large-hadron-collider\nBossu, C., Iniesto, F., Vladimirschi, V, Jordan, K., and Pete, J. (2023): GO-GN Guidelines for Equity Diversity and Inclusion in Open Education with a focus on Africa and Latin America, Global OER Graduate Network (GO-GN). The Open University (UK).\nAvailable at: https://go-gn.net/gogn_outputs/edi-guidelines\nBossu, C., Vladimirschi, V, (2020): Diversity, equity and inclusion in Latin America in the context of an open education initiative, OE Global Connect (presentation).\nAvailable at: https://connect.oeglobal.org/t/diversity-equity-and-inclusion-in-latin-america-in-the-context-of-an-open-education-initiative/387\nElsherif, M., Middleton, S., Azevedo, F., Iley, B., Grosse-Hodge, M., Tyler, S., Kapp, S., Gourdon-Kanhukamwe, A., Grafton-Clark, D., Yeung, S., Shaw, J., Hartmann, H. Dokovova, M. (2022): Bridging neurodiversity and open scholarship: how shared values can guide best practices for research integrity, social justice, and principled education, MetaArXiv Preprints.\nAvailable at: https://osf.io/preprints/metaarxiv/k7a9p\nFarran, E. K., Silverstein, P., Ameen, A. A., Misheva, I., Gilmore, C. Open Research: examples of good practice and resources across disciplines\nAvailable at: https://osf.io/preprints/osf/3r8hb\nIniesto, F. and Bossu, C. (2023).: Equity, diversity, and inclusion in open education: A systematic literature review, Distance Education, 44:4, 694-711\nAvailable at: https://doi.org/10.1080/01587919.2023.2267472\nKathawalla, U., Silverstone, P., Syed, M, (2021): Easing into open science: a guide for graduate students and their advisors, University of California Press\nAvailable at: https://doi.org/10.1525/collabra.18684\nManyPrimates (2024): Many Primates\nAvailable at: https://manyprimates.github.io/\nManyPrimates (2019): Collaborative open science as a way to reproducibility and new insights in primate cognition research, Japanese Psychological Review, Vol. 62, No. 3, 205-220.\nAvailable at: https://manyprimates.github.io/assets/pdfs/ManyPrimates_JPR_2019.pdf\nThe Many Babies Consortium (2024): Many Babies\nAvailable at: https://manybabies.org/\nThe National Human Genome Research Institute (2024): The Human genome project\nAvailable at: https://www.genome.gov/human-genome-project\nOctopus (2025): Octopus (website)\nAvailable at: https://www.octopus.ac/\nPelagios Network (2024): The Pelagios Network\nAvailable at: https://pelagios.org/\nThe Psychological Science Accelerator (2024): About the psychological science accelerator\nAvailable at: https://psysciacc.org/about.html\nSociety for the Improvement of Psychological Sciences (2024): How to manage big team science projects in psychology\nAvailable at: https://docs.google.com/presentation/d/15s7Mo7GMb7Jjs6i-Cl2sF4KmOPx8X6eoilyhhcNGHGw/edit#slide=id.p",
    "crumbs": [
      "Appendices",
      "Reference"
    ]
  },
  {
    "objectID": "reference.html#week-8-committing-to-open-research",
    "href": "reference.html#week-8-committing-to-open-research",
    "title": "Reference",
    "section": "Week 8: Committing to open research",
    "text": "Week 8: Committing to open research\nCenter for Open Science (2024): OSF Preprints\nAvailable at: https://osf.io/preprints\nFarran, E. K., Silverstein, P., Ameen, A. A., Misheva, I., Gilmore, C. Open Research: examples of good practice and resources across disciplines\nAvailable at: https://osf.io/preprints/osf/3r8hb\nKathawalla, U., Silverstone, P., Syed, M, (2021): Easing into open science: a guide for graduate students and their advisors, University of California Press\nAvailable at: https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1111/bjop.12700\nSilverstein, P, Pennington, C, Branney, P, O’Connor, D, Lawlor, E, O’Brien, E, Lynott, D (2024): A registered report survey of open research practices in psychology departments in the UK and Ireland, British Journal of Psychology; 115: 497-534\nAvailable at: https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1111/ bjop.12700\nSilverstein, P (2024): Nowhere lab\nAvailable at: http://nowherelab.com/\nThe Open University (2024): Open Research Data Online (ORDO)\nAvailable at: https://ordo.open.ac.uk/\nThe Framework for Open and Reproducible Research Training (FORTT)\nAvailable at: https://forrt.org/\nUbuntuNet Alliance (2024): AfricArxiv\nAvailable at: https://info.africarxiv.org/\nUK Reproducibility Network (2024): Open research across disciplines\nAvailable at: https://www.ukrn.org/",
    "crumbs": [
      "Appendices",
      "Reference"
    ]
  }
]